{
  "name": "cis-kubernetes-benchmark",
  "title": "CIS Kubernetes Benchmark Profile",
  "maintainer": "Kristian Vlaardingerbroek",
  "copyright": "Schuberg Philis B.V.",
  "copyright_email": "kvlaardingerbroek@schubergphilis.com",
  "license": "Apache-2.0",
  "summary": "An InSpec Compliance profile for the CIS Kubernetes Benchmark",
  "version": "0.2.0",
  "supports": [],
  "controls": [
    {
      "title": "Ensure that the --allow-privileged argument is set to false (Scored)",
      "desc": "Do not allow privileged containers.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/user-guide/security-context/",
          "ref": "security-context"
        }
      ],
      "tags": {
        "rationale": "The privileged container has all the system capabilities, and\n  it also lifts all the limitations enforced by the device cgroup controller. In\n  other words, the container can then do almost everything that the host can do.\n  This flag exists to allow special use-cases, like running Docker within Docker\n  and hence should be avoided for production workloads.",
        "check": "Run the following command on the master node:\n\n  `$ ps -ef | grep kube-apiserver`\n\n  Verify that the `--allow-privileged` argument is set to `false`.",
        "fix": "Edit the `/etc/kubernetes/config` file on the master node and set the\n  `KUBE_ALLOW_PRIV` parameter to \"--allow-privileged=false\":\n\n  `KUBE_ALLOW_PRIV=\"--allow-privileged=false\"`\n\n  Based on your system, restart the `kube-apiserver` service.\n\n  For example: `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "5",
          "6.1"
        ],
        "cis_rid": "1.1.1",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "low"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.1' do\n  title 'Ensure that the --allow-privileged argument is set to false (Scored)'\n  desc 'Do not allow privileged containers.'\n  impact 1.0\n\n  tag rationale: \"The privileged container has all the system capabilities, and\n  it also lifts all the limitations enforced by the device cgroup controller. In\n  other words, the container can then do almost everything that the host can do.\n  This flag exists to allow special use-cases, like running Docker within Docker\n  and hence should be avoided for production workloads.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `$ ps -ef | grep kube-apiserver`\n\n  Verify that the `--allow-privileged` argument is set to `false`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/config` file on the master node and set the\n  `KUBE_ALLOW_PRIV` parameter to \\\"--allow-privileged=false\\\":\n\n  `KUBE_ALLOW_PRIV=\\\"--allow-privileged=false\\\"`\n\n  Based on your system, restart the `kube-apiserver` service.\n\n  For example: `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['5', '6.1']\n  tag cis_rid: \"1.1.1\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n  # @todo verify/add sub-family NIST mapping\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'security-context', url: 'https://kubernetes.io/docs/user-guide/security-context/'\n\n  # @FIXME refactor: we have found that using ruby commands in the describe statment can cause issues\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--allow-privileged=false/) }\n  end\n  # @todo add a check to validate the config file as well\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 24
      },
      "id": "cis-kubernetes-benchmark-1.1.1"
    },
    {
      "title": "Ensure that the --anonymous-auth argument is set to false (Scored)",
      "desc": "Disable anonymous requests to the API server.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/authentication/#anonymous-requests",
          "ref": "anonymous-requests"
        }
      ],
      "tags": {
        "rationale": "When enabled, requests that are not rejected by other configured authentication methods are treated as anonymous requests. These requests are then served by the API server. You should rely on authentication to authorize access and disallow anonymous requests.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--anonymous-auth argument` is set to `false`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--anonymous-auth=false\":`\n\n  `KUBE_API_ARGS=\"--anonymous-auth=false\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example,\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.1.2",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.2' do\n  title 'Ensure that the --anonymous-auth argument is set to false (Scored)'\n  desc \"Disable anonymous requests to the API server.\"\n  impact 1.0\n\n  tag rationale: \"When enabled, requests that are not rejected by other configured authentication methods are treated as anonymous requests. These requests are then served by the API server. You should rely on authentication to authorize access and disallow anonymous requests.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--anonymous-auth argument` is set to `false`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--anonymous-auth=false\\\":`\n\n  `KUBE_API_ARGS=\\\"--anonymous-auth=false\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example,\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.1.2\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'anonymous-requests', url: 'https://kubernetes.io/docs/admin/authentication/#anonymous-requests'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--anonymous-auth=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 67
      },
      "id": "cis-kubernetes-benchmark-1.1.2"
    },
    {
      "title": "Ensure that the --basic-auth-file argument is not set (Scored)",
      "desc": "Do not use basic authentication.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/authentication/#static-password-file",
          "ref": "static-password-file"
        }
      ],
      "tags": {
        "rationale": "Basic authentication uses plaintext credentials for authentication. Currently, the basic authentication credentials last indefinitely, and the password cannot be changed without restarting API server. The basic authentication is currently supported for convenience. Hence, basic authentication should not be used.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--basic-auth-file` argument does not exist.",
        "fix": "Follow the documentation and configure alternate mechanisms for authentication. Then, edit the `/etc/kubernetes/apiserver` file on the master node and remove the `\"--basic- auth-file=<filename>\"` argument from the `KUBE_API_ARGS` parameter.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "16.14",
          "6.1"
        ],
        "cis_rid": "1.1.3",
        "cis_level": 1,
        "nist": [
          "AC-2 (5)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.3' do\n  title 'Ensure that the --basic-auth-file argument is not set (Scored)'\n  desc \"Do not use basic authentication.\"\n  impact 1.0\n\n  tag rationale: \"Basic authentication uses plaintext credentials for authentication. Currently, the basic authentication credentials last indefinitely, and the password cannot be changed without restarting API server. The basic authentication is currently supported for convenience. Hence, basic authentication should not be used.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--basic-auth-file` argument does not exist.\"\n\n  tag fix: \"Follow the documentation and configure alternate mechanisms for authentication. Then, edit the `/etc/kubernetes/apiserver` file on the master node and remove the `\\\"--basic- auth-file=<filename>\\\"` argument from the `KUBE_API_ARGS` parameter.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['16.14', '6.1']\n  tag cis_rid: \"1.1.3\"\n  tag cis_level: 1\n  tag nist: ['AC-2 (5)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'static-password-file', url: 'https://kubernetes.io/docs/admin/authentication/#static-password-file'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should_not match(/--basic-auth-file/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 102
      },
      "id": "cis-kubernetes-benchmark-1.1.3"
    },
    {
      "title": "Ensure that the --insecure-allow-any-token argument is not set (Scored)",
      "desc": "Do not allow any insecure tokens",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "Accepting insecure tokens would allow any token without actually authenticating anything. User information is parsed from the token and connections are allowed.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--insecure-allow-any-token` argument does not exist.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and remove the `--insecure- allow-any-token` argument from the `KUBE_API_ARGS` parameter.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "16",
          "6.1"
        ],
        "cis_rid": "1.1.4",
        "cis_level": 1,
        "nist": [
          "AC-2",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.4' do\n  title 'Ensure that the --insecure-allow-any-token argument is not set (Scored)'\n  desc \"Do not allow any insecure tokens\"\n  impact 1.0\n\n  tag rationale: \"Accepting insecure tokens would allow any token without actually authenticating anything. User information is parsed from the token and connections are allowed.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--insecure-allow-any-token` argument does not exist.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and remove the `--insecure- allow-any-token` argument from the `KUBE_API_ARGS` parameter.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['16', '6.1']\n  tag cis_rid: \"1.1.4\"\n  tag cis_level: 1\n  tag nist: ['AC-2', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should_not match(/--insecure-allow-any-token/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 135
      },
      "id": "cis-kubernetes-benchmark-1.1.4"
    },
    {
      "title": "Ensure that the --kubelet-https argument is set to true (Scored)",
      "desc": "Use https for kubelet connections.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kubelet-authentication-authorization/",
          "ref": "kubelet-authentication-authorization"
        }
      ],
      "tags": {
        "rationale": "Connections from apiserver to kubelets could potentially carry sensitive data such as secrets and keys. It is thus important to use in-transit encryption for any communication between the apiserver and kubelets.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--kubelet-https` argument either does not exist or is set to `true`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and remove the `--kubelet- https` argument from the `KUBE_API_ARGS` parameter.\n\n  Based on your system, restart the kube-apiserver service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "1.1.5",
        "cis_level": 1,
        "nist": [
          "SC-8",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.5' do\n  title 'Ensure that the --kubelet-https argument is set to true (Scored)'\n  desc \"Use https for kubelet connections.\"\n  impact 1.0\n\n  tag rationale: \"Connections from apiserver to kubelets could potentially carry sensitive data such as secrets and keys. It is thus important to use in-transit encryption for any communication between the apiserver and kubelets.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--kubelet-https` argument either does not exist or is set to `true`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and remove the `--kubelet- https` argument from the `KUBE_API_ARGS` parameter.\n\n  Based on your system, restart the kube-apiserver service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"1.1.5\"\n  tag cis_level: 1\n  tag nist: ['SC-8', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'kubelet-authentication-authorization', url: 'https://kubernetes.io/docs/admin/kubelet-authentication-authorization/'\n\n  describe.one do\n    describe processes('kube-apiserver').commands.to_s do\n      it { should match(/--kubelet-https=true/) }\n    end\n    describe processes('kube-apiserver').commands.to_s do\n      it { should_not match(/--kubelet-https/) }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 167
      },
      "id": "cis-kubernetes-benchmark-1.1.5"
    },
    {
      "title": "Ensure that the --insecure-bind-address argument is not set (Scored)",
      "desc": "Do not bind to non-loopback insecure addresses.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "If you bind the apiserver to an insecure address, basically anyone who could connect to it over the insecure port, would have unauthenticated and unencrypted access to your master node. The apiserver doesn't do any authentication checking for insecure binds and neither the insecure traffic is encrypted. Hence, you should not bind the apiserver to an insecure address.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--insecure-bind-address` argument does not exist or is set to 127.0.0.1.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and remove the `--insecure- bind-address` argument from the `KUBE_API_ADDRESS` parameter.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "9.1",
          "6.1"
        ],
        "cis_rid": "1.1.6",
        "cis_level": 1,
        "nist": [
          "CM-7 (1)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.6' do\n  title 'Ensure that the --insecure-bind-address argument is not set (Scored)'\n  desc \"Do not bind to non-loopback insecure addresses.\"\n  impact 1.0\n\n  tag rationale: \"If you bind the apiserver to an insecure address, basically anyone who could connect to it over the insecure port, would have unauthenticated and unencrypted access to your master node. The apiserver doesn't do any authentication checking for insecure binds and neither the insecure traffic is encrypted. Hence, you should not bind the apiserver to an insecure address.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--insecure-bind-address` argument does not exist or is set to 127.0.0.1.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and remove the `--insecure- bind-address` argument from the `KUBE_API_ADDRESS` parameter.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['9.1', '6.1']\n  tag cis_rid: \"1.1.6\"\n  tag cis_level: 1\n  tag nist: ['CM-7 (1)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  describe.one do\n    describe processes('kube-apiserver').commands.to_s do\n      it { should match(/--insecure-bind-address=127\\.0\\.0\\.1/) }\n    end\n    describe processes('kube-apiserver').commands.to_s do\n      it { should_not match(/--insecure-bind-address/) }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 205
      },
      "id": "cis-kubernetes-benchmark-1.1.6"
    },
    {
      "title": "Ensure that the --insecure-port argument is set to 0 (Scored)",
      "desc": "Do not bind to insecure port.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "Setting up the apiserver to serve on an insecure port would allow unauthenticated and unencrypted access to your master node. It is assumed that firewall rules are set up such that this port is not reachable from outside of the cluster. But, as a defense in depth measure, you should not use an insecure port.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--insecure-port` argument is set to `0`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set `--insecure-port=0` in the `KUBE_API_PORT` parameter.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "9.1",
          "6.1"
        ],
        "cis_rid": "1.1.7",
        "cis_level": 1,
        "nist": [
          "CM-7 (1)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.7' do\n  title 'Ensure that the --insecure-port argument is set to 0 (Scored)'\n  desc \"Do not bind to insecure port.\"\n  impact 1.0\n\n  tag rationale: \"Setting up the apiserver to serve on an insecure port would allow unauthenticated and unencrypted access to your master node. It is assumed that firewall rules are set up such that this port is not reachable from outside of the cluster. But, as a defense in depth measure, you should not use an insecure port.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--insecure-port` argument is set to `0`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set `--insecure-port=0` in the `KUBE_API_PORT` parameter.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['9.1', '6.1']\n  tag cis_rid: \"1.1.7\"\n  tag cis_level: 1\n  tag nist: ['CM-7 (1)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--insecure-port=0/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 242
      },
      "id": "cis-kubernetes-benchmark-1.1.7"
    },
    {
      "title": "Ensure that the --secure-port argument is not set to 0 (Scored)",
      "desc": "Do not disable the secure port.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "The secure port is used to serve https with authentication and authorization. If you disable it, no https traffic is served and all traffic is served unencrypted.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--secure-port` argument is either not set or is set to an integer value between 1 and 65535.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and either remove the `--secure-port` argument from the `KUBE_API_ARGS` parameter or set it to a different desired port.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "1.1.8",
        "cis_level": 1,
        "nist": [
          "SC-8",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.8' do\n  title 'Ensure that the --secure-port argument is not set to 0 (Scored)'\n  desc \"Do not disable the secure port.\"\n  impact 1.0\n\n  tag rationale: \"The secure port is used to serve https with authentication and authorization. If you disable it, no https traffic is served and all traffic is served unencrypted.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--secure-port` argument is either not set or is set to an integer value between 1 and 65535.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and either remove the `--secure-port` argument from the `KUBE_API_ARGS` parameter or set it to a different desired port.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"1.1.8\"\n  tag cis_level: 1\n  tag nist: ['SC-8', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  describe.one do\n    describe processes('kube-apiserver').commands.to_s do\n      it { should match(/--secure-port=([1-9][0-9]{0,3}|[1-5][0-9]{4}|6[0-4][0-9]{3}|65[0-4][0-9]{2}|655[0-2][0-9]|6553[0-5])/) }\n    end\n    describe processes('kube-apiserver').commands.to_s do\n      it { should_not match(/--secure-port/) }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 274
      },
      "id": "cis-kubernetes-benchmark-1.1.8"
    },
    {
      "title": "Ensure that the --profiling argument is set to false (Scored)",
      "desc": "Disable profiling, if not needed.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/community/blob/master/contributors/devel/profiling.md",
          "ref": "profiling.md"
        }
      ],
      "tags": {
        "rationale": "Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--profiling` argument is set to `false`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--profiling=false\"`:\n\n  `KUBE_API_ARGS=\"--profiling=false\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.1.9",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.9' do\n  title 'Ensure that the --profiling argument is set to false (Scored)'\n  desc \"Disable profiling, if not needed.\"\n  impact 1.0\n\n  tag rationale: \"Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--profiling` argument is set to `false`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--profiling=false\\\"`:\n\n  `KUBE_API_ARGS=\\\"--profiling=false\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.1.9\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'profiling.md', url: 'https://github.com/kubernetes/community/blob/master/contributors/devel/profiling.md'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--profiling=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 311
      },
      "id": "cis-kubernetes-benchmark-1.1.9"
    },
    {
      "title": "Ensure that the --repair-malformed-updates argument is set to false (Scored)",
      "desc": "Disable fixing of malformed updates.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/15580",
          "ref": "Kubernetes issues 15580"
        }
      ],
      "tags": {
        "rationale": "The apiserver will potentially attempt to fix the update requests to pass the validation even if the requests are malformed. Malformed requests are one of the potential ways to interact with a service without legitimate information. Such requests could potentially be used to sabotage apiserver responses.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--repair-malformed-updates` argument is set to `false`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--repair-malformed-updates=false\"`:\n\n  `KUBE_API_ARGS=\"--repair-malformed-updates=false\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.1.10",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.10' do\n  title 'Ensure that the --repair-malformed-updates argument is set to false (Scored)'\n  desc \"Disable fixing of malformed updates.\"\n  impact 1.0\n\n  tag rationale: \"The apiserver will potentially attempt to fix the update requests to pass the validation even if the requests are malformed. Malformed requests are one of the potential ways to interact with a service without legitimate information. Such requests could potentially be used to sabotage apiserver responses.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--repair-malformed-updates` argument is set to `false`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--repair-malformed-updates=false\\\"`:\n\n  `KUBE_API_ARGS=\\\"--repair-malformed-updates=false\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.1.10\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'Kubernetes issues 15580', url: 'https://github.com/kubernetes/kubernetes/issues/15580'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--repair-malformed-updates=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 346
      },
      "id": "cis-kubernetes-benchmark-1.1.10"
    },
    {
      "title": "Ensure that the admission control policy is not set to AlwaysAdmit (Scored)",
      "desc": "Do not allow all requests.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/admission-controllers/#alwaysadmit",
          "ref": "AlwaysAdmit"
        }
      ],
      "tags": {
        "rationale": "Setting admission control policy to `AlwaysAdmit` allows all requests and do not filter any requests.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that does not include `AlwaysAdmit`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to a value that does not include `AlwaysAdmit`.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.1.11",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.11' do\n  title 'Ensure that the admission control policy is not set to AlwaysAdmit (Scored)'\n  desc \"Do not allow all requests.\"\n  impact 1.0\n\n  tag rationale: \"Setting admission control policy to `AlwaysAdmit` allows all requests and do not filter any requests.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that does not include `AlwaysAdmit`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to a value that does not include `AlwaysAdmit`.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.1.11\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'AlwaysAdmit', url: 'https://kubernetes.io/docs/admin/admission-controllers/#alwaysadmit'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should_not match(/--admission-control=(?:.)*AlwaysAdmit,*(?:.)*/) }\n    it { should match(/--admission-control=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 381
      },
      "id": "cis-kubernetes-benchmark-1.1.11"
    },
    {
      "title": "Ensure that the admission control policy is set to AlwaysPullImages (Scored)",
      "desc": "Always pull images.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/admission-controllers/#alwayspullimages",
          "ref": "AlwaysPullImages"
        }
      ],
      "tags": {
        "rationale": "Setting admission control policy to `AlwaysPullImages` forces every new pod to pull the required images every time. In a multitenant cluster users can be assured that their private images can only be used by those who have the credentials to pull them. Without this admisssion control policy, once an image has been pulled to a node, any pod from any user can use it simply by knowing the image’s name, without any authorization check against the image ownership. When this plug-in is enabled, images are always pulled prior to starting containers, which means valid credentials are required.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `AlwaysPullImages`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\"--admission- control=...,AlwaysPullImages,...\"`:\n\n  `KUBE_ADMISSION_CONTROL=\"--admission-control=...,AlwaysPullImages,...\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14.4",
          "6.1"
        ],
        "cis_rid": "1.1.12",
        "cis_level": 1,
        "nist": [
          "AC-3 (3)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.12' do\n  title 'Ensure that the admission control policy is set to AlwaysPullImages (Scored)'\n  desc \"Always pull images.\"\n  impact 1.0\n\n  tag rationale: \"Setting admission control policy to `AlwaysPullImages` forces every new pod to pull the required images every time. In a multitenant cluster users can be assured that their private images can only be used by those who have the credentials to pull them. Without this admisssion control policy, once an image has been pulled to a node, any pod from any user can use it simply by knowing the image’s name, without any authorization check against the image ownership. When this plug-in is enabled, images are always pulled prior to starting containers, which means valid credentials are required.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `AlwaysPullImages`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\\\"--admission- control=...,AlwaysPullImages,...\\\"`:\n\n  `KUBE_ADMISSION_CONTROL=\\\"--admission-control=...,AlwaysPullImages,...\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14.4', '6.1']\n  tag cis_rid: \"1.1.12\"\n  tag cis_level: 1\n  tag nist: ['AC-3 (3)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'AlwaysPullImages', url: 'https://kubernetes.io/docs/admin/admission-controllers/#alwayspullimages'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--admission-control=(?:.)*AlwaysPullImages,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 415
      },
      "id": "cis-kubernetes-benchmark-1.1.12"
    },
    {
      "title": "Ensure that the admission control policy is set to DenyEscalatingExec (Scored)",
      "desc": "Deny execution of `exec` and `attach` commands in privileged pods.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/admission-controllers/#denyescalatingexec",
          "ref": "DenyEscalatingExec"
        }
      ],
      "tags": {
        "rationale": "Setting admission control policy to `DenyEscalatingExec` denies `exec` and `attach` commands to pods that run with escalated privileges that allow host access. This includes pods that run as privileged, have access to the host IPC namespace, and have access to the host PID namespace.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `DenyEscalatingExec`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\"--admission- control=...,DenyEscalatingExec,...\"`:\n\n  `KUBE_ADMISSION_CONTROL=\"--admission-control=...,DenyEscalatingExec,...\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.1.13",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.13' do\n  title 'Ensure that the admission control policy is set to DenyEscalatingExec (Scored)'\n  desc \"Deny execution of `exec` and `attach` commands in privileged pods.\"\n  impact 1.0\n\n  tag rationale: \"Setting admission control policy to `DenyEscalatingExec` denies `exec` and `attach` commands to pods that run with escalated privileges that allow host access. This includes pods that run as privileged, have access to the host IPC namespace, and have access to the host PID namespace.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `DenyEscalatingExec`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\\\"--admission- control=...,DenyEscalatingExec,...\\\"`:\n\n  `KUBE_ADMISSION_CONTROL=\\\"--admission-control=...,DenyEscalatingExec,...\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.1.13\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'DenyEscalatingExec', url: 'https://kubernetes.io/docs/admin/admission-controllers/#denyescalatingexec'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--admission-control=(?:.)*DenyEscalatingExec,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 450
      },
      "id": "cis-kubernetes-benchmark-1.1.13"
    },
    {
      "title": "Ensure that the admission control policy is set to SecurityContextDeny (Scored)",
      "desc": "Restrict pod level SecurityContext customization. Instead of using a customized SecurityContext for your pods, use a Pod Security Policy (PSP), which is a cluster-level resource that controls the actions that a pod can perform and what it has the ability to access.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/admission-controllers/#securitycontextdeny",
          "ref": "SecurityContextDeny"
        },
        {
          "url": "https://kubernetes.io/docs/user-guide/pod-security-policy/#working-with-rbac",
          "ref": "Working with rbac"
        }
      ],
      "tags": {
        "rationale": "Setting admission control policy to `SecurityContextDeny` denies the pod level SecurityContext customization. Any attempts to customize the SecurityContexts that are not explicitly defined in the Pod Security Policy (PSP) are blocked. This ensures that all the pods adhere to the PSP defined by your organization and you have a uniform pod level security posture.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `SecurityContextDeny`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\"--admission- control=...,SecurityContextDeny,...\"`:\n\n  `KUBE_ADMISSION_CONTROL=\"--admission-control=...,SecurityContextDeny,...\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.1.14",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.14' do\n  title 'Ensure that the admission control policy is set to SecurityContextDeny (Scored)'\n  desc \"Restrict pod level SecurityContext customization. Instead of using a customized SecurityContext for your pods, use a Pod Security Policy (PSP), which is a cluster-level resource that controls the actions that a pod can perform and what it has the ability to access.\"\n  impact 1.0\n\n  tag rationale: \"Setting admission control policy to `SecurityContextDeny` denies the pod level SecurityContext customization. Any attempts to customize the SecurityContexts that are not explicitly defined in the Pod Security Policy (PSP) are blocked. This ensures that all the pods adhere to the PSP defined by your organization and you have a uniform pod level security posture.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `SecurityContextDeny`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\\\"--admission- control=...,SecurityContextDeny,...\\\"`:\n\n  `KUBE_ADMISSION_CONTROL=\\\"--admission-control=...,SecurityContextDeny,...\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.1.14\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'SecurityContextDeny', url: 'https://kubernetes.io/docs/admin/admission-controllers/#securitycontextdeny'\n  ref 'Working with rbac', url: 'https://kubernetes.io/docs/user-guide/pod-security-policy/#working-with-rbac'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--admission-control=(?:.)*SecurityContextDeny,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 485
      },
      "id": "cis-kubernetes-benchmark-1.1.14"
    },
    {
      "title": "Ensure that the admission control policy is set to NamespaceLifecycle (Scored)",
      "desc": "Reject creating objects in a namespace that is undergoing termination.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/admission-controllers/#namespacelifecycle",
          "ref": "NamespaceLifecycle"
        }
      ],
      "tags": {
        "rationale": "Setting admission control policy to `NamespaceLifecycle` ensures that objects cannot be created in non-existent namespaces, and that namespaces undergoing termination are not used for creating the new objects. This is recommended to enforce the integrity of the namespace termination process and also for the availability of the newer objects.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `NamespaceLifecycle`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\"--admission- control=NamespaceLifecycle,...\"`:\n\n  `KUBE_ADMISSION_CONTROL=\"--admission-control=NamespaceLifecycle,...\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.1.15",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.15' do\n  title 'Ensure that the admission control policy is set to NamespaceLifecycle (Scored)'\n  desc \"Reject creating objects in a namespace that is undergoing termination.\"\n  impact 1.0\n\n  tag rationale: \"Setting admission control policy to `NamespaceLifecycle` ensures that objects cannot be created in non-existent namespaces, and that namespaces undergoing termination are not used for creating the new objects. This is recommended to enforce the integrity of the namespace termination process and also for the availability of the newer objects.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `NamespaceLifecycle`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\\\"--admission- control=NamespaceLifecycle,...\\\"`:\n\n  `KUBE_ADMISSION_CONTROL=\\\"--admission-control=NamespaceLifecycle,...\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.1.15\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'NamespaceLifecycle', url: 'https://kubernetes.io/docs/admin/admission-controllers/#namespacelifecycle'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--admission-control=(?:.)*NamespaceLifecycle,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 521
      },
      "id": "cis-kubernetes-benchmark-1.1.15"
    },
    {
      "title": "Ensure that the --audit-log-path argument is set as appropriate (Scored)",
      "desc": "Enable auditing on kubernetes apiserver and set the desired audit log path as appropriate.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/cluster-administration/audit/",
          "ref": "cluster-administration"
        },
        {
          "url": "https://github.com/kubernetes/features/issues/22",
          "ref": "Kubernetes issues 22"
        }
      ],
      "tags": {
        "rationale": "Auditing Kubernetes apiserver provides a security-relevant chronological set of records documenting the sequence of activities that have affected system by individual users, administrators or other components of the system. Even though currently, Kubernetes provides only basic audit capabilities, it should be enabled. You can enable it by setting an appropriate audit log path.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--audit-log-path` argument is set as appropriate.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--audit-log-path=<filename>\"`:\n\n  `KUBE_API_ARGS=\"--audit-log-path=/var/log/apiserver/audit.log\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "6.2",
          "6.1"
        ],
        "cis_rid": "1.1.16",
        "cis_level": 1,
        "nist": [
          "AU-3",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.16' do\n  title 'Ensure that the --audit-log-path argument is set as appropriate (Scored)'\n  desc \"Enable auditing on kubernetes apiserver and set the desired audit log path as appropriate.\"\n  impact 1.0\n\n  tag rationale: \"Auditing Kubernetes apiserver provides a security-relevant chronological set of records documenting the sequence of activities that have affected system by individual users, administrators or other components of the system. Even though currently, Kubernetes provides only basic audit capabilities, it should be enabled. You can enable it by setting an appropriate audit log path.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--audit-log-path` argument is set as appropriate.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--audit-log-path=<filename>\\\"`:\n\n  `KUBE_API_ARGS=\\\"--audit-log-path=/var/log/apiserver/audit.log\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['6.2', '6.1']\n  tag cis_rid: \"1.1.16\"\n  tag cis_level: 1\n  tag nist: ['AU-3', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'cluster-administration', url: 'https://kubernetes.io/docs/concepts/cluster-administration/audit/'\n  ref 'Kubernetes issues 22', url: 'https://github.com/kubernetes/features/issues/22'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--audit-log-path=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 556
      },
      "id": "cis-kubernetes-benchmark-1.1.16"
    },
    {
      "title": "Ensure that the --audit-log-maxage argument is set to 30 or as appropriate (Scored)",
      "desc": "Retain the logs for at least 30 days or as appropriate.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/cluster-administration/audit/",
          "ref": "cluster-administration"
        },
        {
          "url": "https://github.com/kubernetes/features/issues/22",
          "ref": "Kubernetes issues 22"
        }
      ],
      "tags": {
        "rationale": "Retaining logs for at least 30 days ensures that you can go back in time and investigate or correlate any events. Set your audit log retention period to 30 days or as per your business requirements.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--audit-log-maxage` argument is set to `30` or as appropriate.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--audit-log-maxage=30\"`:\n\n  `KUBE_API_ARGS=\"--audit-log-maxage=30\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "6.3",
          "6.1"
        ],
        "cis_rid": "1.1.17",
        "cis_level": 1,
        "nist": [
          "AU-4",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.17' do\n  title 'Ensure that the --audit-log-maxage argument is set to 30 or as appropriate (Scored)'\n  desc \"Retain the logs for at least 30 days or as appropriate.\"\n  impact 1.0\n\n  tag rationale: \"Retaining logs for at least 30 days ensures that you can go back in time and investigate or correlate any events. Set your audit log retention period to 30 days or as per your business requirements.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--audit-log-maxage` argument is set to `30` or as appropriate.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--audit-log-maxage=30\\\"`:\n\n  `KUBE_API_ARGS=\\\"--audit-log-maxage=30\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['6.3', '6.1']\n  tag cis_rid: \"1.1.17\"\n  tag cis_level: 1\n  tag nist: ['AU-4', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'cluster-administration', url: 'https://kubernetes.io/docs/concepts/cluster-administration/audit/'\n  ref 'Kubernetes issues 22', url: 'https://github.com/kubernetes/features/issues/22'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--audit-log-maxage=/) }\n  end\n\n  audit_log_maxage = processes('kube-apiserver').commands.to_s.scan(/--audit-log-maxage=(\\d+)/)\n\n  unless audit_log_maxage.empty?\n    describe audit_log_maxage.last.first.to_i do\n      it { should cmp >= 30 }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 592
      },
      "id": "cis-kubernetes-benchmark-1.1.17"
    },
    {
      "title": "Ensure that the --audit-log-maxbackup argument is set to 10 or as appropriate (Scored)",
      "desc": "Retain 10 or an appropriate number of old log files.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/cluster-administration/audit/",
          "ref": "cluster-administration"
        },
        {
          "url": "https://github.com/kubernetes/features/issues/22",
          "ref": "Kubernetes issues 22"
        }
      ],
      "tags": {
        "rationale": "Kubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. For example, if you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--audit-log-maxbackup` argument is set to `10` or as appropriate.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--audit-log-maxbackup=10\"`:\n\n  `KUBE_API_ARGS=\"--audit-log-maxbackup=10\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "6.3",
          "6.1"
        ],
        "cis_rid": "1.1.18",
        "cis_level": 1,
        "nist": [
          "AU-4",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.18' do\n  title 'Ensure that the --audit-log-maxbackup argument is set to 10 or as appropriate (Scored)'\n  desc \"Retain 10 or an appropriate number of old log files.\"\n  impact 1.0\n\n  tag rationale: \"Kubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. For example, if you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--audit-log-maxbackup` argument is set to `10` or as appropriate.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--audit-log-maxbackup=10\\\"`:\n\n  `KUBE_API_ARGS=\\\"--audit-log-maxbackup=10\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['6.3', '6.1']\n  tag cis_rid: \"1.1.18\"\n  tag cis_level: 1\n  tag nist: ['AU-4', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'cluster-administration', url: 'https://kubernetes.io/docs/concepts/cluster-administration/audit/'\n  ref 'Kubernetes issues 22', url: 'https://github.com/kubernetes/features/issues/22'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--audit-log-maxbackup=/) }\n  end\n\n  audit_log_maxbackup = processes('kube-apiserver').commands.to_s.scan(/--audit-log-maxbackup=(\\d+)/)\n\n  unless audit_log_maxbackup.empty?\n    describe audit_log_maxbackup.last.first.to_i do\n      it { should cmp >= 10 }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 636
      },
      "id": "cis-kubernetes-benchmark-1.1.18"
    },
    {
      "title": "Ensure that the --audit-log-maxsize argument is set to 100 or as appropriate (Scored)",
      "desc": "Rotate log files on reaching 100 MB or as appropriate.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/cluster-administration/audit/",
          "ref": "cluster-administration"
        },
        {
          "url": "https://github.com/kubernetes/features/issues/22",
          "ref": "Kubernetes issues 22"
        }
      ],
      "tags": {
        "rationale": "Kubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. If you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--audit-log-maxsize` argument is set to `100` or as appropriate.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--audit-log-maxsize=100\"`:\n\n  `KUBE_API_ARGS=\"--audit-log-maxsize=100\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "6.3",
          "6.1"
        ],
        "cis_rid": "1.1.19",
        "cis_level": 1,
        "nist": [
          "AU-4",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.19' do\n  title 'Ensure that the --audit-log-maxsize argument is set to 100 or as appropriate (Scored)'\n  desc \"Rotate log files on reaching 100 MB or as appropriate.\"\n  impact 1.0\n\n  tag rationale: \"Kubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. If you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--audit-log-maxsize` argument is set to `100` or as appropriate.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--audit-log-maxsize=100\\\"`:\n\n  `KUBE_API_ARGS=\\\"--audit-log-maxsize=100\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['6.3', '6.1']\n  tag cis_rid: \"1.1.19\"\n  tag cis_level: 1\n  tag nist: ['AU-4', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'cluster-administration', url: 'https://kubernetes.io/docs/concepts/cluster-administration/audit/'\n  ref 'Kubernetes issues 22', url: 'https://github.com/kubernetes/features/issues/22'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--audit-log-maxsize=/) }\n  end\n\n  audit_log_maxsize = processes('kube-apiserver').commands.to_s.scan(/--audit-log-maxsize=(\\d+)/)\n\n  unless audit_log_maxsize.empty?\n    describe audit_log_maxsize.last.first.to_i do\n      it { should cmp >= 100 }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 680
      },
      "id": "cis-kubernetes-benchmark-1.1.19"
    },
    {
      "title": "Ensure that the --authorization-mode argument is not set to AlwaysAllow (Scored)",
      "desc": "Do not always authorize all requests.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/authorization/",
          "ref": "authorization"
        }
      ],
      "tags": {
        "rationale": "The apiserver, by default, allows all requests. You should restrict this behavior to only allow the authorization modes that you explicitly use in your environment. For example, if you don't use REST APIs in your environment, it is a good security best practice to switch off that capability.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--authorization-mode` argument exists and is not set to `AlwaysAllow`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to values other than `--authorization-mode=AlwaysAllow`. One such example could be as below:\n\n  `KUBE_API_ARGS=\"--authorization-mode=RBAC\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "9.1",
          "6.1"
        ],
        "cis_rid": "1.1.20",
        "cis_level": 1,
        "nist": [
          "CM-7 (1)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.20' do\n  title 'Ensure that the --authorization-mode argument is not set to AlwaysAllow (Scored)'\n  desc \"Do not always authorize all requests.\"\n  impact 1.0\n\n  tag rationale: \"The apiserver, by default, allows all requests. You should restrict this behavior to only allow the authorization modes that you explicitly use in your environment. For example, if you don't use REST APIs in your environment, it is a good security best practice to switch off that capability.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--authorization-mode` argument exists and is not set to `AlwaysAllow`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to values other than `--authorization-mode=AlwaysAllow`. One such example could be as below:\n\n  `KUBE_API_ARGS=\\\"--authorization-mode=RBAC\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['9.1', '6.1']\n  tag cis_rid: \"1.1.20\"\n  tag cis_level: 1\n  tag nist: ['CM-7 (1)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'authorization', url: 'https://kubernetes.io/docs/admin/authorization/'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should_not match(/--authorization-mode=(?:.)*AlwaysAllow,*(?:.)*/) }\n    it { should match(/--authorization-mode=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 724
      },
      "id": "cis-kubernetes-benchmark-1.1.20"
    },
    {
      "title": "Ensure that the --token-auth-file parameter is not set (Scored)",
      "desc": "Do not use token based authentication.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/authentication/#static-token-file",
          "ref": "static-token-file"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "The token-based authentication utilizes static tokens to authenticate requests to the apiserver. The tokens are stored in clear-text in a file on the apiserver, and cannot be revoked or rotated without restarting the apiserver. Hence, do not use static token-based authentication.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--token-auth-file` argument does not exist.",
        "fix": "Follow the documentation and configure alternate mechanisms for authentication. Then, edit the `/etc/kubernetes/apiserver` file on the master node and remove the `\"--token- auth-file=<filename>\"` argument from the `KUBE_API_ARGS` parameter.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "16.14",
          "6.1"
        ],
        "cis_rid": "1.1.21",
        "cis_level": 1,
        "nist": [
          "AC-2 (5)",
          "Rev_4"
        ],
        "severity": "high"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.21' do\n  title 'Ensure that the --token-auth-file parameter is not set (Scored)'\n  desc \"Do not use token based authentication.\"\n  impact 1.0\n\n  tag rationale: \"The token-based authentication utilizes static tokens to authenticate requests to the apiserver. The tokens are stored in clear-text in a file on the apiserver, and cannot be revoked or rotated without restarting the apiserver. Hence, do not use static token-based authentication.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--token-auth-file` argument does not exist.\"\n\n  tag fix: \"Follow the documentation and configure alternate mechanisms for authentication. Then, edit the `/etc/kubernetes/apiserver` file on the master node and remove the `\\\"--token- auth-file=<filename>\\\"` argument from the `KUBE_API_ARGS` parameter.\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['16.14', '6.1']\n  tag cis_rid: \"1.1.21\"\n  tag cis_level: 1\n  tag nist: ['AC-2 (5)', '4']\n  tag severity: \"medium\"\n\n  ref 'static-token-file', url: 'https://kubernetes.io/docs/admin/authentication/#static-token-file'\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should_not match(/--token-auth-file/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 760
      },
      "id": "cis-kubernetes-benchmark-1.1.21"
    },
    {
      "title": "Ensure that the --kubelet-certificate-authority argument is set as appropriate (Scored)",
      "desc": "Verify kubelet's certificate before establishing connection.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kubelet-authentication-authorization/",
          "ref": "kubelet-authentication-authorization"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/cluster-administration/master-node-communication/#apiserver---kubelet",
          "ref": "apiserver---kubelet"
        }
      ],
      "tags": {
        "rationale": "The connections from the apiserver to the kubelet are used for fetching logs for pods, attaching (through kubectl) to running pods, and using the kubelet’s port-forwarding functionality. These connections terminate at the kubelet’s HTTPS endpoint. By default, the apiserver does not verify the kubelet’s serving certificate, which makes the connection subject to man-in-the-middle attacks, and unsafe to run over untrusted and/or public networks.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--kubelet-certificate-authority` argument exists and is set as appropriate.",
        "fix": "Follow the Kubernetes documentation and setup the TLS connection between the apiserver and kubelets. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--kubelet-certificate-authority=<ca-string>\"`:\n\n  `KUBE_API_ARGS=\"--kubelet-certificate-authority=<ca-string>\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "3.4",
          "6.1"
        ],
        "cis_rid": "1.1.22",
        "cis_level": 1,
        "nist": [
          "SC-2",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.22' do\n  title 'Ensure that the --kubelet-certificate-authority argument is set as appropriate (Scored)'\n  desc \"Verify kubelet's certificate before establishing connection.\"\n  impact 1.0\n\n  tag rationale: \"The connections from the apiserver to the kubelet are used for fetching logs for pods, attaching (through kubectl) to running pods, and using the kubelet’s port-forwarding functionality. These connections terminate at the kubelet’s HTTPS endpoint. By default, the apiserver does not verify the kubelet’s serving certificate, which makes the connection subject to man-in-the-middle attacks, and unsafe to run over untrusted and/or public networks.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--kubelet-certificate-authority` argument exists and is set as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and setup the TLS connection between the apiserver and kubelets. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--kubelet-certificate-authority=<ca-string>\\\"`:\n\n  `KUBE_API_ARGS=\\\"--kubelet-certificate-authority=<ca-string>\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['3.4', '6.1']\n  tag cis_rid: \"1.1.22\"\n  tag cis_level: 1\n  tag nist: ['SC-2', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'kubelet-authentication-authorization', url: 'https://kubernetes.io/docs/admin/kubelet-authentication-authorization/'\n  ref 'apiserver---kubelet', url: 'https://kubernetes.io/docs/concepts/cluster-administration/master-node-communication/#apiserver---kubelet'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--kubelet-certificate-authority=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 793
      },
      "id": "cis-kubernetes-benchmark-1.1.22"
    },
    {
      "title": "Ensure that the --kubelet-client-certificate and --kubelet-client-key arguments are set as appropriate (Scored)",
      "desc": "Enable certificate based kubelet authentication.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kubelet-authentication-authorization/",
          "ref": "kubelet-authentication-authorization"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/cluster-administration/master-node-communication/#apiserver---kubelet",
          "ref": "apiserver---kubelet"
        }
      ],
      "tags": {
        "rationale": "The apiserver, by default, does not authenticate itself to the kubelet's HTTPS endpoints. The requests from the apiserver are treated anonymously. You should set up certificate-based kubelet authentication to ensure that the apiserver authenticates itself to kubelets when submitting requests.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--kubelet-client-certificate` and `--kubelet-client-key` arguments exist and they are set as appropriate.",
        "fix": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and kubelets. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--kubelet-client- certificate=<path/to/client-certificate-file>\"` and `\"--kubelet-client- key=<path/to/client-key-file>\"`:\n\n  `KUBE_API_ARGS=\"--kubelet-client-certificate=<path/to/client-certificate-file> --kubelet-client-key=<path/to/client-key-file>\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "3.4",
          "6.1"
        ],
        "cis_rid": "1.1.23",
        "cis_level": 1,
        "nist": [
          "SC-2",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.23' do\n  title 'Ensure that the --kubelet-client-certificate and --kubelet-client-key arguments are set as appropriate (Scored)'\n  desc \"Enable certificate based kubelet authentication.\"\n  impact 1.0\n\n  tag rationale: \"The apiserver, by default, does not authenticate itself to the kubelet's HTTPS endpoints. The requests from the apiserver are treated anonymously. You should set up certificate-based kubelet authentication to ensure that the apiserver authenticates itself to kubelets when submitting requests.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--kubelet-client-certificate` and `--kubelet-client-key` arguments exist and they are set as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and set up the TLS connection between the apiserver and kubelets. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--kubelet-client- certificate=<path/to/client-certificate-file>\\\"` and `\\\"--kubelet-client- key=<path/to/client-key-file>\\\"`:\n\n  `KUBE_API_ARGS=\\\"--kubelet-client-certificate=<path/to/client-certificate-file> --kubelet-client-key=<path/to/client-key-file>\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['3.4', '6.1']\n  tag cis_rid: \"1.1.23\"\n  tag cis_level: 1\n  tag nist: ['SC-2', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'kubelet-authentication-authorization', url: 'https://kubernetes.io/docs/admin/kubelet-authentication-authorization/'\n  ref 'apiserver---kubelet', url: 'https://kubernetes.io/docs/concepts/cluster-administration/master-node-communication/#apiserver---kubelet'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--kubelet-client-certificate=/) }\n    it { should match(/--kubelet-client-key=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 829
      },
      "id": "cis-kubernetes-benchmark-1.1.23"
    },
    {
      "title": "Ensure that the --service-account-lookup argument is set to true (Scored)",
      "desc": "Validate service account before validating token.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/24167",
          "ref": "Kubernetes issues 24167"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Time_of_check_to_time_of_use",
          "ref": "Time_of_check_to_time_of_use"
        }
      ],
      "tags": {
        "rationale": "By default, the apiserver only verifies that the authentication token is valid. However, it does not validate that the service account token mentioned in the request is actually present in etcd. This allows using a service account token even after the corresponding service account is deleted. This is an example of time of check to time of use security issue.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--service-account-lookup` argument exists and is set to `true`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--service-account-lookup=true\"`:\n\n  `KUBE_API_ARGS=\"--service-account-lookup=true\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "16",
          "6.1"
        ],
        "cis_rid": "1.1.24",
        "cis_level": 1,
        "nist": [
          "AC-2",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.24' do\n  title 'Ensure that the --service-account-lookup argument is set to true (Scored)'\n  desc \"Validate service account before validating token.\"\n  impact 1.0\n\n  tag rationale: \"By default, the apiserver only verifies that the authentication token is valid. However, it does not validate that the service account token mentioned in the request is actually present in etcd. This allows using a service account token even after the corresponding service account is deleted. This is an example of time of check to time of use security issue.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--service-account-lookup` argument exists and is set to `true`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--service-account-lookup=true\\\"`:\n\n  `KUBE_API_ARGS=\\\"--service-account-lookup=true\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['16', '6.1']\n  tag cis_rid: \"1.1.24\"\n  tag cis_level: 1\n  tag nist: ['AC-2', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'Kubernetes issues 24167', url: 'https://github.com/kubernetes/kubernetes/issues/24167'\n  ref 'Time_of_check_to_time_of_use', url: 'https://en.wikipedia.org/wiki/Time_of_check_to_time_of_use'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--service-account-lookup=true/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 866
      },
      "id": "cis-kubernetes-benchmark-1.1.24"
    },
    {
      "title": "Ensure that the admission control policy is set to PodSecurityPolicy (Scored)",
      "desc": "Reject creating pods that do not match Pod Security Policies.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/admission-controllers/#podsecuritypolicy",
          "ref": "PodSecurityPolicy"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/policy/pod-security-policy/#enabling-pod-security-policies",
          "ref": "Enabling PodSecurityPolicy"
        }
      ],
      "tags": {
        "rationale": "A Pod Security Policy is a cluster-level resource that controls the actions that a pod can perform and what it has the ability to access. The `PodSecurityPolicy` objects define a set of conditions that a pod must run with in order to be accepted into the system. Pod Security Policies are comprised of settings and strategies that control the security features a pod has access to and hence this must be used to control pod access permissions.",
        "check": "Run the following command on the master node:\n\n  'ps -ef | grep kube-apiserver'\n\n  Verify that the `--admission-control` argument is set to a value that includes `PodSecurityPolicy`.",
        "fix": "Follow the documentation and create Pod Security Policy objects as per your environment. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\"--admission- control=...,PodSecurityPolicy,...\"`:\n\n  `KUBE_ADMISSION_CONTROL=\"--admission-control=...,PodSecurityPolicy,...\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.1.25",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.25' do\n  title 'Ensure that the admission control policy is set to PodSecurityPolicy (Scored)'\n  desc \"Reject creating pods that do not match Pod Security Policies.\"\n  impact 1.0\n\n  tag rationale: \"A Pod Security Policy is a cluster-level resource that controls the actions that a pod can perform and what it has the ability to access. The `PodSecurityPolicy` objects define a set of conditions that a pod must run with in order to be accepted into the system. Pod Security Policies are comprised of settings and strategies that control the security features a pod has access to and hence this must be used to control pod access permissions.\"\n\n  tag check: \"Run the following command on the master node:\n\n  'ps -ef | grep kube-apiserver'\n\n  Verify that the `--admission-control` argument is set to a value that includes `PodSecurityPolicy`.\"\n\n  tag fix: \"Follow the documentation and create Pod Security Policy objects as per your environment. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\\\"--admission- control=...,PodSecurityPolicy,...\\\"`:\n\n  `KUBE_ADMISSION_CONTROL=\\\"--admission-control=...,PodSecurityPolicy,...\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.1.25\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'PodSecurityPolicy', url: 'https://kubernetes.io/docs/admin/admission-controllers/#podsecuritypolicy'\n  ref 'Enabling PodSecurityPolicy', url: 'https://kubernetes.io/docs/concepts/policy/pod-security-policy/#enabling-pod-security-policies'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--admission-control=(?:.)*PodSecurityPolicy,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 902
      },
      "id": "cis-kubernetes-benchmark-1.1.25"
    },
    {
      "title": "Ensure that the --service-account-key-file argument is set as appropriate (Scored)",
      "desc": "Explicitly set a service account public key file for service accounts on the apiserver.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/24167",
          "ref": "Kubernetes issues 24167"
        }
      ],
      "tags": {
        "rationale": "By default, if no `--service-account-key-file` is specified to the apiserver, it uses the private key from the TLS serving certificate to verify service account tokens. To ensure that the keys for service account tokens could be rotated as needed, a separate public/private key pair should be used for signing service account tokens. Hence, the public key should be specified to the apiserver with `--service-account-key-file`.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--service-account-key-file` argument exists and is set as appropriate.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--service-account-key-file=<filename>\"`:\n\n  `KUBE_API_ARGS=\"--service-account-key-file=<filename>\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "3",
          "6.1"
        ],
        "cis_rid": "1.1.26",
        "cis_level": 1,
        "nist": [
          "CM-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.26' do\n  title 'Ensure that the --service-account-key-file argument is set as appropriate (Scored)'\n  desc \"Explicitly set a service account public key file for service accounts on the apiserver.\"\n  impact 1.0\n\n  tag rationale: \"By default, if no `--service-account-key-file` is specified to the apiserver, it uses the private key from the TLS serving certificate to verify service account tokens. To ensure that the keys for service account tokens could be rotated as needed, a separate public/private key pair should be used for signing service account tokens. Hence, the public key should be specified to the apiserver with `--service-account-key-file`.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--service-account-key-file` argument exists and is set as appropriate.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--service-account-key-file=<filename>\\\"`:\n\n  `KUBE_API_ARGS=\\\"--service-account-key-file=<filename>\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['3', '6.1']\n  tag cis_rid: \"1.1.26\"\n  tag cis_level: 1\n  tag nist: ['CM-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'Kubernetes issues 24167', url: 'https://github.com/kubernetes/kubernetes/issues/24167'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--service-account-key-file=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 938
      },
      "id": "cis-kubernetes-benchmark-1.1.26"
    },
    {
      "title": "Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate (Scored)",
      "desc": "etcd should be configured to make use of TLS encryption for client connections.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/security.html",
          "ref": "security.html"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the API server to identify itself to the etcd server using a client certificate and key.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--etcd-certfile` and `--etcd-keyfile` arguments exist and they are set as appropriate.",
        "fix": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to include `\"--etcd-certfile=<path/to/client- certificate-file>\"` and `\"--etcd-keyfile=<path/to/client-key-file>\"`:\n\n  `KUBE_API_ARGS=\"... --etcd-certfile=<path/to/client-certificate-file> --etcd- keyfile=<path/to/client-key-file> ...\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "9",
          "6.1"
        ],
        "cis_rid": "1.1.27",
        "cis_level": 1,
        "nist": [
          "SC-7",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.27' do\n  title 'Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate (Scored)'\n  desc \"etcd should be configured to make use of TLS encryption for client connections.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the API server to identify itself to the etcd server using a client certificate and key.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--etcd-certfile` and `--etcd-keyfile` arguments exist and they are set as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to include `\\\"--etcd-certfile=<path/to/client- certificate-file>\\\"` and `\\\"--etcd-keyfile=<path/to/client-key-file>\\\"`:\n\n  `KUBE_API_ARGS=\\\"... --etcd-certfile=<path/to/client-certificate-file> --etcd- keyfile=<path/to/client-key-file> ...\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['9', '6.1']\n  tag cis_rid: \"1.1.27\"\n  tag cis_level: 1\n  tag nist: ['SC-7', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'security.html', url: 'https://coreos.com/etcd/docs/latest/op-guide/security.html'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--etcd-certfile=/) }\n    it { should match(/--etcd-keyfile=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 973
      },
      "id": "cis-kubernetes-benchmark-1.1.27"
    },
    {
      "title": "Ensure that the admission control policy is set to ServiceAccount (Scored)",
      "desc": "Automate service accounts management.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/admission-controllers/#serviceaccount",
          "ref": "ServiceAccount"
        },
        {
          "url": "https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/",
          "ref": "Configure-Service-Account"
        }
      ],
      "tags": {
        "rationale": "When you create a pod, if you do not specify a service account, it is automatically assigned the `default` service account in the same namespace. You should create your own service account and let the API server manage its security tokens.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `ServiceAccount`.",
        "fix": "Follow the documentation and create ServiceAccount objects as per your environment. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\"--admission- control=...,ServiceAccount,...\"`:\n\n  `KUBE_ADMISSION_CONTROL=\"--admission-control=...,ServiceAccount,...\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "16",
          "6.1"
        ],
        "cis_rid": "1.1.28",
        "cis_level": 1,
        "nist": [
          "AC-2",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.28' do\n  title 'Ensure that the admission control policy is set to ServiceAccount (Scored)'\n  desc \"Automate service accounts management.\"\n  impact 1.0\n\n  tag rationale: \"When you create a pod, if you do not specify a service account, it is automatically assigned the `default` service account in the same namespace. You should create your own service account and let the API server manage its security tokens.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `ServiceAccount`.\"\n\n  tag fix: \"Follow the documentation and create ServiceAccount objects as per your environment. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\\\"--admission- control=...,ServiceAccount,...\\\"`:\n\n  `KUBE_ADMISSION_CONTROL=\\\"--admission-control=...,ServiceAccount,...\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['16', '6.1']\n  tag cis_rid: \"1.1.28\"\n  tag cis_level: 1\n  tag nist: ['AC-2', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'ServiceAccount', url: 'https://kubernetes.io/docs/admin/admission-controllers/#serviceaccount'\n  ref 'Configure-Service-Account', url: 'https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--admission-control=(?:.)*ServiceAccount,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 1009
      },
      "id": "cis-kubernetes-benchmark-1.1.28"
    },
    {
      "title": "Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Scored)",
      "desc": "Setup TLS connection on the API server.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "http://rootsquash.com/2016/05/10/securing-the-kubernetes-api/",
          "ref": "securing-the-kubernetes-api"
        },
        {
          "url": "https://github.com/kelseyhightower/docker-kubernetes-tls-guide",
          "ref": "docker-kubernetes-tls-guide"
        }
      ],
      "tags": {
        "rationale": "API server communication contains sensitive parameters that should remain encrypted in transit. Configure the API server to serve only HTTPS traffic.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--tls-cert-file` and `--tls-private-key-file` arguments exist and they are set as appropriate.",
        "fix": "Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to include `\"--tls-cert-file=<path/to/tls-certificate- file>\"` and `\"--tls-private-key-file=<path/to/tls-key-file>\"`:\n\n  `KUBE_API_ARGS=\"--tls-cert-file=<path/to/tls-certificate-file> --tls-private- key-file=<path/to/tls-key-file>\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "1.1.29",
        "cis_level": 1,
        "nist": [
          "SC-8",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.29' do\n  title 'Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Scored)'\n  desc \"Setup TLS connection on the API server.\"\n  impact 1.0\n\n  tag rationale: \"API server communication contains sensitive parameters that should remain encrypted in transit. Configure the API server to serve only HTTPS traffic.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--tls-cert-file` and `--tls-private-key-file` arguments exist and they are set as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to include `\\\"--tls-cert-file=<path/to/tls-certificate- file>\\\"` and `\\\"--tls-private-key-file=<path/to/tls-key-file>\\\"`:\n\n  `KUBE_API_ARGS=\\\"--tls-cert-file=<path/to/tls-certificate-file> --tls-private- key-file=<path/to/tls-key-file>\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"1.1.29\"\n  tag cis_level: 1\n  tag nist: ['SC-8', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'securing-the-kubernetes-api', url: 'http://rootsquash.com/2016/05/10/securing-the-kubernetes-api/'\n  ref 'docker-kubernetes-tls-guide', url: 'https://github.com/kelseyhightower/docker-kubernetes-tls-guide'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--tls-cert-file=/) }\n    it { should match(/--tls-private-key-file=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 1045
      },
      "id": "cis-kubernetes-benchmark-1.1.29"
    },
    {
      "title": "Ensure that the --client-ca-file argument is set as appropriate (Scored)",
      "desc": "Setup TLS connection on the API server.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "http://rootsquash.com/2016/05/10/securing-the-kubernetes-api/",
          "ref": "securing-the-kubernetes-api"
        },
        {
          "url": "https://github.com/kelseyhightower/docker-kubernetes-tls-guide",
          "ref": "docker-kubernetes-tls-guide"
        }
      ],
      "tags": {
        "rationale": "API server communication contains sensitive parameters that should remain encrypted in transit. Configure the API server to serve only HTTPS traffic. If `--client-ca-file` argument is set, any request presenting a client certificate signed by one of the authorities in the `client-ca-file` is authenticated with an identity corresponding to the CommonName of the client certificate.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--client-ca-file` argument exists and it is set as appropriate.",
        "fix": "Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to include `\"--client-ca-file=<path/to/client-ca-file>\"`:\n\n  `KUBE_API_ARGS=\"--client-ca-file=<path/to/client-ca-file>\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "1.1.30",
        "cis_level": 1,
        "nist": [
          "SC-8",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.30' do\n  title 'Ensure that the --client-ca-file argument is set as appropriate (Scored)'\n  desc \"Setup TLS connection on the API server.\"\n  impact 1.0\n\n  tag rationale: \"API server communication contains sensitive parameters that should remain encrypted in transit. Configure the API server to serve only HTTPS traffic. If `--client-ca-file` argument is set, any request presenting a client certificate signed by one of the authorities in the `client-ca-file` is authenticated with an identity corresponding to the CommonName of the client certificate.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--client-ca-file` argument exists and it is set as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and set up the TLS connection on the apiserver. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to include `\\\"--client-ca-file=<path/to/client-ca-file>\\\"`:\n\n  `KUBE_API_ARGS=\\\"--client-ca-file=<path/to/client-ca-file>\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"1.1.30\"\n  tag cis_level: 1\n  tag nist: ['SC-8', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'securing-the-kubernetes-api', url: 'http://rootsquash.com/2016/05/10/securing-the-kubernetes-api/'\n  ref 'docker-kubernetes-tls-guide', url: 'https://github.com/kelseyhightower/docker-kubernetes-tls-guide'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--client-ca-file=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 1082
      },
      "id": "cis-kubernetes-benchmark-1.1.30"
    },
    {
      "title": "Ensure that the --etcd-cafile argument is set as appropriate (Scored)",
      "desc": "etcd should be configured to make use of TLS encryption for client connections.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/security.html",
          "ref": "security.html"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the API server to identify itself to the etcd server using a SSL Certificate Authority file.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--etcd-cafile` argument exists and it is set as appropriate.",
        "fix": "Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to include `\"--etcd-cafile=<path/to/ca-file>\"`:\n\n  `KUBE_API_ARGS=\"--etcd-cafile=<path/to/ca-file>\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "1.1.31",
        "cis_level": 1,
        "nist": [
          "SC-8",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.31' do\n  title 'Ensure that the --etcd-cafile argument is set as appropriate (Scored)'\n  desc \"etcd should be configured to make use of TLS encryption for client connections.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the API server to identify itself to the etcd server using a SSL Certificate Authority file.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--etcd-cafile` argument exists and it is set as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and set up the TLS connection between the apiserver and etcd. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to include `\\\"--etcd-cafile=<path/to/ca-file>\\\"`:\n\n  `KUBE_API_ARGS=\\\"--etcd-cafile=<path/to/ca-file>\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"1.1.31\"\n  tag cis_level: 1\n  tag nist: ['SC-8', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'security.html', url: 'https://coreos.com/etcd/docs/latest/op-guide/security.html'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--etcd-cafile/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 1118
      },
      "id": "cis-kubernetes-benchmark-1.1.31"
    },
    {
      "title": "Ensure that the --authorization-mode argument is set to Node (Scored)",
      "desc": "Restrict kubelet nodes to reading only objects associated with them.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/authorization/node/",
          "ref": "node"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/pull/46076",
          "ref": "kubernetes pull 46076"
        },
        {
          "url": "https://acotten.com/post/kube17-security",
          "ref": "kube17-security"
        }
      ],
      "tags": {
        "rationale": "The Node authorization mode only allows kubelets to read Secret, ConfigMap, PersistentVolume, and PersistentVolumeClaim objects associated with their nodes.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--authorization-mode` argument exists and is set to a value to include `Node`.",
        "fix": "Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to a value to include `--authorization-mode=Node`. One such example could be as below:\n\n  `KUBE_API_ARGS=\"--authorization-mode=Node,RBAC\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "9.1",
          "6.1"
        ],
        "cis_rid": "1.1.32",
        "cis_level": 1,
        "nist": [
          "CM-7 (1)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.32' do\n  title 'Ensure that the --authorization-mode argument is set to Node (Scored)'\n  desc \"Restrict kubelet nodes to reading only objects associated with them.\"\n  impact 1.0\n\n  tag rationale: \"The Node authorization mode only allows kubelets to read Secret, ConfigMap, PersistentVolume, and PersistentVolumeClaim objects associated with their nodes.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--authorization-mode` argument exists and is set to a value to include `Node`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to a value to include `--authorization-mode=Node`. One such example could be as below:\n\n  `KUBE_API_ARGS=\\\"--authorization-mode=Node,RBAC\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['9.1', '6.1']\n  tag cis_rid: \"1.1.32\"\n  tag cis_level: 1\n  tag nist: ['CM-7 (1)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'node', url: 'https://kubernetes.io/docs/admin/authorization/node/'\n  ref 'kubernetes pull 46076', url: 'https://github.com/kubernetes/kubernetes/pull/46076'\n  ref 'kube17-security', url: 'https://acotten.com/post/kube17-security'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--authorization-mode=(?:.)*Node,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 1153
      },
      "id": "cis-kubernetes-benchmark-1.1.32"
    },
    {
      "title": "Ensure that the admission control policy is set to NodeRestriction (Scored)",
      "desc": "Limit the Node and Pod objects that a kubelet could modify.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://kubernetes.io/docs/admin/admission-controllers/#noderestriction",
          "ref": "NodeRestriction"
        },
        {
          "url": "https://kubernetes.io/docs/admin/authorization/node/",
          "ref": "node"
        },
        {
          "url": "https://acotten.com/post/kube17-security",
          "ref": "kube17-security"
        }
      ],
      "tags": {
        "rationale": "Using the NodeRestriction plug-in ensures that the kubelet is restricted to the Node and Pod objects that it could modify as defined. Such kubelets will only be allowed to modify their own Node API object, and only modify Pod API objects that are bound to their node.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `NodeRestriction`.",
        "fix": "Follow the Kubernetes documentation and configure `NodeRestriction` plug-in on kubelets. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\"--admission- control=...,NodeRestriction,...\"`:\n\n  `KUBE_ADMISSION_CONTROL=\"--admission-control=...,NodeRestriction,...\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.1.33",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.33' do\n  title 'Ensure that the admission control policy is set to NodeRestriction (Scored)'\n  desc \"Limit the Node and Pod objects that a kubelet could modify.\"\n  impact 1.0\n\n  tag rationale: \"Using the NodeRestriction plug-in ensures that the kubelet is restricted to the Node and Pod objects that it could modify as defined. Such kubelets will only be allowed to modify their own Node API object, and only modify Pod API objects that are bound to their node.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `NodeRestriction`.\"\n\n  tag fix: \"Follow the Kubernetes documentation and configure `NodeRestriction` plug-in on kubelets. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_ADMISSION_CONTROL` parameter to `\\\"--admission- control=...,NodeRestriction,...\\\"`:\n\n  `KUBE_ADMISSION_CONTROL=\\\"--admission-control=...,NodeRestriction,...\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.1.33\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'NodeRestriction', url: 'https://kubernetes.io/docs/admin/admission-controllers/#noderestriction'\n  ref 'node', url: 'https://kubernetes.io/docs/admin/authorization/node/'\n  ref 'kube17-security', url: 'https://acotten.com/post/kube17-security'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--admission-control=(?:.)*NodeRestriction,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 1190
      },
      "id": "cis-kubernetes-benchmark-1.1.33"
    },
    {
      "title": "Ensure that the --experimental-encryption-provider-config argument is set as appropriate (Scored)",
      "desc": "Encrypt etcd key-value store.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/",
          "ref": "encrypt-data"
        },
        {
          "url": "https://acotten.com/post/kube17-security",
          "ref": "kube17-security"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/features/issues/92",
          "ref": "Kubernetes issues 92"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted at rest to avoid any disclosures.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--experimental-encryption-provider-config` argument is set to a `EncryptionConfig` file. Additionally, ensure that the `EncryptionConfig` file has all the desired `resources` covered especially any secrets.",
        "fix": "Follow the Kubernetes documentation and configure a `EncryptionConfig` file. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--experimental-encryption-provider- config=</path/to/EncryptionConfig/File>\"`:\n\n  `KUBE_API_ARGS=\"--experimental-encryption-provider- config=</path/to/EncryptionConfig/File>\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`",
        "cis_family": [
          "14.5",
          "6.1"
        ],
        "cis_rid": "1.1.34",
        "cis_level": 1,
        "nist": [
          "SC-28",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.34' do\n  title 'Ensure that the --experimental-encryption-provider-config argument is set as appropriate (Scored)'\n  desc \"Encrypt etcd key-value store.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted at rest to avoid any disclosures.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Verify that the `--experimental-encryption-provider-config` argument is set to a `EncryptionConfig` file. Additionally, ensure that the `EncryptionConfig` file has all the desired `resources` covered especially any secrets.\"\n\n  tag fix: \"Follow the Kubernetes documentation and configure a `EncryptionConfig` file. Then, edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--experimental-encryption-provider- config=</path/to/EncryptionConfig/File>\\\"`:\n\n  `KUBE_API_ARGS=\\\"--experimental-encryption-provider- config=</path/to/EncryptionConfig/File>\\\"`\n\n  Based on your system, restart the `kube-apiserver` service. For example:\n\n  `systemctl restart kube-apiserver.service`\"\n\n  tag cis_family: ['14.5', '6.1']\n  tag cis_rid: \"1.1.34\"\n  tag cis_level: 1\n  tag nist: ['SC-28', '4']\n  tag severity: \"medium\"\n\n  ref 'encrypt-data', url: 'https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/'\n  ref 'kube17-security', url: 'https://acotten.com/post/kube17-security'\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'Kubernetes issues 92', url: 'https://github.com/kubernetes/features/issues/92'\n\n  describe processes('kube-apiserver').commands.to_s do\n    it { should match(/--experimental-encryption-provider-config=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 1227
      },
      "id": "cis-kubernetes-benchmark-1.1.34"
    },
    {
      "title": "Ensure that the encryption provider is set to aescbc (Scored)",
      "desc": "Use aescbc encryption provider.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/",
          "ref": "encrypt-data"
        },
        {
          "url": "https://acotten.com/post/kube17-security",
          "ref": "kube17-security"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/features/issues/92",
          "ref": "Kubernetes issues 92"
        },
        {
          "url": "https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/#providers",
          "ref": "providers"
        }
      ],
      "tags": {
        "rationale": "aescbc is currently the strongest encryption provider, It should be preferred over other providers.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Get the `EncryptionConfig` file set for `--experimental-encryption-provider-config` argument. Verify that the `aescbc` encryption provider is used for all the desired `resources`.",
        "fix": "Follow the Kubernetes documentation and configure a `EncryptionConfig` file. In this file, choose `aescbc` as the encryption provider.\n\n  For example,\n\n  `kind: EncryptionConfig\n  apiVersion: v1\n  resources:\n    - resources:\n      - secrets\n      providers:\n      - aescbc:\n        keys:\n        - name: key1\n          secret: <32-byte base64-encoded secret>`",
        "cis_family": [
          "14.5",
          "6.1"
        ],
        "cis_rid": "1.1.35",
        "cis_level": 1,
        "nist": [
          "SC-28",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.1.35' do\n  title 'Ensure that the encryption provider is set to aescbc (Scored)'\n  desc \"Use aescbc encryption provider.\"\n  impact 1.0\n\n  tag rationale: \"aescbc is currently the strongest encryption provider, It should be preferred over other providers.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-apiserver`\n\n  Get the `EncryptionConfig` file set for `--experimental-encryption-provider-config` argument. Verify that the `aescbc` encryption provider is used for all the desired `resources`.\"\n\n  tag fix: \"Follow the Kubernetes documentation and configure a `EncryptionConfig` file. In this file, choose `aescbc` as the encryption provider.\n\n  For example,\n\n  `kind: EncryptionConfig\n  apiVersion: v1\n  resources:\n    - resources:\n      - secrets\n      providers:\n      - aescbc:\n        keys:\n        - name: key1\n          secret: <32-byte base64-encoded secret>`\"\n\n  tag cis_family: ['14.5', '6.1']\n  tag cis_rid: \"1.1.35\"\n  tag cis_level: 1\n  tag nist: ['SC-28', '4']\n  tag severity: \"medium\"\n\n  ref 'encrypt-data', url: 'https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/'\n  ref 'kube17-security', url: 'https://acotten.com/post/kube17-security'\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n  ref 'Kubernetes issues 92', url: 'https://github.com/kubernetes/features/issues/92'\n  ref 'providers', url: 'https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/#providers'\n\n  describe 'cis-kubernetes-benchmark-1.1.35' do\n    skip 'Review the `EncryptionConfig` file and verify that `aescbc` is used as the encryption provider.'\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_1_master_node_api_server.rb",
        "line": 1264
      },
      "id": "cis-kubernetes-benchmark-1.1.35"
    },
    {
      "title": "Ensure that the --profiling argument is set to false (Scored)",
      "desc": "Disable profiling, if not needed.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-scheduler/",
          "ref": "kube-scheduler"
        },
        {
          "url": "https://github.com/kubernetes/community/blob/master/contributors/devel/profiling.md",
          "ref": "profiling.md"
        }
      ],
      "tags": {
        "rationale": "Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-scheduler`\n\n  Verify that the `--profiling` argument is set to `false`.",
        "fix": "Edit the `/etc/kubernetes/scheduler` file on the master node and set the `KUBE_SCHEDULER_ARGS` parameter to `\"--profiling=false\"`:\n\n  `KUBE_SCHEDULER_ARGS=\"--profiling=false\"`\n\n  Based on your system, restart the `kube-scheduler` service. For example:\n\n  `systemctl restart kube-scheduler.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.2.1",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.2.1' do\n  title 'Ensure that the --profiling argument is set to false (Scored)'\n  desc \"Disable profiling, if not needed.\"\n  impact 1.0\n\n  tag rationale: \"Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-scheduler`\n\n  Verify that the `--profiling` argument is set to `false`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/scheduler` file on the master node and set the `KUBE_SCHEDULER_ARGS` parameter to `\\\"--profiling=false\\\"`:\n\n  `KUBE_SCHEDULER_ARGS=\\\"--profiling=false\\\"`\n\n  Based on your system, restart the `kube-scheduler` service. For example:\n\n  `systemctl restart kube-scheduler.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.2.1\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-scheduler', url: 'https://kubernetes.io/docs/admin/kube-scheduler/'\n  ref 'profiling.md', url: 'https://github.com/kubernetes/community/blob/master/contributors/devel/profiling.md'\n\n  describe processes('kube-scheduler').commands.to_s do\n    it { should match(/--profiling=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_2_master_node_scheduler.rb",
        "line": 24
      },
      "id": "cis-kubernetes-benchmark-1.2.1"
    },
    {
      "title": "Ensure that the --terminated-pod-gc-threshold argument is set as appropriate (Scored)",
      "desc": "Activate garbage collector on pod termination, as appropriate.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-controller-manager/",
          "ref": "kube-controller-manager"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/28484",
          "ref": "Kubernetes issues 28484"
        }
      ],
      "tags": {
        "rationale": "Garbage collection is important to ensure sufficient resource availability and avoiding degraded performance and availability. In the worst case, the system might crash or just be unusable for a long period of time. The current setting for garbage collection is 12,500 terminated pods which might be too high for your system to sustain. Based on your system resources and tests, choose an appropriate threshold value to activate garbage collection.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that the `--terminated-pod-gc-threshold` argument is set as appropriate.",
        "fix": "Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to `\"--terminated-pod-gc- threshold=<appropriate-number>\"`:\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\"--terminated-pod-gc-threshold=10\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.3.1",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.3.1' do\n  title 'Ensure that the --terminated-pod-gc-threshold argument is set as appropriate (Scored)'\n  desc \"Activate garbage collector on pod termination, as appropriate.\"\n  impact 1.0\n\n  tag rationale: \"Garbage collection is important to ensure sufficient resource availability and avoiding degraded performance and availability. In the worst case, the system might crash or just be unusable for a long period of time. The current setting for garbage collection is 12,500 terminated pods which might be too high for your system to sustain. Based on your system resources and tests, choose an appropriate threshold value to activate garbage collection.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that the `--terminated-pod-gc-threshold` argument is set as appropriate.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to `\\\"--terminated-pod-gc- threshold=<appropriate-number>\\\"`:\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\\\"--terminated-pod-gc-threshold=10\\\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.3.1\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-controller-manager', url: 'https://kubernetes.io/docs/admin/kube-controller-manager/'\n  ref 'Kubernetes issues 28484', url: 'https://github.com/kubernetes/kubernetes/issues/28484'\n\n  describe processes('kube-controller-manager').commands.to_s do\n    it { should match(/--terminated-pod-gc-threshold=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_3_master_node_controller_manager.rb",
        "line": 24
      },
      "id": "cis-kubernetes-benchmark-1.3.1"
    },
    {
      "title": "Ensure that the --profiling argument is set to false (Scored)",
      "desc": "Disable profiling, if not needed.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-controller-manager/",
          "ref": "kube-controller-manager"
        },
        {
          "url": "https://github.com/kubernetes/community/blob/master/contributors/devel/profi ling.md",
          "ref": "profiling.md"
        }
      ],
      "tags": {
        "rationale": "Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that the `--profiling` argument is set to `false`.",
        "fix": "Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to `\"--profiling=false\"`:\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\"--profiling=false\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.3.2",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.3.2' do\n  title 'Ensure that the --profiling argument is set to false (Scored)'\n  desc \"Disable profiling, if not needed.\"\n  impact 1.0\n\n  tag rationale: \"Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that the `--profiling` argument is set to `false`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to `\\\"--profiling=false\\\"`:\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\\\"--profiling=false\\\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.3.2\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-controller-manager', url: 'https://kubernetes.io/docs/admin/kube-controller-manager/'\n  ref 'profiling.md', url: 'https://github.com/kubernetes/community/blob/master/contributors/devel/profi ling.md'\n\n  describe processes('kube-controller-manager').commands.to_s do\n    it { should match(/--profiling=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_3_master_node_controller_manager.rb",
        "line": 59
      },
      "id": "cis-kubernetes-benchmark-1.3.2"
    },
    {
      "title": "Ensure that the --use-service-account-credentials argument is set to true (Scored)",
      "desc": "Use individual service account credentials for each controller.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-controller-manager/",
          "ref": "kube-controller-manager"
        },
        {
          "url": "https://kubernetes.io/docs/admin/service-accounts-admin/",
          "ref": "service-accounts-admin"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/release-1.6/plugin/pkg/auth/authorizer/rbac/bootstrappolicy/testdata/controller-roles.yaml",
          "ref": "controller-roles.yaml"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/release-1.6/plugin/pkg/auth/authorizer/rbac/bootstrappolicy/testdata/controller-role-bindings.yaml",
          "ref": "controller-role-bindings.yaml"
        },
        {
          "url": "https://kubernetes.io/docs/admin/authorization/rbac/#controller-roles",
          "ref": "controller-roles"
        }
      ],
      "tags": {
        "rationale": "The controller manager creates a service account per controller in the `kube-system` namespace, generates a credential for it, and builds a dedicated API client with that service account credential for each controller loop to use. Setting the `--use-service-account-credentials` to `true` runs each control loop within the controller manager using a separate service account credential. When used in combination with RBAC, this ensures that the control loops run with the minimum permissions required to perform their intended tasks.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that the `--use-service-account-credentials` argument is set to `true`.",
        "fix": "Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to `--use-service-account- credentials=true`:\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\"--use-service-account-credentials=true\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.3.3",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.3.3' do\n  title 'Ensure that the --use-service-account-credentials argument is set to true (Scored)'\n  desc \"Use individual service account credentials for each controller.\"\n  impact 1.0\n\n  tag rationale: \"The controller manager creates a service account per controller in the `kube-system` namespace, generates a credential for it, and builds a dedicated API client with that service account credential for each controller loop to use. Setting the `--use-service-account-credentials` to `true` runs each control loop within the controller manager using a separate service account credential. When used in combination with RBAC, this ensures that the control loops run with the minimum permissions required to perform their intended tasks.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that the `--use-service-account-credentials` argument is set to `true`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to `--use-service-account- credentials=true`:\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\\\"--use-service-account-credentials=true\\\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.3.3\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-controller-manager', url: 'https://kubernetes.io/docs/admin/kube-controller-manager/'\n  ref 'service-accounts-admin', url: 'https://kubernetes.io/docs/admin/service-accounts-admin/'\n  ref 'controller-roles.yaml', url: 'https://github.com/kubernetes/kubernetes/blob/release-1.6/plugin/pkg/auth/authorizer/rbac/bootstrappolicy/testdata/controller-roles.yaml'\n  ref 'controller-role-bindings.yaml', url: 'https://github.com/kubernetes/kubernetes/blob/release-1.6/plugin/pkg/auth/authorizer/rbac/bootstrappolicy/testdata/controller-role-bindings.yaml'\n  ref 'controller-roles', url: 'https://kubernetes.io/docs/admin/authorization/rbac/#controller-roles'\n\n  describe processes('kube-controller-manager').commands.to_s do\n    it { should match(/--use-service-account-credentials=true/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_3_master_node_controller_manager.rb",
        "line": 94
      },
      "id": "cis-kubernetes-benchmark-1.3.3"
    },
    {
      "title": "Ensure that the --service-account-private-key-file argument is set as appropriate (Scored)",
      "desc": "Explicitly set a service account private key file for service accounts on the controller manager.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-controller-manager/",
          "ref": "kube-controller-manager"
        }
      ],
      "tags": {
        "rationale": "To ensure that keys for service account tokens can be rotated as needed, a separate public/private key pair should be used for signing service account tokens. The private key should be specified to the controller manager with `--service-account-private-key-file` as appropriate.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that the `--service-account-private-key-file` argument is set as appropriate.",
        "fix": "Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to `--service-account-private-key- file=<filename>`:\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\"--service-account-private-key-file=<filename>\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.3.4",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.3.4' do\n  title 'Ensure that the --service-account-private-key-file argument is set as appropriate (Scored)'\n  desc \"Explicitly set a service account private key file for service accounts on the controller manager.\"\n  impact 1.0\n\n  tag rationale: \"To ensure that keys for service account tokens can be rotated as needed, a separate public/private key pair should be used for signing service account tokens. The private key should be specified to the controller manager with `--service-account-private-key-file` as appropriate.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that the `--service-account-private-key-file` argument is set as appropriate.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to `--service-account-private-key- file=<filename>`:\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\\\"--service-account-private-key-file=<filename>\\\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.3.4\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-controller-manager', url: 'https://kubernetes.io/docs/admin/kube-controller-manager/'\n\n  describe processes('kube-controller-manager').commands.to_s do\n    it { should match(/--service-account-private-key-file=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_3_master_node_controller_manager.rb",
        "line": 132
      },
      "id": "cis-kubernetes-benchmark-1.3.4"
    },
    {
      "title": "Ensure that the --root-ca-file argument is set as appropriate (Scored)",
      "desc": "Allow pods to verify the API server's serving certificate before establishing connections.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-controller-manager/",
          "ref": "kube-controller-manager"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/11000",
          "ref": "Kubernetes issues 11000"
        }
      ],
      "tags": {
        "rationale": "Processes running within pods that need to contact the API server must verify the API server's serving certificate. Failing to do so could be a subject to man-in-the-middle attacks. Providing the root certificate for the API server's serving certificate to the controller manager with the `--root-ca-file` argument allows the controller manager to inject the trusted bundle into pods so that they can verify TLS connections to the API server.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that the `--root-ca-file` argument exists and is set to a certificate bundle file containing the root certificate for the API server's serving certificate.",
        "fix": "Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to include `--root-ca-file=<file>`:\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\"--root-ca-file=<file>\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "1.3.5",
        "cis_level": 1,
        "nist": [
          "SC-8",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.3.5' do\n  title 'Ensure that the --root-ca-file argument is set as appropriate (Scored)'\n  desc \"Allow pods to verify the API server's serving certificate before establishing connections.\"\n  impact 1.0\n\n  tag rationale: \"Processes running within pods that need to contact the API server must verify the API server's serving certificate. Failing to do so could be a subject to man-in-the-middle attacks. Providing the root certificate for the API server's serving certificate to the controller manager with the `--root-ca-file` argument allows the controller manager to inject the trusted bundle into pods so that they can verify TLS connections to the API server.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that the `--root-ca-file` argument exists and is set to a certificate bundle file containing the root certificate for the API server's serving certificate.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to include `--root-ca-file=<file>`:\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\\\"--root-ca-file=<file>\\\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"1.3.5\"\n  tag cis_level: 1\n  tag nist: ['SC-8', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-controller-manager', url: 'https://kubernetes.io/docs/admin/kube-controller-manager/'\n  ref 'Kubernetes issues 11000', url: 'https://github.com/kubernetes/kubernetes/issues/11000'\n\n  describe processes('kube-controller-manager').commands.to_s do\n    it { should match(/--root-ca-file=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_3_master_node_controller_manager.rb",
        "line": 166
      },
      "id": "cis-kubernetes-benchmark-1.3.5"
    },
    {
      "title": "Apply Security Context to Your Pods and Containers (Not Scored)",
      "desc": "Apply Security Context to Your Pods and Containers.",
      "impact": 0,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/concepts/policy/security-context/",
          "ref": "security-context"
        },
        {
          "url": "https://learn.cisecurity.org/benchmarks",
          "ref": "benchmarks"
        }
      ],
      "tags": {
        "rationale": "A security context defines the operating system security settings (uid, gid, capabilities, SELinux role, etc..) applied to a container. When designing your containers and pods, make sure that you configure the security context for your pods, containers, and volumes. A security context is a property defined in the deployment yaml. It controls the security parameters that will be assigned to the pod/container/volume. There are two levels of security context: pod level security context, and container level security context.",
        "check": "Review the pod definitions in your cluster and verify that you have security contexts defined as appropriate.",
        "fix": "Follow the Kubernetes documentation and apply security contexts to your pods. For a suggested list of security contexts, you may refer to the CIS Security Benchmark for Docker Containers.",
        "cis_family": [
          "3",
          "6.1"
        ],
        "cis_rid": "1.3.6",
        "cis_level": 1,
        "nist": [
          "CM-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.3.6' do\n  title 'Apply Security Context to Your Pods and Containers (Not Scored)'\n  desc \"Apply Security Context to Your Pods and Containers.\"\n  impact 0.0\n\n  tag rationale: \"A security context defines the operating system security settings (uid, gid, capabilities, SELinux role, etc..) applied to a container. When designing your containers and pods, make sure that you configure the security context for your pods, containers, and volumes. A security context is a property defined in the deployment yaml. It controls the security parameters that will be assigned to the pod/container/volume. There are two levels of security context: pod level security context, and container level security context.\"\n\n  tag check: \"Review the pod definitions in your cluster and verify that you have security contexts defined as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and apply security contexts to your pods. For a suggested list of security contexts, you may refer to the CIS Security Benchmark for Docker Containers.\"\n\n  tag cis_family: ['3', '6.1']\n  tag cis_rid: \"1.3.6\"\n  tag cis_level: 1\n  tag nist: ['CM-6', '4']\n  tag severity: \"medium\"\n\n  ref 'security-context', url: 'https://kubernetes.io/docs/concepts/policy/security-context/'\n  ref 'benchmarks', url: 'https://learn.cisecurity.org/benchmarks'\n\n  describe 'cis-kubernetes-benchmark-1.3.6' do\n    skip 'Review the pod definitions in your cluster and verify that you have security contexts defined as appropriate.'\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_3_master_node_controller_manager.rb",
        "line": 201
      },
      "id": "cis-kubernetes-benchmark-1.3.6"
    },
    {
      "title": "Ensure that the RotateKubeletServerCertificate argument is set to true (Scored)",
      "desc": "Enable kubelet server certificate rotation on controller-manager.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#approval-controller",
          "ref": "approval-controller"
        },
        {
          "url": "https://github.com/kubernetes/features/issues/267",
          "ref": "Kubernetes issues 267"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/pull/45059",
          "ref": "Kubernetes pull 45049"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kube-controller-manager/",
          "ref": "kube-controller-manager"
        }
      ],
      "tags": {
        "rationale": "RotateKubeletServerCertificate causes the kubelet to both request a serving certificate after bootstrapping its client credentials and rotate the certificate as its existing credentials expire. This automated periodic rotation ensures that the there are no downtimes due to expired certificates and thus addressing availability in the CIA security triad. Note: This recommendation only applies if you let kubelets get their certificates from the API server. In case your kubelet certificates come from an outside authority/tool (e.g. Vault) then you need to take care of rotation yourself.",
        "check": "Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that `RotateKubeletServerCertificate` argument exists and is set to `true`.",
        "fix": "Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to a value to include `\"--feature- gates=RotateKubeletServerCertificate=true\"`.\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\"--feature- gates=RotateKubeletServerCertificate=true\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "1.3.7",
        "cis_level": 1,
        "nist": [
          "SC-8",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.3.7' do\n  title 'Ensure that the RotateKubeletServerCertificate argument is set to true (Scored)'\n  desc \"Enable kubelet server certificate rotation on controller-manager.\"\n  impact 1.0\n\n  tag rationale: \"RotateKubeletServerCertificate causes the kubelet to both request a serving certificate after bootstrapping its client credentials and rotate the certificate as its existing credentials expire. This automated periodic rotation ensures that the there are no downtimes due to expired certificates and thus addressing availability in the CIA security triad. Note: This recommendation only applies if you let kubelets get their certificates from the API server. In case your kubelet certificates come from an outside authority/tool (e.g. Vault) then you need to take care of rotation yourself.\"\n\n  tag check: \"Run the following command on the master node:\n\n  `ps -ef | grep kube-controller-manager`\n\n  Verify that `RotateKubeletServerCertificate` argument exists and is set to `true`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/controller-manager` file on the master node and set the `KUBE_CONTROLLER_MANAGER_ARGS` parameter to a value to include `\\\"--feature- gates=RotateKubeletServerCertificate=true\\\"`.\n\n  `KUBE_CONTROLLER_MANAGER_ARGS=\\\"--feature- gates=RotateKubeletServerCertificate=true\\\"`\n\n  Based on your system, restart the `kube-controller-manager` service. For example:\n\n  `systemctl restart kube-controller-manager.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"1.3.7\"\n  tag cis_level: 1\n  tag nist: ['SC-8', '4']\n  tag severity: \"medium\"\n\n  ref 'approval-controller', url: 'https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#approval-controller'\n  ref 'Kubernetes issues 267', url: 'https://github.com/kubernetes/features/issues/267'\n  ref 'Kubernetes pull 45049', url: 'https://github.com/kubernetes/kubernetes/pull/45059'\n  ref 'kube-controller-manager', url: 'https://kubernetes.io/docs/admin/kube-controller-manager/'\n\n  describe processes('kube-controller-manager').commands.to_s do\n    it { should match(/--feature-gates=(?:.)*RotateKubeletServerCertificate=true,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_3_master_node_controller_manager.rb",
        "line": 226
      },
      "id": "cis-kubernetes-benchmark-1.3.7"
    },
    {
      "title": "Ensure that the apiserver file permissions are set to 644 or more restrictive (Scored)",
      "desc": "Ensure that the `apiserver` file has permissions of `644` or more restrictive.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "The `apiserver` file controls various parameters that set the behavior of the API server. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.",
        "check": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %a /etc/kubernetes/apiserver`\n\n  Verify that the permissions are `644` or more restrictive.",
        "fix": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chmod 644 /etc/kubernetes/apiserver`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.4.1",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.1' do\n  title 'Ensure that the apiserver file permissions are set to 644 or more restrictive (Scored)'\n  desc \"Ensure that the `apiserver` file has permissions of `644` or more restrictive.\"\n  impact 1.0\n\n  tag rationale: \"The `apiserver` file controls various parameters that set the behavior of the API server. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %a /etc/kubernetes/apiserver`\n\n  Verify that the permissions are `644` or more restrictive.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chmod 644 /etc/kubernetes/apiserver`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.4.1\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  only_if do\n    file('/etc/kubernetes/apiserver').exist?\n  end\n\n  describe file('/etc/kubernetes/apiserver').mode.to_s do\n    it { should match(/[0246][024][024]/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 20
      },
      "id": "cis-kubernetes-benchmark-1.4.1"
    },
    {
      "title": "Ensure that the apiserver file ownership is set to root:root (Scored)",
      "desc": "Ensure that the `apiserver` file ownership is set to `root:root`.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "The `apiserver` file controls various parameters that set the behavior of the API server. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.",
        "check": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/apiserver`\n\n  Verify that the ownership is set to `root:root`.",
        "fix": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chown root:root /etc/kubernetes/apiserver`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.4.2",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "high"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.2' do\n  title 'Ensure that the apiserver file ownership is set to root:root (Scored)'\n  desc \"Ensure that the `apiserver` file ownership is set to `root:root`.\"\n  impact 1.0\n\n  tag rationale: \"The `apiserver` file controls various parameters that set the behavior of the API server. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/apiserver`\n\n  Verify that the ownership is set to `root:root`.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chown root:root /etc/kubernetes/apiserver`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.4.2\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  only_if do\n    file('/etc/kubernetes/apiserver').exist?\n  end\n\n  describe file('/etc/kubernetes/apiserver') do\n    it { should be_owned_by 'root' }\n    it { should be_grouped_into 'root' }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 54
      },
      "id": "cis-kubernetes-benchmark-1.4.2"
    },
    {
      "title": "Ensure that the config file permissions are set to 644 or more restrictive (Scored)",
      "desc": "Ensure that the `config` file has permissions of `644` or more restrictive.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "The `config` file controls various parameters that set the behavior of various components of the master node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.",
        "check": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %a /etc/kubernetes/config`\n\n  Verify that the permissions are `644` or more restrictive.",
        "fix": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chmod 644 /etc/kubernetes/config`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.4.3",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.3' do\n  title 'Ensure that the config file permissions are set to 644 or more restrictive (Scored)'\n  desc \"Ensure that the `config` file has permissions of `644` or more restrictive.\"\n  impact 1.0\n\n  tag rationale: \"The `config` file controls various parameters that set the behavior of various components of the master node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %a /etc/kubernetes/config`\n\n  Verify that the permissions are `644` or more restrictive.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chmod 644 /etc/kubernetes/config`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.4.3\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  only_if do\n    file('/etc/kubernetes/config').exist?\n  end\n\n  describe file('/etc/kubernetes/config').mode.to_s do\n    it { should match(/[0246][024][024]/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 89
      },
      "id": "cis-kubernetes-benchmark-1.4.3"
    },
    {
      "title": "Ensure that the config file ownership is set to root:root (Scored)",
      "desc": "Ensure that the `config` file ownership is set to `root:root`.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "The `config` file controls various parameters that set the behavior of various components of the master node. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.",
        "check": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/config`\n\n  Verify that the ownership is set to `root:root`.",
        "fix": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chown root:root /etc/kubernetes/config`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.4.4",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.4' do\n  title 'Ensure that the config file ownership is set to root:root (Scored)'\n  desc \"Ensure that the `config` file ownership is set to `root:root`.\"\n  impact 1.0\n\n  tag rationale: \"The `config` file controls various parameters that set the behavior of various components of the master node. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/config`\n\n  Verify that the ownership is set to `root:root`.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chown root:root /etc/kubernetes/config`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.4.4\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  only_if do\n    file('/etc/kubernetes/config').exist?\n  end\n\n  describe file('/etc/kubernetes/config') do\n    it { should be_owned_by 'root' }\n    it { should be_grouped_into 'root' }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 123
      },
      "id": "cis-kubernetes-benchmark-1.4.4"
    },
    {
      "title": "Ensure that the scheduler file permissions are set to 644 or more restrictive (Scored)",
      "desc": "Ensure that the `scheduler` file has permissions of `644` or more restrictive.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "The `scheduler` file controls various parameters that set the behavior of the `kube-scheduler` service in the master node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.",
        "check": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %a /etc/kubernetes/scheduler`\n\n  Verify that the permissions are `644` or more restrictive.",
        "fix": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chmod 644 /etc/kubernetes/scheduler`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.4.5",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.5' do\n  title 'Ensure that the scheduler file permissions are set to 644 or more restrictive (Scored)'\n  desc \"Ensure that the `scheduler` file has permissions of `644` or more restrictive.\"\n  impact 1.0\n\n  tag rationale: \"The `scheduler` file controls various parameters that set the behavior of the `kube-scheduler` service in the master node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %a /etc/kubernetes/scheduler`\n\n  Verify that the permissions are `644` or more restrictive.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chmod 644 /etc/kubernetes/scheduler`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.4.5\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  only_if do\n    file('/etc/kubernetes/scheduler').exist?\n  end\n\n  describe file('/etc/kubernetes/scheduler').mode.to_s do\n    it { should match(/[0246][024][024]/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 158
      },
      "id": "cis-kubernetes-benchmark-1.4.5"
    },
    {
      "title": "Ensure that the scheduler file ownership is set to root:root (Scored)",
      "desc": "Ensure that the `scheduler` file ownership is set to `root:root`.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kube-apiserver/",
          "ref": "kube-apiserver"
        }
      ],
      "tags": {
        "rationale": "The `scheduler` file controls various parameters that set the behavior of the `kube-scheduler` service in the master node. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.",
        "check": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/scheduler`\n\n  Verify that the ownership is set to `root:root`.",
        "fix": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chown root:root /etc/kubernetes/scheduler`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.4.6",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.6' do\n  title 'Ensure that the scheduler file ownership is set to root:root (Scored)'\n  desc \"Ensure that the `scheduler` file ownership is set to `root:root`.\"\n  impact 1.0\n\n  tag rationale: \"The `scheduler` file controls various parameters that set the behavior of the `kube-scheduler` service in the master node. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/scheduler`\n\n  Verify that the ownership is set to `root:root`.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chown root:root /etc/kubernetes/scheduler`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.4.6\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kube-apiserver', url: 'https://kubernetes.io/docs/admin/kube-apiserver/'\n\n  only_if do\n    file('/etc/kubernetes/scheduler').exist?\n  end\n\n  describe file('/etc/kubernetes/scheduler') do\n    it { should be_owned_by 'root' }\n    it { should be_grouped_into 'root' }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 192
      },
      "id": "cis-kubernetes-benchmark-1.4.6"
    },
    {
      "title": "Ensure that the etcd.conf file permissions are set to 644 or more restrictive (Scored)",
      "desc": "Ensure that the `etcd.conf` file has permissions of `644` or more restrictive.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd",
          "ref": "coreos-etcd"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        }
      ],
      "tags": {
        "rationale": "The `etcd.conf` file controls various parameters that set the behavior of the `etcd` service in the master node. etcd is a highly-available key value store which Kubernetes uses for persistent storage of all of its REST API object. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.",
        "check": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %a /etc/etcd/etcd.conf`\n\n  Verify that the permissions are `644` or more restrictive.",
        "fix": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chmod 644 /etc/etcd/etcd.conf`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.4.7",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.7' do\n  title 'Ensure that the etcd.conf file permissions are set to 644 or more restrictive (Scored)'\n  desc \"Ensure that the `etcd.conf` file has permissions of `644` or more restrictive.\"\n  impact 1.0\n\n  tag rationale: \"The `etcd.conf` file controls various parameters that set the behavior of the `etcd` service in the master node. etcd is a highly-available key value store which Kubernetes uses for persistent storage of all of its REST API object. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %a /etc/etcd/etcd.conf`\n\n  Verify that the permissions are `644` or more restrictive.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chmod 644 /etc/etcd/etcd.conf`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.4.7\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'coreos-etcd', url: 'https://coreos.com/etcd'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n\n  only_if do\n    file('/etc/etcd/etcd.conf').exist?\n  end\n\n  describe file('/etc/etcd/etcd.conf').mode.to_s do\n    it { should match(/[0246][024][024]/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 227
      },
      "id": "cis-kubernetes-benchmark-1.4.7"
    },
    {
      "title": "Ensure that the etcd.conf file ownership is set to root:root (Scored)",
      "desc": "Ensure that the `etcd.conf` file ownership is set to `root:root`.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd",
          "ref": "coreos-etcd"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        }
      ],
      "tags": {
        "rationale": "The `etcd.conf` file controls various parameters that set the behavior of the `etcd` service in the master node. etcd is a highly-available key value store which Kubernetes uses for persistent storage of all of its REST API object. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.",
        "check": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %U:%G /etc/etcd/etcd.conf`\n\n  Verify that the ownership is set to `root:root`.",
        "fix": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chown root:root /etc/etcd/etcd.conf`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.4.8",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.8' do\n  title 'Ensure that the etcd.conf file ownership is set to root:root (Scored)'\n  desc \"Ensure that the `etcd.conf` file ownership is set to `root:root`.\"\n  impact 1.0\n\n  tag rationale: \"The `etcd.conf` file controls various parameters that set the behavior of the `etcd` service in the master node. etcd is a highly-available key value store which Kubernetes uses for persistent storage of all of its REST API object. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %U:%G /etc/etcd/etcd.conf`\n\n  Verify that the ownership is set to `root:root`.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chown root:root /etc/etcd/etcd.conf`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.4.8\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'coreos-etcd', url: 'https://coreos.com/etcd'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n\n  only_if do\n    file('/etc/etcd/etcd.conf').exist?\n  end\n\n  describe file('/etc/etcd/etcd.conf') do\n    it { should be_owned_by 'root' }\n    it { should be_grouped_into 'root' }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 262
      },
      "id": "cis-kubernetes-benchmark-1.4.8"
    },
    {
      "title": "Ensure that the flanneld file permissions are set to 644 or more restrictive (Scored)",
      "desc": "Ensure that the `flanneld` file has permissions of `644` or more restrictive.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/flannel/docs/latest/",
          "ref": "coreos-flannel"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/cluster-administration/networking/#flannel",
          "ref": "flannel"
        }
      ],
      "tags": {
        "rationale": "The `flanneld` file controls various parameters that set the behavior of the `flanneld` service in the master node. Flannel is one of the various options for a simple overlay network. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.",
        "check": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %a /etc/sysconfig/flanneld`\n\n  Verify that the permissions are `644` or more restrictive.\n\n  Note: Flannel is an optional component of Kubernetes. If you are not using Flannel then this requirement is not applicable. If you are using any other option for configuring your networking, please extend this recommendation to cover important configuration files as appropriate.",
        "fix": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chmod 644 /etc/sysconfig/flanneld`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.4.9",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.9' do\n  title 'Ensure that the flanneld file permissions are set to 644 or more restrictive (Scored)'\n  desc \"Ensure that the `flanneld` file has permissions of `644` or more restrictive.\"\n  impact 1.0\n\n  tag rationale: \"The `flanneld` file controls various parameters that set the behavior of the `flanneld` service in the master node. Flannel is one of the various options for a simple overlay network. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %a /etc/sysconfig/flanneld`\n\n  Verify that the permissions are `644` or more restrictive.\n\n  Note: Flannel is an optional component of Kubernetes. If you are not using Flannel then this requirement is not applicable. If you are using any other option for configuring your networking, please extend this recommendation to cover important configuration files as appropriate.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `chmod 644 /etc/sysconfig/flanneld`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.4.9\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'coreos-flannel', url: 'https://coreos.com/flannel/docs/latest/'\n  ref 'flannel', url: 'https://kubernetes.io/docs/concepts/cluster-administration/networking/#flannel'\n\n  only_if do\n    file('/etc/sysconfig/flanneld').exist?\n  end\n\n  describe file('/etc/sysconfig/flanneld').mode.to_s do\n    it { should match(/[0246][024][024]/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 298
      },
      "id": "cis-kubernetes-benchmark-1.4.9"
    },
    {
      "title": "Ensure that the flanneld file ownership is set to root:root (Scored)",
      "desc": "Ensure that the `flanneld` file ownership is set to `root:root`.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/flannel/docs/latest/",
          "ref": "coreos-flannel"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/cluster-administration/networking/#flannel",
          "ref": "flannel"
        }
      ],
      "tags": {
        "rationale": "The `flanneld` file controls various parameters that set the behavior of the `flanneld` service in the master node. Flannel is one of the various options for a simple overlay network. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.",
        "check": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %U:%G /etc/sysconfig/flanneld`\n\n  Verify that the ownership is set to `root:root`.\n\n  Note: Flannel is an optional component of Kubernetes. If you are not using Flannel then this requirement is not applicable. If you are using any other option for configuring your networking, please extend this recommendation to cover important configuration files as appropriate.",
        "fix": "Run the below command (based on the file location on your system) on the master node. For example,\n\n  chown root:root /etc/sysconfig/flanneld",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.4.10",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.10' do\n  title 'Ensure that the flanneld file ownership is set to root:root (Scored)'\n  desc \"Ensure that the `flanneld` file ownership is set to `root:root`.\"\n  impact 1.0\n\n  tag rationale: \"The `flanneld` file controls various parameters that set the behavior of the `flanneld` service in the master node. Flannel is one of the various options for a simple overlay network. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  `stat -c %U:%G /etc/sysconfig/flanneld`\n\n  Verify that the ownership is set to `root:root`.\n\n  Note: Flannel is an optional component of Kubernetes. If you are not using Flannel then this requirement is not applicable. If you are using any other option for configuring your networking, please extend this recommendation to cover important configuration files as appropriate.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the master node. For example,\n\n  chown root:root /etc/sysconfig/flanneld\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.4.10\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'coreos-flannel', url: 'https://coreos.com/flannel/docs/latest/'\n  ref 'flannel', url: 'https://kubernetes.io/docs/concepts/cluster-administration/networking/#flannel'\n\n  only_if do\n    file('/etc/sysconfig/flanneld').exist?\n  end\n\n  describe file('/etc/sysconfig/flanneld') do\n    it { should be_owned_by 'root' }\n    it { should be_grouped_into 'root' }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 335
      },
      "id": "cis-kubernetes-benchmark-1.4.10"
    },
    {
      "title": "Ensure that the etcd data directory permissions are set to 700 or more restrictive (Scored)",
      "desc": "Ensure that the etcd data directory has permissions of `700` or more restrictive.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#data-dir",
          "ref": "data-dir"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. This data directory should be protected from any unauthorized reads or writes. It should not be readable or writable by any group members or the world.",
        "check": "On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n  `ps -ef | grep etcd`\n\n  Run the below command (based on the etcd data directory found above). For example,\n\n  `stat -c %a /var/lib/etcd/default.etcd`\n\n  Verify that the permissions are `700` or more restrictive.",
        "fix": "On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n  `ps -ef | grep etcd`\n\n  Run the below command (based on the etcd data directory found above). For example,\n\n  `chmod 700 /var/lib/etcd/default.etcd`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.4.11",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.11' do\n  title 'Ensure that the etcd data directory permissions are set to 700 or more restrictive (Scored)'\n  desc \"Ensure that the etcd data directory has permissions of `700` or more restrictive.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. This data directory should be protected from any unauthorized reads or writes. It should not be readable or writable by any group members or the world.\"\n\n  tag check: \"On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n  `ps -ef | grep etcd`\n\n  Run the below command (based on the etcd data directory found above). For example,\n\n  `stat -c %a /var/lib/etcd/default.etcd`\n\n  Verify that the permissions are `700` or more restrictive.\"\n\n  tag fix: \"On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n  `ps -ef | grep etcd`\n\n  Run the below command (based on the etcd data directory found above). For example,\n\n  `chmod 700 /var/lib/etcd/default.etcd`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.4.11\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'data-dir', url: 'https://coreos.com/etcd/docs/latest/op-guide/configuration.html#data-dir'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n\n  etcd_process = processes(Regexp.new(%r{/usr/bin/etcd}))\n  data_dir = ''\n\n  catch(:stop) do\n    if etcd_process.exists?\n      if (data_dir = etcd_process.commands.to_s.scan(/--data-dir=(\\S+)/).last)\n        data_dir = data_dir.first\n        throw :stop\n      end\n\n      if (data_dir = file(\"/proc/#{etcd_process.pids.first}/environ\").content.split(\"\\0\").select { |i| i[/^ETCD_DATA_DIR/] }.first.split('=').last)\n        throw :stop\n      end\n    end\n  end\n\n  if !data_dir.empty?\n    describe file(data_dir).mode.to_s do\n      it { should match(/[01234567]00/) }\n    end\n  else\n    describe 'cis-kubernetes-benchmark-1.4.11' do\n      skip 'etcd data directory not found'\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 373
      },
      "id": "cis-kubernetes-benchmark-1.4.11"
    },
    {
      "title": "Ensure that the etcd data directory ownership is set to etcd:etcd (Scored)",
      "desc": "Ensure that the etcd data directory ownership is set to `etcd:etcd`.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#data-dir",
          "ref": "data-dir"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. This data directory should be protected from any unauthorized reads or writes. It should be owned by `etcd:etcd`.",
        "check": "On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n  `ps -ef | grep etcd`\n\n  Run the below command (based on the etcd data directory found above). For example,\n\n  `stat -c %U:%G /var/lib/etcd/default.etcd`\n\n  Verify that the ownership is set to `etcd:etcd`.",
        "fix": "On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n  `ps -ef | grep etcd`\n\n  Run the below command (based on the etcd data directory found above). For example,\n\n  `chown etcd:etcd /var/lib/etcd/default.etcd`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.4.12",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.4.12' do\n  title 'Ensure that the etcd data directory ownership is set to etcd:etcd (Scored)'\n  desc \"Ensure that the etcd data directory ownership is set to `etcd:etcd`.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. This data directory should be protected from any unauthorized reads or writes. It should be owned by `etcd:etcd`.\"\n\n  tag check: \"On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n  `ps -ef | grep etcd`\n\n  Run the below command (based on the etcd data directory found above). For example,\n\n  `stat -c %U:%G /var/lib/etcd/default.etcd`\n\n  Verify that the ownership is set to `etcd:etcd`.\"\n\n  tag fix: \"On the etcd server node, get the etcd data directory, passed as an argument `--data-dir`, from the below command:\n\n  `ps -ef | grep etcd`\n\n  Run the below command (based on the etcd data directory found above). For example,\n\n  `chown etcd:etcd /var/lib/etcd/default.etcd`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.4.12\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'data-dir', url: 'https://coreos.com/etcd/docs/latest/op-guide/configuration.html#data-dir'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n\n  etcd_process = processes(Regexp.new(%r{/usr/bin/etcd}))\n  data_dir = ''\n\n  catch(:stop) do\n    if etcd_process.exists?\n      if (data_dir = etcd_process.commands.to_s.scan(/--data-dir=(\\S+)/).last)\n        data_dir = data_dir.first\n        throw :stop\n      end\n\n      if (data_dir = file(\"/proc/#{etcd_process.pids.first}/environ\").content.split(\"\\0\").select { |i| i[/^ETCD_DATA_DIR/] }.first.split('=').last)\n        throw :stop\n      end\n    end\n  end\n\n  if !data_dir.empty?\n    describe file(data_dir).mode.to_s do\n      it { should be_owned_by 'etcd' }\n      it { should be_grouped_into 'etcd' }\n    end\n  else\n    describe 'cis-kubernetes-benchmark-1.4.12' do\n      skip 'etcd data directory not found'\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_4_master_node_configuration_files.rb",
        "line": 434
      },
      "id": "cis-kubernetes-benchmark-1.4.12"
    },
    {
      "title": "Ensure that the --cert-file and --key-file arguments are set as appropriate (Scored)",
      "desc": "Configure TLS encryption for the etcd service.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/security.html",
          "ref": "security.html"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted in transit.",
        "check": "Run the following command on the etcd server node\n\n  `ps -ef | grep etcd`\n\n  Verify that the `--cert-file` and the `--key-file` arguments are set as appropriate.",
        "fix": "",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "1.5.1",
        "cis_level": 1,
        "nist": [
          "SC-8",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.5.1' do\n  title 'Ensure that the --cert-file and --key-file arguments are set as appropriate (Scored)'\n  desc \"Configure TLS encryption for the etcd service.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted in transit.\"\n\n  tag check: \"Run the following command on the etcd server node\n\n  `ps -ef | grep etcd`\n\n  Verify that the `--cert-file` and the `--key-file` arguments are set as appropriate.\"\n\n  tag fix: \"\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"1.5.1\"\n  tag cis_level: 1\n  tag nist: ['SC-8', '4']\n  tag severity: \"medium\"\n\n  ref 'security.html', url: 'https://coreos.com/etcd/docs/latest/op-guide/security.html'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n\n  describe.one do\n    describe etcd_process.commands.to_s do\n      it { should match(/--cert-file=/) }\n    end\n\n    describe etcd_env_vars do\n      its(:ETCD_CERT_FILE) { should_not be_empty }\n    end\n  end\n\n  describe.one do\n    describe etcd_process.commands.to_s do\n      it { should match(/--key-file=/) }\n    end\n\n    describe etcd_env_vars do\n      its(:ETCD_KEY_FILE) { should_not be_empty }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_5_master_node_etcd.rb",
        "line": 30
      },
      "id": "cis-kubernetes-benchmark-1.5.1"
    },
    {
      "title": "Ensure that the --client-cert-auth argument is set to true (Scored)",
      "desc": "Enable client authentication on etcd service.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/security.html",
          "ref": "security.html"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        },
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#client-cert-auth",
          "ref": "client-cert-auth"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should not be available to unauthenticated clients. You should enable the client authentication via valid certificates to secure the access to the etcd service.",
        "check": "Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that the `--client-cert-auth` argument is set to `true`.",
        "fix": "Edit the etcd envrironment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and set the `ETCD_CLIENT_CERT_AUTH` parameter to `\"true\"`:\n\n  `ETCD_CLIENT_CERT_AUTH=\"true\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi- user.target.wants/etcd.service`) and configure the startup parameter for `--client-cert-auth` and set it to `\"${ETCD_CLIENT_CERT_AUTH}\"`:\n\n  `ExecStart=/bin/bash -c \"GOMAXPROCS=$(nproc) /usr/bin/etcd --name=\"${ETCD_NAME}\" --data-dir=\"${ETCD_DATA_DIR}\" --listen-client- urls=\"${ETCD_LISTEN_CLIENT_URLS}\" --client-cert- auth=\"${ETCD_CLIENT_CERT_AUTH}\"\"`\n\n  Based on your system, reload the daemon and restart the `etcd` service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.5.2",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.5.2' do\n  title 'Ensure that the --client-cert-auth argument is set to true (Scored)'\n  desc \"Enable client authentication on etcd service.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should not be available to unauthenticated clients. You should enable the client authentication via valid certificates to secure the access to the etcd service.\"\n\n  tag check: \"Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that the `--client-cert-auth` argument is set to `true`.\"\n\n  tag fix: \"Edit the etcd envrironment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and set the `ETCD_CLIENT_CERT_AUTH` parameter to `\\\"true\\\"`:\n\n  `ETCD_CLIENT_CERT_AUTH=\\\"true\\\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi- user.target.wants/etcd.service`) and configure the startup parameter for `--client-cert-auth` and set it to `\\\"${ETCD_CLIENT_CERT_AUTH}\\\"`:\n\n  `ExecStart=/bin/bash -c \\\"GOMAXPROCS=$(nproc) /usr/bin/etcd --name=\\\"${ETCD_NAME}\\\" --data-dir=\\\"${ETCD_DATA_DIR}\\\" --listen-client- urls=\\\"${ETCD_LISTEN_CLIENT_URLS}\\\" --client-cert- auth=\\\"${ETCD_CLIENT_CERT_AUTH}\\\"\\\"`\n\n  Based on your system, reload the daemon and restart the `etcd` service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.5.2\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'security.html', url: 'https://coreos.com/etcd/docs/latest/op-guide/security.html'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n  ref 'client-cert-auth', url: 'https://coreos.com/etcd/docs/latest/op-guide/configuration.html#client-cert-auth'\n\n  describe.one do\n    describe etcd_process.commands.to_s do\n      it { should match(/--client-cert-auth=true/) }\n    end\n\n    describe etcd_env_vars do\n      its(:ETCD_CLIENT_CERT_AUTH) { should_not be_empty }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_5_master_node_etcd.rb",
        "line": 75
      },
      "id": "cis-kubernetes-benchmark-1.5.2"
    },
    {
      "title": "Ensure that the --auto-tls argument is not set to true (Scored)",
      "desc": "Do not use self-signed certificates for TLS.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/security.html",
          "ref": "security.html"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        },
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#auto-tls",
          "ref": "auto-tls"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should not be available to unauthenticated clients. You should enable the client authentication via valid certificates to secure the access to the etcd service.",
        "check": "Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that if the `--auto-tls` argument exists, it is not set to `true`.",
        "fix": "Edit the etcd environment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and comment out the `ETCD_AUTO_TLS` parameter.\n\n  `#ETCD_AUTO_TLS=\"true\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi-user.target.wants/etcd.service`) and remove the startup parameter for `--auto-tls`. Based on your system, reload the daemon and restart the `etcd` service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "1.5.3",
        "cis_level": 1,
        "nist": [
          "SC-8",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.5.3' do\n  title 'Ensure that the --auto-tls argument is not set to true (Scored)'\n  desc \"Do not use self-signed certificates for TLS.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should not be available to unauthenticated clients. You should enable the client authentication via valid certificates to secure the access to the etcd service.\"\n\n  tag check: \"Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that if the `--auto-tls` argument exists, it is not set to `true`.\"\n\n  tag fix: \"Edit the etcd environment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and comment out the `ETCD_AUTO_TLS` parameter.\n\n  `#ETCD_AUTO_TLS=\\\"true\\\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi-user.target.wants/etcd.service`) and remove the startup parameter for `--auto-tls`. Based on your system, reload the daemon and restart the `etcd` service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"1.5.3\"\n  tag cis_level: 1\n  tag nist: ['SC-8', '4']\n  tag severity: \"medium\"\n\n  ref 'security.html', url: 'https://coreos.com/etcd/docs/latest/op-guide/security.html'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n  ref 'auto-tls', url: 'https://coreos.com/etcd/docs/latest/op-guide/configuration.html#auto-tls'\n\n  describe etcd_process.commands.to_s do\n    it { should_not match(/--auto-tls=true/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_5_master_node_etcd.rb",
        "line": 122
      },
      "id": "cis-kubernetes-benchmark-1.5.3"
    },
    {
      "title": "Ensure that the --peer-cert-file and --peer-key-file arguments are set as appropriate (Scored)",
      "desc": "etcd should be configured to make use of TLS encryption for peer connections.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/security.html",
          "ref": "security.html"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted in transit and also amongst peers in the etcd clusters.",
        "check": "Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that the `--peer-cert-file` and `--peer-key-file` arguments are set as appropriate.\n\n  Note: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.",
        "fix": "Follow the etcd service documentation and configure peer TLS encryption as appropriate for your etcd cluster.",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "1.5.4",
        "cis_level": 1,
        "nist": [
          "SC-8",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.5.4' do\n  title 'Ensure that the --peer-cert-file and --peer-key-file arguments are set as appropriate (Scored)'\n  desc \"etcd should be configured to make use of TLS encryption for peer connections.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be encrypted in transit and also amongst peers in the etcd clusters.\"\n\n  tag check: \"Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that the `--peer-cert-file` and `--peer-key-file` arguments are set as appropriate.\n\n  Note: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.\"\n\n  tag fix: \"Follow the etcd service documentation and configure peer TLS encryption as appropriate for your etcd cluster.\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"1.5.4\"\n  tag cis_level: 1\n  tag nist: ['SC-8', '4']\n  tag severity: \"medium\"\n\n  ref 'security.html', url: 'https://coreos.com/etcd/docs/latest/op-guide/security.html'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n\n  describe.one do\n    describe etcd_process.commands.to_s do\n      it { should match(/--peer-cert-file=/) }\n    end\n\n    describe etcd_env_vars do\n      its(:ETCD_PEER_CERT_FILE) { should_not be_empty }\n    end\n  end\n\n  describe.one do\n    describe etcd_process.commands.to_s do\n      it { should match(/--peer-key-file=/) }\n    end\n\n    describe etcd_env_vars do\n      its(:ETCD_PEER_KEY_FILE) { should_not be_empty }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_5_master_node_etcd.rb",
        "line": 159
      },
      "id": "cis-kubernetes-benchmark-1.5.4"
    },
    {
      "title": "Ensure that the --peer-client-cert-auth argument is set to true (Scored)",
      "desc": "etcd should be configured for peer authentication.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/security.html",
          "ref": "security.html"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        },
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#peer-client-cert-auth",
          "ref": "peer-client-cert-auth"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be accessible only by authenticated etcd peers in the etcd cluster.",
        "check": "Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that the `--peer-client-cert-auth` argument is set to `true`.\n\n  Note: This recommendation is applicable only for etcd clusters. If you are using only one\n  etcd server in your environment then this recommendation is not applicable.",
        "fix": "Edit the etcd environment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and set the `ETCD_PEER_CLIENT_CERT_AUTH` parameter to `\"true\"`:\n\n  `ETCD_PEER_CLIENT_CERT_AUTH=\"true\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi-user.target.wants/etcd.service`) and configure the startup parameter for `--peer- client-cert-auth` and set it to `\"${ETCD_PEER_CLIENT_CERT_AUTH}\"`:\n\n  `ExecStart=/bin/bash -c \"GOMAXPROCS=$(nproc) /usr/bin/etcd -- name=\"${ETCD_NAME}\" --data-dir=\"${ETCD_DATA_DIR}\"--listen-client- urls=\"${ETCD_LISTEN_CLIENT_URLS}\" --peer-client-cert- auth=\"${ETCD_PEER_CLIENT_CERT_AUTH}\"\"`\n\n  Based on your system, reload the daemon and restart the etcd service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`",
        "cis_family": [
          "14.4",
          "6.1"
        ],
        "cis_rid": "1.5.5",
        "cis_level": 1,
        "nist": [
          "AC-3 (3)",
          "Rev_4"
        ],
        "severity": "low"
      },
      "code": "control 'cis-kubernetes-benchmark-1.5.5' do\n  title 'Ensure that the --peer-client-cert-auth argument is set to true (Scored)'\n  desc \"etcd should be configured for peer authentication.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be accessible only by authenticated etcd peers in the etcd cluster.\"\n\n  tag check: \"Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that the `--peer-client-cert-auth` argument is set to `true`.\n\n  Note: This recommendation is applicable only for etcd clusters. If you are using only one\n  etcd server in your environment then this recommendation is not applicable.\"\n\n  tag fix: \"Edit the etcd environment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and set the `ETCD_PEER_CLIENT_CERT_AUTH` parameter to `\\\"true\\\"`:\n\n  `ETCD_PEER_CLIENT_CERT_AUTH=\\\"true\\\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi-user.target.wants/etcd.service`) and configure the startup parameter for `--peer- client-cert-auth` and set it to `\\\"${ETCD_PEER_CLIENT_CERT_AUTH}\\\"`:\n\n  `ExecStart=/bin/bash -c \\\"GOMAXPROCS=$(nproc) /usr/bin/etcd -- name=\\\"${ETCD_NAME}\\\" --data-dir=\\\"${ETCD_DATA_DIR}\\\"--listen-client- urls=\\\"${ETCD_LISTEN_CLIENT_URLS}\\\" --peer-client-cert- auth=\\\"${ETCD_PEER_CLIENT_CERT_AUTH}\\\"\\\"`\n\n  Based on your system, reload the daemon and restart the etcd service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`\"\n\n  tag cis_family: ['14.4', '6.1']\n  tag cis_rid: \"1.5.5\"\n  tag cis_level: 1\n  tag nist: ['AC-3 (3)', '4']\n  tag severity: \"medium\"\n\n  ref 'security.html', url: 'https://coreos.com/etcd/docs/latest/op-guide/security.html'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n  ref 'peer-client-cert-auth', url: 'https://coreos.com/etcd/docs/latest/op-guide/configuration.html#peer-client-cert-auth'\n\n  describe.one do\n    describe etcd_process.commands.to_s do\n      it { should match(/--peer-client-cert-auth=true/) }\n    end\n\n    describe etcd_env_vars do\n      its(:ETCD_PEER_CLIENT_CERT_AUTH) { should_not be_empty }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_5_master_node_etcd.rb",
        "line": 206
      },
      "id": "cis-kubernetes-benchmark-1.5.5"
    },
    {
      "title": "Ensure that the --peer-auto-tls argument is not set to true (Scored)",
      "desc": "Do not use automatically generated self-signed certificates for TLS connections between peers.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/security.html",
          "ref": "security.html"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        },
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#peer-auto-tls",
          "ref": "peer-auto-tls"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be accessible only by authenticated etcd peers in the etcd cluster. Hence, do not use self-signed certificates for authentication.",
        "check": "Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that if the `--peer-auto-tls` argument exists, it is not set to `true`. Note: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.",
        "fix": "Edit the etcd environment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and comment out the `ETCD_PEER_AUTO_TLS` parameter:\n\n  `#ETCD_PEER_AUTO_TLS=\"true\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi-user.target.wants/etcd.service`) and remove the startup parameter for `--peer-auto- tls`. Based on your system, reload the daemon and restart the etcd service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.5.6",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.5.6' do\n  title 'Ensure that the --peer-auto-tls argument is not set to true (Scored)'\n  desc \"Do not use automatically generated self-signed certificates for TLS connections between peers.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be accessible only by authenticated etcd peers in the etcd cluster. Hence, do not use self-signed certificates for authentication.\"\n\n  tag check: \"Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that if the `--peer-auto-tls` argument exists, it is not set to `true`. Note: This recommendation is applicable only for etcd clusters. If you are using only one etcd server in your environment then this recommendation is not applicable.\"\n\n  tag fix: \"Edit the etcd environment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and comment out the `ETCD_PEER_AUTO_TLS` parameter:\n\n  `#ETCD_PEER_AUTO_TLS=\\\"true\\\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi-user.target.wants/etcd.service`) and remove the startup parameter for `--peer-auto- tls`. Based on your system, reload the daemon and restart the etcd service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.5.6\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'security.html', url: 'https://coreos.com/etcd/docs/latest/op-guide/security.html'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n  ref 'peer-auto-tls', url: 'https://coreos.com/etcd/docs/latest/op-guide/configuration.html#peer-auto-tls'\n\n  describe etcd_process.commands.to_s do\n    it { should_not match(/--peer-auto-tls=true/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_5_master_node_etcd.rb",
        "line": 256
      },
      "id": "cis-kubernetes-benchmark-1.5.6"
    },
    {
      "title": "Ensure that the --wal-dir argument is set as appropriate (Scored)",
      "desc": "Store etcd logs separately from etcd data.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        },
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#wal-dir",
          "ref": "wal-dir"
        },
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#data-dir",
          "ref": "data-dir"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should not be mixed with log data. Keeping the log data separate from the etcd data also ensures that those two types of data could individually be safeguarded. Also, you could use a centralized and remote log directory for persistent logging. Additionally, this separation also helps to avoid IO competition between logging and other IO operations.",
        "check": "Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that `--wal-dir` argument exists, and it is set as appropriate. At the minimum, it should not be set to the same directory as set for `--data-dir` argument.",
        "fix": "Edit the etcd environment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and set the `ETCD_WAL_DIR` parameter as appropriate:\n\n  `ETCD_WAL_DIR=\"<dir-name>\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi-user.target.wants/etcd.service`) and configure the startup parameter for `--wal-dir` and set it to `\"${ETCD_WAL_DIR}\"`:\n\n  `ExecStart=/bin/bash -c \"GOMAXPROCS=$(nproc) /usr/bin/etcd -- name=\"${ETCD_NAME}\" --data-dir=\"${ETCD_DATA_DIR}\" --listen-client- urls=\"${ETCD_LISTEN_CLIENT_URLS}\" --wal-dir=\"${ETCD_WAL_DIR}\"\"`\n\n  Based on your system, reload the daemon and restart the etcd service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.5.7",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.5.7' do\n  title 'Ensure that the --wal-dir argument is set as appropriate (Scored)'\n  desc \"Store etcd logs separately from etcd data.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should not be mixed with log data. Keeping the log data separate from the etcd data also ensures that those two types of data could individually be safeguarded. Also, you could use a centralized and remote log directory for persistent logging. Additionally, this separation also helps to avoid IO competition between logging and other IO operations.\"\n\n  tag check: \"Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that `--wal-dir` argument exists, and it is set as appropriate. At the minimum, it should not be set to the same directory as set for `--data-dir` argument.\"\n\n  tag fix: \"Edit the etcd environment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and set the `ETCD_WAL_DIR` parameter as appropriate:\n\n  `ETCD_WAL_DIR=\\\"<dir-name>\\\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi-user.target.wants/etcd.service`) and configure the startup parameter for `--wal-dir` and set it to `\\\"${ETCD_WAL_DIR}\\\"`:\n\n  `ExecStart=/bin/bash -c \\\"GOMAXPROCS=$(nproc) /usr/bin/etcd -- name=\\\"${ETCD_NAME}\\\" --data-dir=\\\"${ETCD_DATA_DIR}\\\" --listen-client- urls=\\\"${ETCD_LISTEN_CLIENT_URLS}\\\" --wal-dir=\\\"${ETCD_WAL_DIR}\\\"\\\"`\n\n  Based on your system, reload the daemon and restart the etcd service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.5.7\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n  ref 'wal-dir', url: 'https://coreos.com/etcd/docs/latest/op-guide/configuration.html#wal-dir'\n  ref 'data-dir', url: 'https://coreos.com/etcd/docs/latest/op-guide/configuration.html#data-dir'\n\n  wal_dir = ''\n\n  catch(:stop) do\n    if etcd_process.exists?\n      if (wal_dir = etcd_process.commands.to_s.scan(/--data-dir=(\\S+)/).last)\n        wal_dir = wal_dir.first\n        throw :stop\n      end\n\n      if (wal_dir = etcd_env_vars.ETCD_WAL_DIR)\n        throw :stop\n      end\n    end\n  end\n\n  if !wal_dir.empty?\n    describe file(wal_dir).mode.to_s do\n      it { should be_owned_by 'etcd' }\n      it { should be_grouped_into 'etcd' }\n    end\n  else\n    describe 'cis-kubernetes-benchmark-1.5.7' do\n      skip 'WAL directory not found'\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_5_master_node_etcd.rb",
        "line": 293
      },
      "id": "cis-kubernetes-benchmark-1.5.7"
    },
    {
      "title": "Ensure that the --max-wals argument is set to 0 (Scored)",
      "desc": "Do not auto rotate logs.",
      "impact": 1,
      "refs": [
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/configuration.html#max-wals",
          "ref": "max-wals"
        },
        {
          "url": "https://kubernetes.io/docs/admin/etcd/",
          "ref": "kubernetes-etcd"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. You should avoid automatic log rotation and instead safeguard the logs in a centralized repository or through a separate log management system.",
        "check": "Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that `--max-wals` argument exists and it is set to `0`.",
        "fix": "Edit the etcd environment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and set the `ETCD_MAX_WALS` parameter to `0`:\n\n  `ETCD_MAX_WALS=\"0\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi-user.target.wants/etcd.service`) and configure the startup parameter for `--max-wals` and set it to `\"${ETCD_MAX_WALS}\"`:\n\n  `ExecStart=/bin/bash -c \"GOMAXPROCS=$(nproc) /usr/bin/etcd --name=\"${ETCD_NAME}\" --data-dir=\"${ETCD_DATA_DIR}\" --listen-client- urls=\"${ETCD_LISTEN_CLIENT_URLS}\" --max-walsr=\"${ETCD_MAX_WALS}\"\"`\n\n  Based on your system, reload the daemon and restart the etcd service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`",
        "cis_family": [
          "6",
          "6.1"
        ],
        "cis_rid": "1.5.8",
        "cis_level": 1,
        "nist": [
          "AU-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.5.8' do\n  title 'Ensure that the --max-wals argument is set to 0 (Scored)'\n  desc \"Do not auto rotate logs.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. You should avoid automatic log rotation and instead safeguard the logs in a centralized repository or through a separate log management system.\"\n\n  tag check: \"Run the following command on the etcd server node:\n\n  `ps -ef | grep etcd`\n\n  Verify that `--max-wals` argument exists and it is set to `0`.\"\n\n  tag fix: \"Edit the etcd environment file (for example, `/etc/etcd/etcd.conf`) on the etcd server node and set the `ETCD_MAX_WALS` parameter to `0`:\n\n  `ETCD_MAX_WALS=\\\"0\\\"`\n\n  Edit the etcd startup file (for example, `/etc/systemd/system/multi-user.target.wants/etcd.service`) and configure the startup parameter for `--max-wals` and set it to `\\\"${ETCD_MAX_WALS}\\\"`:\n\n  `ExecStart=/bin/bash -c \\\"GOMAXPROCS=$(nproc) /usr/bin/etcd --name=\\\"${ETCD_NAME}\\\" --data-dir=\\\"${ETCD_DATA_DIR}\\\" --listen-client- urls=\\\"${ETCD_LISTEN_CLIENT_URLS}\\\" --max-walsr=\\\"${ETCD_MAX_WALS}\\\"\\\"`\n\n  Based on your system, reload the daemon and restart the etcd service. For example,\n\n  `systemctl daemon-reload\n  systemctl restart etcd.service`\"\n\n  tag cis_family: ['6', '6.1']\n  tag cis_rid: \"1.5.8\"\n  tag cis_level: 1\n  tag nist: ['AU-6', '4']\n  tag severity: \"medium\"\n\n  ref 'max-wals', url: 'https://coreos.com/etcd/docs/latest/op-guide/configuration.html#max-wals'\n  ref 'kubernetes-etcd', url: 'https://kubernetes.io/docs/admin/etcd/'\n\n  describe.one do\n    describe etcd_process.commands.to_s do\n      it { should match(/--max-wals=0/) }\n    end\n\n    describe etcd_env_vars do\n      its(:ETCD_MAX_WALS) { should eq '0' }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_5_master_node_etcd.rb",
        "line": 356
      },
      "id": "cis-kubernetes-benchmark-1.5.8"
    },
    {
      "title": "Ensure that a unique Certificate Authority is used for etcd (Not Scored)",
      "desc": "Use a different certificate authority for etcd from the one used for Kubernetes.",
      "impact": 0,
      "refs": [
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/security.html",
          "ref": "security.html"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. Its access should be restricted to specifically designated clients and peers only. Authentication to etcd is based on whether the certificate presented was issued by a trusted certificate authority. There is no checking of certificate attributes such as common name or subject alternative name. As such, if any attackers were able to gain access to any certificate issued by the trusted certificate authority, they would be able to gain full access to the etcd database.",
        "check": "Review the CA used by the etcd environment and ensure that it does not match the CA certificate used by Kubernetes.\n\n    Run the following command on the etcd server node:\n\n    `ps -ef | grep etcd`\n\n    Review the file referenced by the `--trusted-ca-file` argument and ensure that the referenced CA is not the same one as is used for management of the overall Kubernetes cluster.",
        "fix": "Follow the etcd documentation and create a dedicated certificate authority setup for the etcd service.",
        "cis_family": [
          "9",
          "6.1"
        ],
        "cis_rid": "1.5.9",
        "cis_level": 2,
        "nist": [
          "SC-7",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "  control 'cis-kubernetes-benchmark-1.5.9' do\n    title 'Ensure that a unique Certificate Authority is used for etcd (Not Scored)'\n    desc \"Use a different certificate authority for etcd from the one used for Kubernetes.\"\n    impact 0.0\n\n    tag rationale: \"etcd is a highly available key-value store used by Kubernetes deployments for persistent storage of all of its REST API objects. Its access should be restricted to specifically designated clients and peers only. Authentication to etcd is based on whether the certificate presented was issued by a trusted certificate authority. There is no checking of certificate attributes such as common name or subject alternative name. As such, if any attackers were able to gain access to any certificate issued by the trusted certificate authority, they would be able to gain full access to the etcd database.\"\n\n    tag check: \"Review the CA used by the etcd environment and ensure that it does not match the CA certificate used by Kubernetes.\n\n    Run the following command on the etcd server node:\n\n    `ps -ef | grep etcd`\n\n    Review the file referenced by the `--trusted-ca-file` argument and ensure that the referenced CA is not the same one as is used for management of the overall Kubernetes cluster.\"\n\n    tag fix: \"Follow the etcd documentation and create a dedicated certificate authority setup for the etcd service.\"\n\n    tag cis_family: ['9', '6.1']\n    tag cis_rid: \"1.5.9\"\n    tag cis_level: 2\n    tag nist: ['SC-7', '4']\n  tag severity: \"medium\"\n\n    ref 'security.html', url: 'https://coreos.com/etcd/docs/latest/op-guide/security.html'\n\n    describe 'cis-kubernetes-benchmark-1.5.9' do\n      skip 'Review if the CA used for etcd is different from the one used for Kubernetes'\n    end\n  end\n",
      "source_location": {
        "ref": "./controls/1_5_master_node_etcd.rb",
        "line": 403
      },
      "id": "cis-kubernetes-benchmark-1.5.9"
    },
    {
      "title": "Ensure that the cluster-admin role is only used where required (Not Scored)",
      "desc": "The RBAC role `cluster-admin` provides wide-ranging powers over the environment and should be used only where and when needed.",
      "impact": 0,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/authorization/rbac/#user-facing-roles",
          "ref": "user-facing-roles"
        }
      ],
      "tags": {
        "rationale": "Kubernetes provides a set of default roles where RBAC is used. Some of these roles such as `cluster-admin` provide wide-ranging privileges which should only be applied where absolutely necessary. Roles such as `cluster-admin` allow super-user access to perform any action on any resource. When used in a `ClusterRoleBinding`, it gives full control over every resource in the cluster and in all namespaces. When used in a `RoleBinding`, it gives full control over every resource in the rolebinding's namespace, including the namespace itself.",
        "check": "Obtain a list of the principals who have access to the `cluster-admin` role by reviewing the `clusterrolebinding` output for each role binding that has access to the `cluster-admin` role.\n\n  `kubectl get clusterrolebindings -o=custom-columns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].name`\n\n  Review each principal listed and ensure that cluster-admin privilege is required for it.",
        "fix": "Remove any unneeded `clusterrolebindings`:\n\n  `kubectl delete clusterrolebinding [name]`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "1.6.1",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.6.1' do\n  title 'Ensure that the cluster-admin role is only used where required (Not Scored)'\n  desc \"The RBAC role `cluster-admin` provides wide-ranging powers over the environment and should be used only where and when needed.\"\n  impact 0.0\n\n  tag rationale: \"Kubernetes provides a set of default roles where RBAC is used. Some of these roles such as `cluster-admin` provide wide-ranging privileges which should only be applied where absolutely necessary. Roles such as `cluster-admin` allow super-user access to perform any action on any resource. When used in a `ClusterRoleBinding`, it gives full control over every resource in the cluster and in all namespaces. When used in a `RoleBinding`, it gives full control over every resource in the rolebinding's namespace, including the namespace itself.\"\n\n  tag check: \"Obtain a list of the principals who have access to the `cluster-admin` role by reviewing the `clusterrolebinding` output for each role binding that has access to the `cluster-admin` role.\n\n  `kubectl get clusterrolebindings -o=custom-columns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].name`\n\n  Review each principal listed and ensure that cluster-admin privilege is required for it.\"\n\n  tag fix: \"Remove any unneeded `clusterrolebindings`:\n\n  `kubectl delete clusterrolebinding [name]`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"1.6.1\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'user-facing-roles', url: 'https://kubernetes.io/docs/admin/authorization/rbac/#user-facing-roles'\n\n  describe 'cis-kubernetes-benchmark-1.6.1' do\n    skip 'Review the output of `kubectl get clusterrolebindings -o=custom-columns=NAME:.metadata.name,ROLE:.roleRef.name,SUBJECT:.subjects[*].name` and ensure the listed principals require `cluster-admin` privileges.'\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_6_master_node_general_security_primitives.rb",
        "line": 22
      },
      "id": "cis-kubernetes-benchmark-1.6.1"
    },
    {
      "title": "Create Pod Security Policies for your cluster (Not Scored)",
      "desc": "Create and enforce Pod Security Policies for your cluster.",
      "impact": 0,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/concepts/policy/pod-security-policy/",
          "ref": "pod-security-policy"
        },
        {
          "url": "https://benchmarks.cisecurity.org/downloads/browse/index.cfm?category=benchmarks.servers.virtualization.docker",
          "ref": "benchmarks.servers.virtualization.docker"
        }
      ],
      "tags": {
        "rationale": "A Pod Security Policy is a cluster-level resource that controls the actions that a pod can perform and what it has the ability to access. The `PodSecurityPolicy` objects define a set of conditions that a pod must run with in order to be accepted into the system. Pod Security Policies are comprised of settings and strategies that control the security features a pod has access to and hence this must be used to control pod access permissions.",
        "check": "Run the below command and review the Pod Security Policies enforced on the cluster.\n\n  `kubectl get psp`\n\n  Ensure that these policies are configured as per your security requirements.",
        "fix": "Follow the documentation and create and enforce Pod Security Policies for your cluster. Additionally, you could refer the \"CIS Security Benchmark for Docker\" and follow the suggested Pod Security Policies for your environment.",
        "cis_family": [
          "3",
          "6.1"
        ],
        "cis_rid": "1.6.2",
        "cis_level": 1,
        "nist": [
          "CM-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.6.2' do\n  title 'Create Pod Security Policies for your cluster (Not Scored)'\n  desc \"Create and enforce Pod Security Policies for your cluster.\"\n  impact 0.0\n\n  tag rationale: \"A Pod Security Policy is a cluster-level resource that controls the actions that a pod can perform and what it has the ability to access. The `PodSecurityPolicy` objects define a set of conditions that a pod must run with in order to be accepted into the system. Pod Security Policies are comprised of settings and strategies that control the security features a pod has access to and hence this must be used to control pod access permissions.\"\n\n  tag check: \"Run the below command and review the Pod Security Policies enforced on the cluster.\n\n  `kubectl get psp`\n\n  Ensure that these policies are configured as per your security requirements.\"\n\n  tag fix: \"Follow the documentation and create and enforce Pod Security Policies for your cluster. Additionally, you could refer the \\\"CIS Security Benchmark for Docker\\\" and follow the suggested Pod Security Policies for your environment.\"\n\n  tag cis_family: ['3', '6.1']\n  tag cis_rid: \"1.6.2\"\n  tag cis_level: 1\n  tag nist: ['CM-6', '4']\n  tag severity: \"medium\"\n\n  ref 'pod-security-policy', url: 'https://kubernetes.io/docs/concepts/policy/pod-security-policy/'\n  ref 'benchmarks.servers.virtualization.docker', url: 'https://benchmarks.cisecurity.org/downloads/browse/index.cfm?category=benchmarks.servers.virtualization.docker'\n\n  describe 'cis-kubernetes-benchmark-1.6.2' do\n    skip 'Review the output of `kubectl get psp` and ensure policies are configured per your security requirements.'\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_6_master_node_general_security_primitives.rb",
        "line": 52
      },
      "id": "cis-kubernetes-benchmark-1.6.2"
    },
    {
      "title": "Create administrative boundaries between resources using namespaces (Not Scored)",
      "desc": "Use namespaces to isolate your Kubernetes objects.",
      "impact": 0,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/concepts/overview/working-with- objects/namespaces/",
          "ref": "namespaces"
        },
        {
          "url": "http://blog.kubernetes.io/2016/08/security-best-practices-kubernetes-deployment.html",
          "ref": "security-best-practices-kubernetes-deployment.html"
        }
      ],
      "tags": {
        "rationale": "Limiting the scope of user permissions can reduce the impact of mistakes or malicious activities. A Kubernetes namespace allows you to partition created resources into logically named groups. Resources created in one namespace can be hidden from other namespaces. By default, each resource created by a user in Kubernetes cluster runs in a default namespace, called `default`. You can create additional namespaces and attach resources and users to them. You can use Kubernetes Authorization plugins to create policies that segregate access to namespace resources between different users.",
        "check": "Run the below command and review the namespaces created in the cluster.\n\n  `kubectl get namespaces`\n\n  Ensure that these namespaces are the ones you need and are adequately administered as per your requirements.",
        "fix": "Follow the documentation and create namespaces for objects in your deployment as you need them.",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "1.6.3",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-1.6.3' do\n  title 'Create administrative boundaries between resources using namespaces (Not Scored)'\n  desc \"Use namespaces to isolate your Kubernetes objects.\"\n  impact 0.0\n\n  tag rationale: \"Limiting the scope of user permissions can reduce the impact of mistakes or malicious activities. A Kubernetes namespace allows you to partition created resources into logically named groups. Resources created in one namespace can be hidden from other namespaces. By default, each resource created by a user in Kubernetes cluster runs in a default namespace, called `default`. You can create additional namespaces and attach resources and users to them. You can use Kubernetes Authorization plugins to create policies that segregate access to namespace resources between different users.\"\n\n  tag check: \"Run the below command and review the namespaces created in the cluster.\n\n  `kubectl get namespaces`\n\n  Ensure that these namespaces are the ones you need and are adequately administered as per your requirements.\"\n\n  tag fix: \"Follow the documentation and create namespaces for objects in your deployment as you need them.\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"1.6.3\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'namespaces', url: 'https://kubernetes.io/docs/concepts/overview/working-with- objects/namespaces/'\n  ref 'security-best-practices-kubernetes-deployment.html', url: 'http://blog.kubernetes.io/2016/08/security-best-practices-kubernetes-deployment.html'\n\n  describe 'cis-kubernetes-benchmark-1.6.3' do\n    skip 'Review the output of `kubectl get namespaces` and ensure they are the ones you need.'\n  end\nend\n",
      "source_location": {
        "ref": "./controls/1_6_master_node_general_security_primitives.rb",
        "line": 81
      },
      "id": "cis-kubernetes-benchmark-1.6.3"
    },
    {
      "title": "Create network segmentation using Network Policies (Not Scored)",
      "desc": "Use network policies to isolate your cluster network.",
      "impact": 0,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/concepts/services-networking/networkpolicies/",
          "ref": "networkpolicies"
        },
        {
          "url": "http://blog.kubernetes.io/2016/08/security-best-practices-kubernetes-deployment.html",
          "ref": "security-best-practices-kubernetes-deployment.html"
        },
        {
          "url": "https://kubernetes.io/docs/tasks/configure-pod-container/declare-network- policy/",
          "ref": "declare-network-policy"
        }
      ],
      "tags": {
        "rationale": "Running different applications on the same Kubernetes cluster creates a risk of one compromised application attacking a neighboring application. Network segmentation is important to ensure that containers can communicate only with those they are supposed to. A network policy is a specification of how selections of pods are allowed to communicate with each other and other network endpoints. `NetworkPolicy` resources use labels to select pods and define whitelist rules which allow traffic to the selected pods in addition to what is allowed by the isolation policy for a given namespace.",
        "check": "Run the below command and review the `NetworkPolicy` objects created in the cluster.\n\n    `kubectl get pods --namespace=kube-system`\n\n    Ensure that these `NetworkPolicy` objects are the ones you need and are adequately administered as per your requirements.",
        "fix": "Follow the documentation and create `NetworkPolicy` objects as you need them.",
        "cis_family": [
          "14.1",
          "6.1"
        ],
        "cis_rid": "1.6.4",
        "cis_level": 2,
        "nist": [
          "AC-4",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "  control 'cis-kubernetes-benchmark-1.6.4' do\n    title 'Create network segmentation using Network Policies (Not Scored)'\n    desc \"Use network policies to isolate your cluster network.\"\n    impact 0.0\n\n    tag rationale: \"Running different applications on the same Kubernetes cluster creates a risk of one compromised application attacking a neighboring application. Network segmentation is important to ensure that containers can communicate only with those they are supposed to. A network policy is a specification of how selections of pods are allowed to communicate with each other and other network endpoints. `NetworkPolicy` resources use labels to select pods and define whitelist rules which allow traffic to the selected pods in addition to what is allowed by the isolation policy for a given namespace.\"\n\n    tag check: \"Run the below command and review the `NetworkPolicy` objects created in the cluster.\n\n    `kubectl get pods --namespace=kube-system`\n\n    Ensure that these `NetworkPolicy` objects are the ones you need and are adequately administered as per your requirements.\"\n\n    tag fix: \"Follow the documentation and create `NetworkPolicy` objects as you need them.\"\n\n    tag cis_family: ['14.1', '6.1']\n    tag cis_rid: \"1.6.4\"\n    tag cis_level: 2\n    tag nist: ['AC-4', '4']\n  tag severity: \"medium\"\n\n    ref 'networkpolicies', url: 'https://kubernetes.io/docs/concepts/services-networking/networkpolicies/'\n    ref 'security-best-practices-kubernetes-deployment.html', url: 'http://blog.kubernetes.io/2016/08/security-best-practices-kubernetes-deployment.html'\n    ref 'declare-network-policy', url: 'https://kubernetes.io/docs/tasks/configure-pod-container/declare-network- policy/'\n\n    describe 'cis-kubernetes-benchmark-1.6.4' do\n      skip 'Review the output of `kubectl get pods --namespace=kube-system` and ensure the `NetworkPolicy` objects are the ones you need.'\n    end\n  end\n",
      "source_location": {
        "ref": "./controls/1_6_master_node_general_security_primitives.rb",
        "line": 111
      },
      "id": "cis-kubernetes-benchmark-1.6.4"
    },
    {
      "title": "Ensure that the seccomp profile is set to docker/default in your pod definitions (Not Scored)",
      "desc": "Enable `docker/default` seccomp profile in your pod definitions.",
      "impact": 0,
      "refs": [
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/39845",
          "ref": "Kubernetes issues 39845"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/pull/21790",
          "ref": "Kubernetes pull 21790"
        },
        {
          "url": "https://github.com/kubernetes/community/blob/master/contributors/design-proposals/seccomp.md#examples",
          "ref": "examples"
        },
        {
          "url": "https://docs.docker.com/engine/security/seccomp/",
          "ref": "seccomp"
        }
      ],
      "tags": {
        "rationale": "Seccomp (secure computing mode) is used to restrict the set of system calls applications can make, allowing cluster administrators greater control over the security of workloads running in the cluster. Kubernetes disables seccomp profiles by default for historical reasons. You should enable it to ensure that the workloads have restricted actions available within the container.",
        "check": "Review the pod definitions in your cluster. It should create a line as below:\n\n    `annotations:\n      seccomp.security.alpha.kubernetes.io/pod: docker/default`",
        "fix": "Seccomp is an alpha feature currently. By default, all alpha features are disabled. So, you would need to enable alpha features in the apiserver by passing `\"--feature- gates=AllAlpha=true\"` argument.\n\n    Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\"--feature-gates=AllAlpha=true\"`\n\n    `KUBE_API_ARGS=\"--feature-gates=AllAlpha=true\"`\n\n    Based on your system, restart the `kube-apiserver` service. For example:\n\n    `systemctl restart kube-apiserver.service`\n\n    Use `annotations` to enable the `docker/default` seccomp profile in your pod definitions. An example is as below:\n\n    `apiVersion: v1\n    kind: Pod\n    metadata:\n      name: trustworthy-pod\n      annotations:\n    seccomp.security.alpha.kubernetes.io/pod: docker/default spec:\n      containers:\n        - name: trustworthy-container\n          image: sotrustworthy:latest`",
        "cis_family": [
          "5",
          "6.1"
        ],
        "cis_rid": "1.6.5",
        "cis_level": 2,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "  control 'cis-kubernetes-benchmark-1.6.5' do\n    title 'Ensure that the seccomp profile is set to docker/default in your pod definitions (Not Scored)'\n    desc \"Enable `docker/default` seccomp profile in your pod definitions.\"\n    impact 0.0\n\n    tag rationale: \"Seccomp (secure computing mode) is used to restrict the set of system calls applications can make, allowing cluster administrators greater control over the security of workloads running in the cluster. Kubernetes disables seccomp profiles by default for historical reasons. You should enable it to ensure that the workloads have restricted actions available within the container.\"\n\n    tag check: \"Review the pod definitions in your cluster. It should create a line as below:\n\n    `annotations:\n      seccomp.security.alpha.kubernetes.io/pod: docker/default`\"\n\n    tag fix: \"Seccomp is an alpha feature currently. By default, all alpha features are disabled. So, you would need to enable alpha features in the apiserver by passing `\\\"--feature- gates=AllAlpha=true\\\"` argument.\n\n    Edit the `/etc/kubernetes/apiserver` file on the master node and set the `KUBE_API_ARGS` parameter to `\\\"--feature-gates=AllAlpha=true\\\"`\n\n    `KUBE_API_ARGS=\\\"--feature-gates=AllAlpha=true\\\"`\n\n    Based on your system, restart the `kube-apiserver` service. For example:\n\n    `systemctl restart kube-apiserver.service`\n\n    Use `annotations` to enable the `docker/default` seccomp profile in your pod definitions. An example is as below:\n\n    `apiVersion: v1\n    kind: Pod\n    metadata:\n      name: trustworthy-pod\n      annotations:\n    seccomp.security.alpha.kubernetes.io/pod: docker/default spec:\n      containers:\n        - name: trustworthy-container\n          image: sotrustworthy:latest`\"\n\n    tag cis_family: ['5', '6.1']\n    tag cis_rid: \"1.6.5\"\n    tag cis_level: 2\n    tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n    ref 'Kubernetes issues 39845', url: 'https://github.com/kubernetes/kubernetes/issues/39845'\n    ref 'Kubernetes pull 21790', url: 'https://github.com/kubernetes/kubernetes/pull/21790'\n    ref 'examples', url: 'https://github.com/kubernetes/community/blob/master/contributors/design-proposals/seccomp.md#examples'\n    ref 'seccomp', url: 'https://docs.docker.com/engine/security/seccomp/'\n\n    describe 'cis-kubernetes-benchmark-1.6.5' do\n      skip 'Review all the pod definitions in your cluster and verify that `seccomp` is enabled.'\n    end\n  end\n",
      "source_location": {
        "ref": "./controls/1_6_master_node_general_security_primitives.rb",
        "line": 141
      },
      "id": "cis-kubernetes-benchmark-1.6.5"
    },
    {
      "title": "Apply Security Context to Your Pods and Containers (Not Scored)",
      "desc": "Apply Security Context to Your Pods and Containers",
      "impact": 0,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/concepts/policy/security-context/",
          "ref": "security-context"
        },
        {
          "url": "https://learn.cisecurity.org/benchmarks",
          "ref": "benchmarks"
        }
      ],
      "tags": {
        "rationale": "A security context defines the operating system security settings (uid, gid, capabilities, SELinux role, etc..) applied to a container. When designing your containers and pods, make sure that you configure the security context for your pods, containers, and volumes. A security context is a property defined in the deployment yaml. It controls the security parameters that will be assigned to the pod/container/volume. There are two levels of security context: pod level security context, and container level security context.",
        "check": "Review the pod definitions in your cluster and verify that you have security contexts defined as appropriate.",
        "fix": "Follow the Kubernetes documentation and apply security contexts to your pods. For a suggested list of security contexts, you may refer to the CIS Security Benchmark for Docker Containers.",
        "cis_family": [
          "3",
          "6.1"
        ],
        "cis_rid": "1.6.6",
        "cis_level": 2,
        "nist": [
          "CM-6",
          "Rev_4"
        ],
        "severity": "low"
      },
      "code": "  control 'cis-kubernetes-benchmark-1.6.6' do\n    title 'Apply Security Context to Your Pods and Containers (Not Scored)'\n    desc \"Apply Security Context to Your Pods and Containers\"\n    impact 0.0\n\n    tag rationale: \"A security context defines the operating system security settings (uid, gid, capabilities, SELinux role, etc..) applied to a container. When designing your containers and pods, make sure that you configure the security context for your pods, containers, and volumes. A security context is a property defined in the deployment yaml. It controls the security parameters that will be assigned to the pod/container/volume. There are two levels of security context: pod level security context, and container level security context.\"\n\n    tag check: \"Review the pod definitions in your cluster and verify that you have security contexts defined as appropriate.\"\n\n    tag fix: \"Follow the Kubernetes documentation and apply security contexts to your pods. For a suggested list of security contexts, you may refer to the CIS Security Benchmark for Docker Containers.\"\n\n    tag cis_family: ['3', '6.1']\n    tag cis_rid: \"1.6.6\"\n    tag cis_level: 2\n    tag nist: ['CM-6', '4']\n  tag severity: \"medium\"\n\n    ref 'security-context', url: 'https://kubernetes.io/docs/concepts/policy/security-context/'\n    ref 'benchmarks', url: 'https://learn.cisecurity.org/benchmarks'\n\n    describe 'cis-kubernetes-benchmark-1.6.6' do\n      skip 'Review the pod definitions in your cluster and verify that you have security contexts defined as appropriate.'\n    end\n  end\n",
      "source_location": {
        "ref": "./controls/1_6_master_node_general_security_primitives.rb",
        "line": 191
      },
      "id": "cis-kubernetes-benchmark-1.6.6"
    },
    {
      "title": "Configure Image Provenance using ImagePolicyWebhook admission controller (Not Scored)",
      "desc": "Configure Image Provenance for your deployment.",
      "impact": 0,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/admission-controllers/#imagepolicywebhook",
          "ref": "imagepolicywebhook"
        },
        {
          "url": "https://github.com/kubernetes/community/blob/master/contributors/design-proposals/image-provenance.md",
          "ref": "image-provenance"
        },
        {
          "url": "https://hub.docker.com/r/dnurmi/anchore-toolbox/",
          "ref": "anchore-toolbox"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/22888",
          "ref": "Kubernetes issues 22888"
        }
      ],
      "tags": {
        "rationale": "Kubernetes supports plugging in provenance rules to accept or reject the images in your deployments. You could configure such rules to ensure that only approved images are deployed in the cluster.",
        "check": "Review the pod definitions in your cluster and verify that image provenance is configured as appropriate.",
        "fix": "Follow the Kubernetes documentation and setup image provenance.",
        "cis_family": [
          "18",
          "6.1"
        ],
        "cis_rid": "1.6.7",
        "cis_level": 2,
        "nist": [
          "SI-1",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "  control 'cis-kubernetes-benchmark-1.6.7' do\n    title 'Configure Image Provenance using ImagePolicyWebhook admission controller (Not Scored)'\n    desc \"Configure Image Provenance for your deployment.\"\n    impact 0.0\n\n    tag rationale: \"Kubernetes supports plugging in provenance rules to accept or reject the images in your deployments. You could configure such rules to ensure that only approved images are deployed in the cluster.\"\n\n    tag check: \"Review the pod definitions in your cluster and verify that image provenance is configured as appropriate.\"\n\n    tag fix: \"Follow the Kubernetes documentation and setup image provenance.\"\n\n    tag cis_family: ['18', '6.1']\n    tag cis_rid: \"1.6.7\"\n    tag cis_level: 2\n    tag nist: ['SI-1', '4']\n  tag severity: \"medium\"\n\n    ref 'imagepolicywebhook', url: 'https://kubernetes.io/docs/admin/admission-controllers/#imagepolicywebhook'\n    ref 'image-provenance', url: 'https://github.com/kubernetes/community/blob/master/contributors/design-proposals/image-provenance.md'\n    ref 'anchore-toolbox', url: 'https://hub.docker.com/r/dnurmi/anchore-toolbox/'\n    ref 'Kubernetes issues 22888', url: 'https://github.com/kubernetes/kubernetes/issues/22888'\n\n    describe 'cis-kubernetes-benchmark-1.6.7' do\n      skip 'Review the pod definitions in your cluster and verify that image provenance is configured as appropriate.'\n    end\n  end\n",
      "source_location": {
        "ref": "./controls/1_6_master_node_general_security_primitives.rb",
        "line": 216
      },
      "id": "cis-kubernetes-benchmark-1.6.7"
    },
    {
      "title": "Configure Network policies as appropriate (Not Scored)",
      "desc": "Configure Network policies as appropriate.",
      "impact": 0,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/concepts/services-networking/network-policies/",
          "ref": "network-policies"
        }
      ],
      "tags": {
        "rationale": "The Network Policy API is now stable. Network policy, implemented through a network plug-in, allows users to set and enforce rules governing which pods can communicate with each other. You should leverage it as appropriate in your environment.",
        "check": "Review the network policies enforced and ensure that they are suitable for your requirements.",
        "fix": "Follow the Kubernetes documentation and setup network policies as appropriate.\n\n    For example, you could create a \"default\" isolation policy for a Namespace by creating a NetworkPolicy that selects all pods but does not allow any traffic:\n\n    `apiVersion: networking.k8s.io/v1\n    kind: NetworkPolicy\n    metadata:\n      name: default-deny\n    spec:\n      podSelector:`",
        "cis_family": [
          "12",
          "6.1"
        ],
        "cis_rid": "1.6.8",
        "cis_level": 2,
        "nist": [
          "SC-7",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "  control 'cis-kubernetes-benchmark-1.6.8' do\n    title 'Configure Network policies as appropriate (Not Scored)'\n    desc \"Configure Network policies as appropriate.\"\n    impact 0.0\n\n    tag rationale: \"The Network Policy API is now stable. Network policy, implemented through a network plug-in, allows users to set and enforce rules governing which pods can communicate with each other. You should leverage it as appropriate in your environment.\"\n\n    tag check: \"Review the network policies enforced and ensure that they are suitable for your requirements.\"\n\n    tag fix: \"Follow the Kubernetes documentation and setup network policies as appropriate.\n\n    For example, you could create a \\\"default\\\" isolation policy for a Namespace by creating a NetworkPolicy that selects all pods but does not allow any traffic:\n\n    `apiVersion: networking.k8s.io/v1\n    kind: NetworkPolicy\n    metadata:\n      name: default-deny\n    spec:\n      podSelector:`\"\n\n    tag cis_family: ['12', '6.1']\n    tag cis_rid: \"1.6.8\"\n    tag cis_level: 2\n    tag nist: ['SC-7', '4']\n  tag severity: \"medium\"\n\n    ref 'network-policies', url: 'https://kubernetes.io/docs/concepts/services-networking/network-policies/'\n\n    describe 'cis-kubernetes-benchmark-1.6.8' do\n      skip 'Review the network policies enforced and ensure that they are suitable for your requirements.'\n    end\n  end\n",
      "source_location": {
        "ref": "./controls/1_6_master_node_general_security_primitives.rb",
        "line": 243
      },
      "id": "cis-kubernetes-benchmark-1.6.8"
    },
    {
      "title": "Ensure that the --allow-privileged argument is set to false (Scored)",
      "desc": "Do not allow privileged containers.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        },
        {
          "url": "https://kubernetes.io/docs/user-guide/security-context/",
          "ref": "security-context"
        }
      ],
      "tags": {
        "rationale": "The privileged container has all the system capabilities, and it also lifts all the limitations enforced by the device cgroup controller. In other words, the container can then do almost everything that the host can do. This flag exists to allow special use-cases, like running Docker within Docker and hence should be avoided for production workloads.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--allow-privileged` argument is set to `false`.",
        "fix": "Edit the `/etc/kubernetes/config` file on each node and set the `KUBE_ALLOW_PRIV` parameter to `\"--allow-privileged=false\"`:\n\n  `KUBE_ALLOW_PRIV=\"--allow-privileged=false\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "2.1.1",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.1' do\n  title 'Ensure that the --allow-privileged argument is set to false (Scored)'\n  desc \"Do not allow privileged containers.\"\n  impact 1.0\n\n  tag rationale: \"The privileged container has all the system capabilities, and it also lifts all the limitations enforced by the device cgroup controller. In other words, the container can then do almost everything that the host can do. This flag exists to allow special use-cases, like running Docker within Docker and hence should be avoided for production workloads.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--allow-privileged` argument is set to `false`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/config` file on each node and set the `KUBE_ALLOW_PRIV` parameter to `\\\"--allow-privileged=false\\\"`:\n\n  `KUBE_ALLOW_PRIV=\\\"--allow-privileged=false\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"2.1.1\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n  ref 'security-context', url: 'https://kubernetes.io/docs/user-guide/security-context/'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--allow-privileged=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 24
      },
      "id": "cis-kubernetes-benchmark-2.1.1"
    },
    {
      "title": "Ensure that the --anonymous-auth argument is set to false (Scored)",
      "desc": "Disable anonymous requests to the Kubelet server.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authentication",
          "ref": "kubelet-authentication"
        }
      ],
      "tags": {
        "rationale": "When enabled, requests that are not rejected by other configured authentication methods are treated as anonymous requests. These requests are then served by the Kubelet server. You should rely on authentication to authorize access and disallow anonymous requests.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--anonymous-auth` argument is set to `false`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\"--anonymous-auth=false\"`:\n\n  `KUBELET_ARGS=\"--anonymous-auth=false\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "2.1.2",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.2' do\n  title 'Ensure that the --anonymous-auth argument is set to false (Scored)'\n  desc \"Disable anonymous requests to the Kubelet server.\"\n  impact 1.0\n\n  tag rationale: \"When enabled, requests that are not rejected by other configured authentication methods are treated as anonymous requests. These requests are then served by the Kubelet server. You should rely on authentication to authorize access and disallow anonymous requests.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--anonymous-auth` argument is set to `false`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\\\"--anonymous-auth=false\\\"`:\n\n  `KUBELET_ARGS=\\\"--anonymous-auth=false\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"2.1.2\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n  ref 'kubelet-authentication', url: 'https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authentication'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--anonymous-auth=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 59
      },
      "id": "cis-kubernetes-benchmark-2.1.2"
    },
    {
      "title": "Ensure that the --authorization-mode argument is not set to AlwaysAllow (Scored)",
      "desc": "Do not allow all requests. Enable explicit authorization.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authentication",
          "ref": "kubelet-authentication"
        }
      ],
      "tags": {
        "rationale": "Kubelets, by default, allow all authenticated requests (even anonymous ones) without needing explicit authorization checks from the apiserver. You should restrict this behavior and only allow explicitly authorized requests.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--authorization-mode` argument exists and is not set to `AlwaysAllow`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\"--authorization-mode=Webhook\"`:\n\n  `KUBELET_ARGS=\"--authorization-mode=Webhook\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "2.1.3",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.3' do\n  title 'Ensure that the --authorization-mode argument is not set to AlwaysAllow (Scored)'\n  desc \"Do not allow all requests. Enable explicit authorization.\"\n  impact 1.0\n\n  tag rationale: \"Kubelets, by default, allow all authenticated requests (even anonymous ones) without needing explicit authorization checks from the apiserver. You should restrict this behavior and only allow explicitly authorized requests.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--authorization-mode` argument exists and is not set to `AlwaysAllow`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\\\"--authorization-mode=Webhook\\\"`:\n\n  `KUBELET_ARGS=\\\"--authorization-mode=Webhook\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"2.1.3\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n  ref 'kubelet-authentication', url: 'https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authentication'\n\n  describe processes('kubelet').commands.to_s do\n    it { should_not match(/--authorization-mode=(?:.)*AlwaysAllow,*(?:.)*/) }\n    it { should match(/--authorization-mode=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 94
      },
      "id": "cis-kubernetes-benchmark-2.1.3"
    },
    {
      "title": "Ensure that the --client-ca-file argument is set as appropriate (Scored)",
      "desc": "Enable Kubelet authentication using certificates.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authentication",
          "ref": "kubelet-authentication"
        }
      ],
      "tags": {
        "rationale": "The connections from the apiserver to the kubelet are used for fetching logs for pods, attaching (through kubectl) to running pods, and using the kubelet’s port-forwarding functionality. These connections terminate at the kubelet’s HTTPS endpoint. By default, the apiserver does not verify the kubelet’s serving certificate, which makes the connection subject to man-in-the-middle attacks, and unsafe to run over untrusted and/or public networks. Enabling Kubelet certificate authentication ensures that the apiserver could authenticate the Kubelet before submitting any requests.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--client-ca-file` argument exists and is set as appropriate.",
        "fix": "Follow the Kubernetes documentation and setup the TLS connection between the apiserver and kubelets. Then, edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\"--client-ca-file=<path/to/client-ca-file>\"`:\n\n  `KUBELET_ARGS=\"--client-ca-file=<path/to/client-ca-file>\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "2.1.4",
        "cis_level": 1,
        "nist": [
          "AC-4 (20)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.4' do\n  title 'Ensure that the --client-ca-file argument is set as appropriate (Scored)'\n  desc \"Enable Kubelet authentication using certificates.\"\n  impact 1.0\n\n  tag rationale: \"The connections from the apiserver to the kubelet are used for fetching logs for pods, attaching (through kubectl) to running pods, and using the kubelet’s port-forwarding functionality. These connections terminate at the kubelet’s HTTPS endpoint. By default, the apiserver does not verify the kubelet’s serving certificate, which makes the connection subject to man-in-the-middle attacks, and unsafe to run over untrusted and/or public networks. Enabling Kubelet certificate authentication ensures that the apiserver could authenticate the Kubelet before submitting any requests.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--client-ca-file` argument exists and is set as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and setup the TLS connection between the apiserver and kubelets. Then, edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\\\"--client-ca-file=<path/to/client-ca-file>\\\"`:\n\n  `KUBELET_ARGS=\\\"--client-ca-file=<path/to/client-ca-file>\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"2.1.4\"\n  tag cis_level: 1\n  tag nist: ['AC-4 (20)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n  ref 'kubelet-authentication', url: 'https://kubernetes.io/docs/admin/kubelet-authentication-authorization/#kubelet-authentication'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--client-ca-file=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 130
      },
      "id": "cis-kubernetes-benchmark-2.1.4"
    },
    {
      "title": "Ensure that the --read-only-port argument is set to 0 (Scored)",
      "desc": "Disable the read-only port.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        }
      ],
      "tags": {
        "rationale": "The Kubelet process provides a read-only API in addition to the main Kubelet API. Unauthenticated access is provided to this read-only API which could possibly retrieve potentially sensitive information about the cluster.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--read-only-port` argument exists and is set to `0`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\"--read-only-port=0\"`\n\n  `KUBELET_ARGS=\"--read-only-port=0\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "9.1",
          "6.1"
        ],
        "cis_rid": "2.1.5",
        "cis_level": 1,
        "nist": [
          "CM-7 (1)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.5' do\n  title 'Ensure that the --read-only-port argument is set to 0 (Scored)'\n  desc \"Disable the read-only port.\"\n  impact 1.0\n\n  tag rationale: \"The Kubelet process provides a read-only API in addition to the main Kubelet API. Unauthenticated access is provided to this read-only API which could possibly retrieve potentially sensitive information about the cluster.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--read-only-port` argument exists and is set to `0`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\\\"--read-only-port=0\\\"`\n\n  `KUBELET_ARGS=\\\"--read-only-port=0\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['9.1', '6.1']\n  tag cis_rid: \"2.1.5\"\n  tag cis_level: 1\n  tag nist: ['CM-7 (1)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--read-only-port=0/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 165
      },
      "id": "cis-kubernetes-benchmark-2.1.5"
    },
    {
      "title": "Ensure that the --streaming-connection-idle-timeout argument is not set to 0 (Scored)",
      "desc": "Do not disable timeouts on streaming connections.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/pull/18552",
          "ref": "Kubernetes pull 18552"
        }
      ],
      "tags": {
        "rationale": "Setting idle timeouts ensures that you are protected against Denial-of-Service attacks, inactive connections and running out of ephemeral ports. **Note:** By default, `--streaming-connection-idle-timeout` is set to 4 hours which might be too high for your environment. Setting this as appropriate would additionally ensure that such streaming connections are timed out after serving legitimate use cases.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--streaming-connection-idle-timeout` argument is not set to `0`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\"--streaming-connection-idle-timeout=<appropriate-timeout-value>\"`\n\n  `KUBELET_ARGS=\"--streaming-connection-idle-timeout=5m\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "9",
          "6.1"
        ],
        "cis_rid": "2.1.6",
        "cis_level": 1,
        "nist": [
          "SC-7",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.6' do\n  title 'Ensure that the --streaming-connection-idle-timeout argument is not set to 0 (Scored)'\n  desc \"Do not disable timeouts on streaming connections.\"\n  impact 1.0\n\n  tag rationale: \"Setting idle timeouts ensures that you are protected against Denial-of-Service attacks, inactive connections and running out of ephemeral ports. **Note:** By default, `--streaming-connection-idle-timeout` is set to 4 hours which might be too high for your environment. Setting this as appropriate would additionally ensure that such streaming connections are timed out after serving legitimate use cases.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--streaming-connection-idle-timeout` argument is not set to `0`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\\\"--streaming-connection-idle-timeout=<appropriate-timeout-value>\\\"`\n\n  `KUBELET_ARGS=\\\"--streaming-connection-idle-timeout=5m\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['9', '6.1']\n  tag cis_rid: \"2.1.6\"\n  tag cis_level: 1\n  tag nist: ['SC-7', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n  ref 'Kubernetes pull 18552', url: 'https://github.com/kubernetes/kubernetes/pull/18552'\n\n  describe processes('kubelet').commands.to_s do\n    it { should_not match(/--streaming-connection-idle-timeout=0/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 199
      },
      "id": "cis-kubernetes-benchmark-2.1.6"
    },
    {
      "title": "Ensure that the --protect-kernel-defaults argument is set to true (Scored)",
      "desc": "Protect tuned kernel parameters from overriding kubelet default kernel parameter values.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        }
      ],
      "tags": {
        "rationale": "Kernel parameters are usually tuned and hardened by the system administrators before putting the systems into production. These parameters protect the kernel and the system. Your kubelet kernel defaults that rely on such parameters should be appropriately set to match the desired secured system state. Ignoring this could potentially lead to running pods with undesired kernel behavior.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--protect-kernel-defaults` argument is set to `true`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\"--protect-kernel-defaults=true\"`\n\n  `KUBELET_ARGS=\"--protect-kernel-defaults=true\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "3",
          "6.1"
        ],
        "cis_rid": "2.1.7",
        "cis_level": 1,
        "nist": [
          "CM-6",
          "Rev_4"
        ],
        "severity": "high"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.7' do\n  title 'Ensure that the --protect-kernel-defaults argument is set to true (Scored)'\n  desc \"Protect tuned kernel parameters from overriding kubelet default kernel parameter values.\"\n  impact 1.0\n\n  tag rationale: \"Kernel parameters are usually tuned and hardened by the system administrators before putting the systems into production. These parameters protect the kernel and the system. Your kubelet kernel defaults that rely on such parameters should be appropriately set to match the desired secured system state. Ignoring this could potentially lead to running pods with undesired kernel behavior.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--protect-kernel-defaults` argument is set to `true`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\\\"--protect-kernel-defaults=true\\\"`\n\n  `KUBELET_ARGS=\\\"--protect-kernel-defaults=true\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['3', '6.1']\n  tag cis_rid: \"2.1.7\"\n  tag cis_level: 1\n  tag nist: ['CM-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--protect-kernel-defaults=true/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 234
      },
      "id": "cis-kubernetes-benchmark-2.1.7"
    },
    {
      "title": "Ensure that the --make-iptables-util-chains argument is set to true (Scored)",
      "desc": "Allow Kubelet to manage iptables.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        }
      ],
      "tags": {
        "rationale": "Kubelets can automatically manage the required changes to iptables based on how you choose your networking options for the pods. It is recommended to let kubelets manage the changes to iptables. This ensures that the iptables configuration remains in sync with pods networking configuration. Manually configuring iptables with dynamic pod network configuration changes might hamper the communication between pods/containers and to the outside world. You might have iptables rules too restrictive or too open.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that if the `--make-iptables-util-chains` argument exists then it is set to `true`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and remove the `--make-iptables-util-chains` argument from the `KUBELET_ARGS` parameter. Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "9",
          "6.1"
        ],
        "cis_rid": "2.1.8",
        "cis_level": 1,
        "nist": [
          "SC-7",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.8' do\n  title 'Ensure that the --make-iptables-util-chains argument is set to true (Scored)'\n  desc \"Allow Kubelet to manage iptables.\"\n  impact 1.0\n\n  tag rationale: \"Kubelets can automatically manage the required changes to iptables based on how you choose your networking options for the pods. It is recommended to let kubelets manage the changes to iptables. This ensures that the iptables configuration remains in sync with pods networking configuration. Manually configuring iptables with dynamic pod network configuration changes might hamper the communication between pods/containers and to the outside world. You might have iptables rules too restrictive or too open.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that if the `--make-iptables-util-chains` argument exists then it is set to `true`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and remove the `--make-iptables-util-chains` argument from the `KUBELET_ARGS` parameter. Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['9', '6.1']\n  tag cis_rid: \"2.1.8\"\n  tag cis_level: 1\n  tag nist: ['SC-7', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--make-iptables-util-chains=true/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 268
      },
      "id": "cis-kubernetes-benchmark-2.1.8"
    },
    {
      "title": "Ensure that the --keep-terminated-pod-volumes argument is set to false (Scored)",
      "desc": "Unmount volumes from the nodes on pod termination.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        }
      ],
      "tags": {
        "rationale": "On pod termination, you should unmount the volumes. Those volumes might have sensitive data that might be exposed if kept mounted on the node without any use. Additionally, such mounted volumes could be modified and later could be mounted on pods. Also, if you retain all mounted volumes for a long time, it might exhaust system resources and you might not be able to mount any more volumes on new pods.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `--keep-terminated-pod-volumes` argument exists and is set to `false`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\"--keep-terminated-pod-volumes=false\"`:\n\n  `KUBELET_ARGS=\"--keep-terminated-pod-volumes=false\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "2.1.9",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.9' do\n  title 'Ensure that the --keep-terminated-pod-volumes argument is set to false (Scored)'\n  desc \"Unmount volumes from the nodes on pod termination.\"\n  impact 1.0\n\n  tag rationale: \"On pod termination, you should unmount the volumes. Those volumes might have sensitive data that might be exposed if kept mounted on the node without any use. Additionally, such mounted volumes could be modified and later could be mounted on pods. Also, if you retain all mounted volumes for a long time, it might exhaust system resources and you might not be able to mount any more volumes on new pods.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `--keep-terminated-pod-volumes` argument exists and is set to `false`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\\\"--keep-terminated-pod-volumes=false\\\"`:\n\n  `KUBELET_ARGS=\\\"--keep-terminated-pod-volumes=false\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"2.1.9\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--keep-terminated-pod-volumes=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 298
      },
      "id": "cis-kubernetes-benchmark-2.1.9"
    },
    {
      "title": "Ensure that the --hostname-override argument is not set (Scored)",
      "desc": "Do not override node hostnames.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/22063",
          "ref": "Kubernetes issues 22063"
        }
      ],
      "tags": {
        "rationale": "Overriding hostnames could potentially break TLS setup between the kubelet and the apiserver. Additionally, with overridden hostnames, it becomes increasingly difficult to associate logs with a particular node and process them for security analytics. Hence, you should setup your kubelet nodes with resolvable FQDNs and avoid overriding the hostnames with IPs.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `--hostname-override` argument does not exist.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_HOSTNAME` parameter to :\n\n  `KUBELET_HOSTNAME=`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "3",
          "6.1"
        ],
        "cis_rid": "2.1.10",
        "cis_level": 1,
        "nist": [
          "CM-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.10' do\n  title 'Ensure that the --hostname-override argument is not set (Scored)'\n  desc \"Do not override node hostnames.\"\n  impact 1.0\n\n  tag rationale: \"Overriding hostnames could potentially break TLS setup between the kubelet and the apiserver. Additionally, with overridden hostnames, it becomes increasingly difficult to associate logs with a particular node and process them for security analytics. Hence, you should setup your kubelet nodes with resolvable FQDNs and avoid overriding the hostnames with IPs.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `--hostname-override` argument does not exist.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_HOSTNAME` parameter to \"\":\n\n  `KUBELET_HOSTNAME=\"\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['3', '6.1']\n  tag cis_rid: \"2.1.10\"\n  tag cis_level: 1\n  tag nist: ['CM-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n  ref 'Kubernetes issues 22063', url: 'https://github.com/kubernetes/kubernetes/issues/22063'\n\n  describe processes('kubelet').commands.to_s do\n    it { should_not match(/--hostname-override/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 332
      },
      "id": "cis-kubernetes-benchmark-2.1.10"
    },
    {
      "title": "Ensure that the --event-qps argument is set to 0 (Scored)",
      "desc": "Do not limit event creation.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        }
      ],
      "tags": {
        "rationale": "It is important to capture all events and not restrict event creation. Events are an important source of security information and analytics that ensure that your environment is consistently monitored using the event data.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `--event-qps` argument exists and is set to `0`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\"--event-qps=0\"`:\n\n  `KUBELET_ARGS=\"--event-qps=0\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "6",
          "6.1"
        ],
        "cis_rid": "2.1.11",
        "cis_level": 1,
        "nist": [
          "AU-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.11' do\n  title 'Ensure that the --event-qps argument is set to 0 (Scored)'\n  desc \"Do not limit event creation.\"\n  impact 1.0\n\n  tag rationale: \"It is important to capture all events and not restrict event creation. Events are an important source of security information and analytics that ensure that your environment is consistently monitored using the event data.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `--event-qps` argument exists and is set to `0`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\\\"--event-qps=0\\\"`:\n\n  `KUBELET_ARGS=\\\"--event-qps=0\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['6', '6.1']\n  tag cis_rid: \"2.1.11\"\n  tag cis_level: 1\n  tag nist: ['AU-6', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--event-qps=0/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 367
      },
      "id": "cis-kubernetes-benchmark-2.1.11"
    },
    {
      "title": "Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Scored)",
      "desc": "Setup TLS connection on the Kubelets.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        },
        {
          "url": "http://rootsquash.com/2016/05/10/securing-the-kubernetes-api/",
          "ref": "securing-the-kubernetes-api"
        },
        {
          "url": "https://github.com/kelseyhightower/docker-kubernetes-tls-guide",
          "ref": "docker-kubernetes-tls-guide"
        }
      ],
      "tags": {
        "rationale": "Kubelet communication contains sensitive parameters that should remain encrypted in transit. Configure the Kubelets to serve only HTTPS traffic.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--tls-cert-file` and `--tls-private-key-file` arguments exist and they are set as appropriate.",
        "fix": "Follow the Kubernetes documentation and set up the TLS connection on the Kubelet. Then, edit the `/etc/kubernetes/kubelet` file on the master node and set the `KUBELET_ARGS` parameter to include `\"--tls-cert-file=<path/to/tls-certificate-file>\"` and `\"--tls- private-key-file=<path/to/tls-key-file>\"`:\n\n  `KUBELET_ARGS=\"--tls-cert-file=<path/to/tls-certificate-file> --tls-private- key-file=<path/to/tls-key-file>\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "2.1.12",
        "cis_level": 1,
        "nist": [
          "AC-4 (20)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.12' do\n  title 'Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Scored)'\n  desc \"Setup TLS connection on the Kubelets.\"\n  impact 1.0\n\n  tag rationale: \"Kubelet communication contains sensitive parameters that should remain encrypted in transit. Configure the Kubelets to serve only HTTPS traffic.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that the `--tls-cert-file` and `--tls-private-key-file` arguments exist and they are set as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and set up the TLS connection on the Kubelet. Then, edit the `/etc/kubernetes/kubelet` file on the master node and set the `KUBELET_ARGS` parameter to include `\\\"--tls-cert-file=<path/to/tls-certificate-file>\\\"` and `\\\"--tls- private-key-file=<path/to/tls-key-file>\\\"`:\n\n  `KUBELET_ARGS=\\\"--tls-cert-file=<path/to/tls-certificate-file> --tls-private- key-file=<path/to/tls-key-file>\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"2.1.12\"\n  tag cis_level: 1\n  tag nist: ['AC-4 (20)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n  ref 'securing-the-kubernetes-api', url: 'http://rootsquash.com/2016/05/10/securing-the-kubernetes-api/'\n  ref 'docker-kubernetes-tls-guide', url: 'https://github.com/kelseyhightower/docker-kubernetes-tls-guide'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--tls-cert-file=/) }\n    it { should match(/--tls-private-key-file=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 401
      },
      "id": "cis-kubernetes-benchmark-2.1.12"
    },
    {
      "title": "Ensure that the --cadvisor-port argument is set to 0 (Scored)",
      "desc": "Disable cAdvisor.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/11710",
          "ref": "Kubernetes issues 11710"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/32638",
          "ref": "Kubernetes issues 32638"
        },
        {
          "url": "https://raesene.github.io/blog/2016/10/14/Kubernetes-Attack-Surface-cAdvisor/",
          "ref": "Kubernetes-Attack-Surface-cAdvisor"
        }
      ],
      "tags": {
        "rationale": "cAdvisor provides potentially sensitive data and there's currently no way to block access to it using anything other than iptables. It does not require authentication/authorization to connect to the cAdvisor port. Hence, you should disable the port.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `--cadvisor-port` argument exists and is set to `0`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\"--cadvisor-port=0\"`:\n\n  `KUBELET_ARGS=\"--cadvisor-port=0\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "9.1",
          "6.1"
        ],
        "cis_rid": "2.1.13",
        "cis_level": 1,
        "nist": [
          "CM-7 (1)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.13' do\n  title 'Ensure that the --cadvisor-port argument is set to 0 (Scored)'\n  desc \"Disable cAdvisor.\"\n  impact 1.0\n\n  tag rationale: \"cAdvisor provides potentially sensitive data and there's currently no way to block access to it using anything other than iptables. It does not require authentication/authorization to connect to the cAdvisor port. Hence, you should disable the port.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `--cadvisor-port` argument exists and is set to `0`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to `\\\"--cadvisor-port=0\\\"`:\n\n  `KUBELET_ARGS=\\\"--cadvisor-port=0\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['9.1', '6.1']\n  tag cis_rid: \"2.1.13\"\n  tag cis_level: 1\n  tag nist: ['CM-7 (1)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n  ref 'Kubernetes issues 11710', url: 'https://github.com/kubernetes/kubernetes/issues/11710'\n  ref 'Kubernetes issues 32638', url: 'https://github.com/kubernetes/kubernetes/issues/32638'\n  ref 'Kubernetes-Attack-Surface-cAdvisor', url: 'https://raesene.github.io/blog/2016/10/14/Kubernetes-Attack-Surface-cAdvisor/'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--cadvisor-port=0/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 438
      },
      "id": "cis-kubernetes-benchmark-2.1.13"
    },
    {
      "title": "Ensure that the RotateKubeletClientCertificate argument is set to true (Scored)",
      "desc": "Enable kubelet client certificate rotation.",
      "impact": 1,
      "refs": [
        {
          "url": "https://github.com/kubernetes/kubernetes/pull/41912",
          "ref": "Kubernetes pull 41912"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#kubelet-configuration",
          "ref": "kubelet-configuration"
        }
      ],
      "tags": {
        "rationale": "RotateKubeletClientCertificate causes the kubelet to rotate its client certificates by creating new CSRs as its existing credentials expire. This automated periodic rotation ensures that the there are no downtimes due to expired certificates and thus addressing availability in the CIA security triad. Note: This recommendation only applies if you let kubelets get their certificates from the API server. In case your kubelet certificates come from an outside authority/tool (e.g. Vault) then you need to take care of rotation yourself.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `RotateKubeletClientCertificate` argument exists and is set to `true`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to a value to include `\"--feature-gates=RotateKubeletClientCertificate=true\"`.\n\n  `KUBELET_ARGS=\"--feature-gates=RotateKubeletClientCertificate=true\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "2.1.14",
        "cis_level": 1,
        "nist": [
          "AC-4 (20)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.14' do\n  title 'Ensure that the RotateKubeletClientCertificate argument is set to true (Scored)'\n  desc \"Enable kubelet client certificate rotation.\"\n  impact 1.0\n\n  tag rationale: \"RotateKubeletClientCertificate causes the kubelet to rotate its client certificates by creating new CSRs as its existing credentials expire. This automated periodic rotation ensures that the there are no downtimes due to expired certificates and thus addressing availability in the CIA security triad. Note: This recommendation only applies if you let kubelets get their certificates from the API server. In case your kubelet certificates come from an outside authority/tool (e.g. Vault) then you need to take care of rotation yourself.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `RotateKubeletClientCertificate` argument exists and is set to `true`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to a value to include `\\\"--feature-gates=RotateKubeletClientCertificate=true\\\"`.\n\n  `KUBELET_ARGS=\\\"--feature-gates=RotateKubeletClientCertificate=true\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"2.1.14\"\n  tag cis_level: 1\n  tag nist: ['AC-4 (20)', '4']\n  tag severity: \"medium\"\n\n  ref 'Kubernetes pull 41912', url: 'https://github.com/kubernetes/kubernetes/pull/41912'\n  ref 'kubelet-configuration', url: 'https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#kubelet-configuration'\n\n  describe processes('kubelet').commands.to_s do\n    it { should match(/--feature-gates=(?:.)*RotateKubeletClientCertificate=true,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 475
      },
      "id": "cis-kubernetes-benchmark-2.1.14"
    },
    {
      "title": "Ensure that the RotateKubeletServerCertificate argument is set to true (Scored)",
      "desc": "Enable kubelet server certificate rotation.",
      "impact": 1,
      "refs": [
        {
          "url": "https://github.com/kubernetes/kubernetes/pull/45059",
          "ref": "Kubernetes pull 45059"
        },
        {
          "url": "https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#kubelet-configuration",
          "ref": "kubelet-configuration"
        }
      ],
      "tags": {
        "rationale": "RotateKubeletServerCertificate causes the kubelet to both request a serving certificate after bootstrapping its client credentials and rotate the certificate as its existing credentials expire. This automated periodic rotation ensures that the there are no downtimes due to expired certificates and thus addressing availability in the CIA security triad. Note: This recommendation only applies if you let kubelets get their certificates from the API server. In case your kubelet certificates come from an outside authority/tool (e.g. Vault) then you need to take care of rotation yourself.",
        "check": "Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `RotateKubeletServerCertificate` argument exists and is set to `true`.",
        "fix": "Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to a value to include `\"--feature-gates=RotateKubeletServerCertificate=true\"`.\n\n  `KUBELET_ARGS=\"--feature-gates=RotateKubeletServerCertificate=true\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "2.1.15",
        "cis_level": 1,
        "nist": [
          "AC-4 (20)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.1.15' do\n  title 'Ensure that the RotateKubeletServerCertificate argument is set to true (Scored)'\n  desc \"Enable kubelet server certificate rotation.\"\n  impact 1.0\n\n  tag rationale: \"RotateKubeletServerCertificate causes the kubelet to both request a serving certificate after bootstrapping its client credentials and rotate the certificate as its existing credentials expire. This automated periodic rotation ensures that the there are no downtimes due to expired certificates and thus addressing availability in the CIA security triad. Note: This recommendation only applies if you let kubelets get their certificates from the API server. In case your kubelet certificates come from an outside authority/tool (e.g. Vault) then you need to take care of rotation yourself.\"\n\n  tag check: \"Run the following command on each node:\n\n  `ps -ef | grep kubelet`\n\n  Verify that `RotateKubeletServerCertificate` argument exists and is set to `true`.\"\n\n  tag fix: \"Edit the `/etc/kubernetes/kubelet` file on each node and set the `KUBELET_ARGS` parameter to a value to include `\\\"--feature-gates=RotateKubeletServerCertificate=true\\\"`.\n\n  `KUBELET_ARGS=\\\"--feature-gates=RotateKubeletServerCertificate=true\\\"`\n\n  Based on your system, restart the `kubelet` service. For example:\n\n  `systemctl restart kubelet.service`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"2.1.15\"\n  tag cis_level: 1\n  tag nist: ['AC-4 (20)', '4']\n  tag severity: \"medium\"\n\n  ref 'Kubernetes pull 45059', url: 'https://github.com/kubernetes/kubernetes/pull/45059'\n  ref 'kubelet-configuration', url: 'https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/#kubelet-configuration'\n\n  describe processes('kube-controller-manager').commands.to_s do\n    it { should match(/--feature-gates=(?:.)*RotateKubeletServerCertificate=true,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_1_worker_node_kubelet.rb",
        "line": 510
      },
      "id": "cis-kubernetes-benchmark-2.1.15"
    },
    {
      "title": "Ensure that the config file permissions are set to 644 or more restrictive (Scored)",
      "desc": "Ensure that the `config` file has permissions of `644` or more restrictive.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        }
      ],
      "tags": {
        "rationale": "The `config` file controls various parameters that set the behavior of various components of the worker node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.",
        "check": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %a /etc/kubernetes/config`\n\n  Verify that the permissions are `644` or more restrictive.",
        "fix": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chmod 644 /etc/kubernetes/config`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "2.2.1",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.2.1' do\n  title 'Ensure that the config file permissions are set to 644 or more restrictive (Scored)'\n  desc \"Ensure that the `config` file has permissions of `644` or more restrictive.\"\n  impact 1.0\n\n  tag rationale: \"The `config` file controls various parameters that set the behavior of various components of the worker node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %a /etc/kubernetes/config`\n\n  Verify that the permissions are `644` or more restrictive.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chmod 644 /etc/kubernetes/config`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"2.2.1\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n\n  only_if do\n    file('/etc/kubernetes/config').exist?\n  end\n\n  describe file('/etc/kubernetes/config').mode.to_s do\n    it { should match(/[0246][024][024]/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_2_worker_node_configuration_files.rb",
        "line": 20
      },
      "id": "cis-kubernetes-benchmark-2.2.1"
    },
    {
      "title": "Ensure that the config file ownership is set to root:root (Scored)",
      "desc": "Ensure that the `config` file ownership is set to `root:root`.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        }
      ],
      "tags": {
        "rationale": "The `config` file controls various parameters that set the behavior of various components of the worker node. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.",
        "check": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/config`\n\n  Verify that the ownership is set to `root:root`.",
        "fix": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chown root:root /etc/kubernetes/config`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "2.2.2",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.2.2' do\n  title 'Ensure that the config file ownership is set to root:root (Scored)'\n  desc \"Ensure that the `config` file ownership is set to `root:root`.\"\n  impact 1.0\n\n  tag rationale: \"The `config` file controls various parameters that set the behavior of various components of the worker node. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/config`\n\n  Verify that the ownership is set to `root:root`.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chown root:root /etc/kubernetes/config`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"2.2.2\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n\n  only_if do\n    file('/etc/kubernetes/config').exist?\n  end\n\n  describe file('/etc/kubernetes/config') do\n    it { should be_owned_by 'root' }\n    it { should be_grouped_into 'root' }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_2_worker_node_configuration_files.rb",
        "line": 54
      },
      "id": "cis-kubernetes-benchmark-2.2.2"
    },
    {
      "title": "Ensure that the kubelet file permissions are set to 644 or more restrictive (Scored)",
      "desc": "Ensure that the `kubelet` file has permissions of `644` or more restrictive.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        },
        {
          "url": "https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#44-joining-your-nodes",
          "ref": "44-joining-your-noes"
        }
      ],
      "tags": {
        "rationale": "The `kubelet` file controls various parameters that set the behavior of the `kubelet` service in the worker node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.",
        "check": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %a /etc/kubernetes/kubelet`\n\n  Verify that the permissions are `644` or more restrictive.",
        "fix": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chmod 644 /etc/kubernetes/kubelet`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "2.2.3",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.2.3' do\n  title 'Ensure that the kubelet file permissions are set to 644 or more restrictive (Scored)'\n  desc \"Ensure that the `kubelet` file has permissions of `644` or more restrictive.\"\n  impact 1.0\n\n  tag rationale: \"The `kubelet` file controls various parameters that set the behavior of the `kubelet` service in the worker node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %a /etc/kubernetes/kubelet`\n\n  Verify that the permissions are `644` or more restrictive.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chmod 644 /etc/kubernetes/kubelet`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"2.2.3\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n  ref '44-joining-your-noes', url: 'https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#44-joining-your-nodes'\n\n  only_if do\n    file('/etc/kubernetes/kubelet').exist?\n  end\n\n  describe file('/etc/kubernetes/kubelet').mode.to_s do\n    it { should match(/[0246][024][024]/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_2_worker_node_configuration_files.rb",
        "line": 89
      },
      "id": "cis-kubernetes-benchmark-2.2.3"
    },
    {
      "title": "Ensure that the kubelet file ownership is set to root:root (Scored)",
      "desc": "Ensure that the `kubelet` file ownership is set to `root:root`.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        },
        {
          "url": "https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#44-joining-your-nodes",
          "ref": "44-joining-your-noes"
        }
      ],
      "tags": {
        "rationale": "The `kubelet` file controls various parameters that set the behavior of the `kubelet` service in the worker node. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.",
        "check": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/kubelet`\n\n  Verify that the ownership is set to `root:root`.",
        "fix": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chown root:root /etc/kubernetes/kubelet`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "2.2.4",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.2.4' do\n  title 'Ensure that the kubelet file ownership is set to root:root (Scored)'\n  desc \"Ensure that the `kubelet` file ownership is set to `root:root`.\"\n  impact 1.0\n\n  tag rationale: \"The `kubelet` file controls various parameters that set the behavior of the `kubelet` service in the worker node. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/kubelet`\n\n  Verify that the ownership is set to `root:root`.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chown root:root /etc/kubernetes/kubelet`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"2.2.4\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n  ref '44-joining-your-noes', url: 'https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#44-joining-your-nodes'\n\n  only_if do\n    file('/etc/kubernetes/kubelet').exist?\n  end\n\n  describe file('/etc/kubernetes/kubelet') do\n    it { should be_owned_by 'root' }\n    it { should be_grouped_into 'root' }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_2_worker_node_configuration_files.rb",
        "line": 124
      },
      "id": "cis-kubernetes-benchmark-2.2.4"
    },
    {
      "title": "Ensure that the proxy file permissions are set to 644 or more restrictive (Scored)",
      "desc": "Ensure that the `proxy` file has permissions of `644` or more restrictive.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        }
      ],
      "tags": {
        "rationale": "The `proxy` file controls various parameters that set the behavior of the `kube-proxy` service in the worker node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.",
        "check": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %a /etc/kubernetes/proxy`\n\n  Verify that the permissions are `644` or more restrictive.",
        "fix": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chmod 644 /etc/kubernetes/proxy`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "2.2.5",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.2.5' do\n  title 'Ensure that the proxy file permissions are set to 644 or more restrictive (Scored)'\n  desc \"Ensure that the `proxy` file has permissions of `644` or more restrictive.\"\n  impact 1.0\n\n  tag rationale: \"The `proxy` file controls various parameters that set the behavior of the `kube-proxy` service in the worker node. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %a /etc/kubernetes/proxy`\n\n  Verify that the permissions are `644` or more restrictive.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chmod 644 /etc/kubernetes/proxy`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"2.2.5\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n\n  only_if do\n    file('/etc/kubernetes/proxy').exist?\n  end\n\n  describe file('/etc/kubernetes/proxy').mode.to_s do\n    it { should match(/[0246][024][024]/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_2_worker_node_configuration_files.rb",
        "line": 160
      },
      "id": "cis-kubernetes-benchmark-2.2.5"
    },
    {
      "title": "Ensure that the proxy file ownership is set to root:root (Scored)",
      "desc": "Ensure that the `proxy` file ownership is set to `root:root`.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/kubelet/",
          "ref": "kubelet"
        }
      ],
      "tags": {
        "rationale": "The `proxy` file controls various parameters that set the behavior of the `kube-proxy` service in the worker node. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.",
        "check": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/proxy`\n\n  Verify that the ownership is set to `root:root`.",
        "fix": "Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chown root:root /etc/kubernetes/proxy`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "2.2.6",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.2.6' do\n  title 'Ensure that the proxy file ownership is set to root:root (Scored)'\n  desc \"Ensure that the `proxy` file ownership is set to `root:root`.\"\n  impact 1.0\n\n  tag rationale: \"The `proxy` file controls various parameters that set the behavior of the `kube-proxy` service in the worker node. You should set its file ownership to maintain the integrity of the file. The file should be owned by `root:root`.\"\n\n  tag check: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `stat -c %U:%G /etc/kubernetes/proxy`\n\n  Verify that the ownership is set to `root:root`.\"\n\n  tag fix: \"Run the below command (based on the file location on your system) on the each worker node. For example,\n\n  `chown root:root /etc/kubernetes/proxy`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"2.2.6\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'kubelet', url: 'https://kubernetes.io/docs/admin/kubelet/'\n\n  only_if do\n    file('/etc/kubernetes/proxy').exist?\n  end\n\n  describe file('/etc/kubernetes/proxy') do\n    it { should be_owned_by 'root' }\n    it { should be_grouped_into 'root' }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_2_worker_node_configuration_files.rb",
        "line": 194
      },
      "id": "cis-kubernetes-benchmark-2.2.6"
    },
    {
      "title": "Ensure that the certificate authorities file permissions are set to 644 or more restrictive (Scored)",
      "desc": "Ensure that the certificate authorities file has permissions of 644 or more restrictive.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/authentication/#x509-client-certs",
          "ref": "x509-client-certs"
        }
      ],
      "tags": {
        "rationale": "The certificate authorities file controls the authorities used to validate API requests. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.",
        "check": "Run the following command:\n\n  `ps -ef | grep kubelet`\n\n  Find the file specified by the `--client-ca-file` argument.\n\n  Run the following command:\n\n  `stat -c %a <filename>`\n\n  Verify that the permissions are `644` or more restrictive.",
        "fix": "Run the following command to modify the file permissions of the `--client-ca-file `\n\n  `chmod 644 <filename>`",
        "cis_family": [
          "14.4",
          "6.1"
        ],
        "cis_rid": "2.2.7",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.2.7' do\n  title 'Ensure that the certificate authorities file permissions are set to 644 or more restrictive (Scored)'\n  desc \"Ensure that the certificate authorities file has permissions of 644 or more restrictive.\"\n  impact 1.0\n\n  tag rationale: \"The certificate authorities file controls the authorities used to validate API requests. You should restrict its file permissions to maintain the integrity of the file. The file should be writable by only the administrators on the system.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep kubelet`\n\n  Find the file specified by the `--client-ca-file` argument.\n\n  Run the following command:\n\n  `stat -c %a <filename>`\n\n  Verify that the permissions are `644` or more restrictive.\"\n\n  tag fix: \"Run the following command to modify the file permissions of the `--client-ca-file `\n\n  `chmod 644 <filename>`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_family: ['14.4', '6.1']\n  tag cis_rid: \"2.2.7\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'x509-client-certs', url: 'https://kubernetes.io/docs/admin/authentication/#x509-client-certs'\n\n  ca_cert_path = processes('kubelet').commands.to_s.scan(/--client-ca-file=(\\S*)/)\n\n  if ca_cert_path.empty?\n    describe 'cis-kubernetes-benchmark-2.2.7' do\n      skip 'No client CA file specified for `kubelet` process'\n    end\n  else\n    describe file(ca_cert_path.last.first).mode.to_s do\n      it { should match(/[0246][024][024]/) }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_2_worker_node_configuration_files.rb",
        "line": 229
      },
      "id": "cis-kubernetes-benchmark-2.2.7"
    },
    {
      "title": "Ensure that the client certificate authorities file ownership is set to root:root (Scored)",
      "desc": "Ensure that the certificate authorities file ownership is set to root:root.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/authentication/#x509-client-certs",
          "ref": "x509-client-certs"
        }
      ],
      "tags": {
        "rationale": "The certificate authorities file controls the authorities used to validate API requests. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.",
        "check": "Run the following command:\n\n  `ps -ef | grep kubelet`\n\n  Find the file specified by the `--client-ca-file` argument.\n\n  Run the following command:\n\n  `stat -c %U:%G <filename>`\n\n  Verify that the ownership is set to `root:root`.",
        "fix": "Run the following command to modify the ownership of the `--client-ca-file`.\n\n  `chown root:root <filename>`",
        "cis_family": [
          "5.1",
          "6.1"
        ],
        "cis_rid": "2.2.8",
        "cis_level": 1,
        "nist": [
          "AC-6 (9)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-2.2.8' do\n  title 'Ensure that the client certificate authorities file ownership is set to root:root (Scored)'\n  desc \"Ensure that the certificate authorities file ownership is set to root:root.\"\n  impact 1.0\n\n  tag rationale: \"The certificate authorities file controls the authorities used to validate API requests. You should set its file ownership to maintain the integrity of the file. The file should be owned by root:root.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep kubelet`\n\n  Find the file specified by the `--client-ca-file` argument.\n\n  Run the following command:\n\n  `stat -c %U:%G <filename>`\n\n  Verify that the ownership is set to `root:root`.\"\n\n  tag fix: \"Run the following command to modify the ownership of the `--client-ca-file`.\n\n  `chown root:root <filename>`\"\n\n  tag cis_family: ['5.1', '6.1']\n  tag cis_rid: \"2.2.8\"\n  tag cis_level: 1\n  tag nist: ['AC-6 (9)', '4']\n  tag severity: \"medium\"\n\n  ref 'x509-client-certs', url: 'https://kubernetes.io/docs/admin/authentication/#x509-client-certs'\n\n  ca_cert_path = processes('kubelet').commands.to_s.scan(/--client-ca-file=(\\S*)/)\n\n  if ca_cert_path.empty?\n    describe 'cis-kubernetes-benchmark-2.2.8' do\n      skip 'No client CA file specified for `kubelet` process'\n    end\n  else\n    describe file(ca_cert_path.last.first) do\n      it { should be_owned_by 'root' }\n      it { should be_grouped_into 'root' }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/2_2_worker_node_configuration_files.rb",
        "line": 274
      },
      "id": "cis-kubernetes-benchmark-2.2.8"
    },
    {
      "title": "Ensure that the --anonymous-auth argument is set to false (Scored)",
      "desc": "Disable anonymous requests to the federation API server.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "When enabled, requests that are not rejected by other configured authentication methods are treated as anonymous requests. These requests are then served by the federation API server. You should rely on authentication to authorize access and disallow anonymous requests.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--anonymous-auth` argument is set to `false`.",
        "fix": "Edit the deployment specs and set `--anonymous-auth=false`.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "3.1.1",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.1' do\n  title 'Ensure that the --anonymous-auth argument is set to false (Scored)'\n  desc \"Disable anonymous requests to the federation API server.\"\n  impact 1.0\n\n  tag rationale: \"When enabled, requests that are not rejected by other configured authentication methods are treated as anonymous requests. These requests are then served by the federation API server. You should rely on authentication to authorize access and disallow anonymous requests.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--anonymous-auth` argument is set to `false`.\"\n\n  tag fix: \"Edit the deployment specs and set `--anonymous-auth=false`.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"3.1.1\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--anonymous-auth=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 24
      },
      "id": "cis-kubernetes-benchmark-3.1.1"
    },
    {
      "title": "Ensure that the --basic-auth-file argument is not set (Scored)",
      "desc": "Do not use basic authentication.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Basic authentication uses plaintext credentials for authentication. Currently, the basic authentication credentials last indefinitely, and the password cannot be changed without restarting the federation API server. The basic authentication is currently supported for convenience. Hence, basic authentication should not be used.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--basic-auth-file` argument does not exist.",
        "fix": "Follow the documentation and configure alternate mechanisms for authentication. Then, edit the deployment specs and remove `\"--basic-auth-file=<filename>\"`.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "16.14",
          "6.1"
        ],
        "cis_rid": "3.1.2",
        "cis_level": 1,
        "nist": [
          "SC-28",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.2' do\n  title 'Ensure that the --basic-auth-file argument is not set (Scored)'\n  desc \"Do not use basic authentication.\"\n  impact 1.0\n\n  tag rationale: \"Basic authentication uses plaintext credentials for authentication. Currently, the basic authentication credentials last indefinitely, and the password cannot be changed without restarting the federation API server. The basic authentication is currently supported for convenience. Hence, basic authentication should not be used.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--basic-auth-file` argument does not exist.\"\n\n  tag fix: \"Follow the documentation and configure alternate mechanisms for authentication. Then, edit the deployment specs and remove `\\\"--basic-auth-file=<filename>\\\"`.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['16.14', '6.1']\n  tag cis_rid: \"3.1.2\"\n  tag cis_level: 1\n  tag nist: ['SC-28', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should_not match(/--basic-auth-file/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 56
      },
      "id": "cis-kubernetes-benchmark-3.1.2"
    },
    {
      "title": "Ensure that the --insecure-allow-any-token argument is not set (Scored)",
      "desc": "Do not allow any insecure tokens.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Accepting insecure tokens would allow any token without actually authenticating anything. User information is parsed from the token and connections are allowed.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--insecure-allow-any-token` argument does not exist.",
        "fix": "Edit the deployment specs and remove `--insecure-allow-any-token`.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "16",
          "6.1"
        ],
        "cis_rid": "3.1.3",
        "cis_level": 1,
        "nist": [
          "AC-2",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.3' do\n  title 'Ensure that the --insecure-allow-any-token argument is not set (Scored)'\n  desc \"Do not allow any insecure tokens.\"\n  impact 1.0\n\n  tag rationale: \"Accepting insecure tokens would allow any token without actually authenticating anything. User information is parsed from the token and connections are allowed.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--insecure-allow-any-token` argument does not exist.\"\n\n  tag fix: \"Edit the deployment specs and remove `--insecure-allow-any-token`.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['16', '6.1']\n  tag cis_rid: \"3.1.3\"\n  tag cis_level: 1\n  tag nist: ['AC-2', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should_not match(/--insecure-allow-any-token/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 88
      },
      "id": "cis-kubernetes-benchmark-3.1.3"
    },
    {
      "title": "Ensure that the --insecure-bind-address argument is not set (Scored)",
      "desc": "Do not bind to insecure addresses.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "If you bind the federation apiserver to an insecure address, basically anyone who could connect to it over the insecure port, would have unauthenticated and unencrypted access to it. The federation apiserver doesn't do any authentication checking for insecure binds and neither the insecure traffic is encrypted. Hence, you should not bind the federation apiserver to an insecure address.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--insecure-bind-address` argument does not exist or is set to 127.0.0.1.",
        "fix": "Edit the deployment specs and remove --insecure-bind-address.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "9.1",
          "6.1"
        ],
        "cis_rid": "3.1.4",
        "cis_level": 1,
        "nist": [
          "CM-7 (1)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.4' do\n  title 'Ensure that the --insecure-bind-address argument is not set (Scored)'\n  desc \"Do not bind to insecure addresses.\"\n  impact 1.0\n\n  tag rationale: \"If you bind the federation apiserver to an insecure address, basically anyone who could connect to it over the insecure port, would have unauthenticated and unencrypted access to it. The federation apiserver doesn't do any authentication checking for insecure binds and neither the insecure traffic is encrypted. Hence, you should not bind the federation apiserver to an insecure address.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--insecure-bind-address` argument does not exist or is set to 127.0.0.1.\"\n\n  tag fix: \"Edit the deployment specs and remove --insecure-bind-address.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['9.1', '6.1']\n  tag cis_rid: \"3.1.4\"\n  tag cis_level: 1\n  tag nist: ['CM-7 (1)', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe.one do\n    describe processes('federation-apiserver').commands.to_s do\n      it { should match(/--insecure-bind-address=127\\.0\\.0\\.1/) }\n    end\n    describe processes('federation-apiserver').commands.to_s do\n      it { should_not match(/--insecure-bind-address/) }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 120
      },
      "id": "cis-kubernetes-benchmark-3.1.4"
    },
    {
      "title": "Ensure that the --insecure-port argument is set to 0 (Scored)",
      "desc": "Do not bind to insecure port.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Setting up the federation apiserver to serve on an insecure port would allow unauthenticated and unencrypted access to it. It is assumed that firewall rules are set up such that this port is not reachable from outside of the cluster. But, as a defense in depth measure, you should not use an insecure port.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--insecure-port` argument is set to `0`.",
        "fix": "Edit the deployment specs and set --insecure-port=0.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "9.1",
          "6.1"
        ],
        "cis_rid": "3.1.5",
        "cis_level": 1,
        "nist": [
          "CM-7 (1)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.5' do\n  title 'Ensure that the --insecure-port argument is set to 0 (Scored)'\n  desc \"Do not bind to insecure port.\"\n  impact 1.0\n\n  tag rationale: \"Setting up the federation apiserver to serve on an insecure port would allow unauthenticated and unencrypted access to it. It is assumed that firewall rules are set up such that this port is not reachable from outside of the cluster. But, as a defense in depth measure, you should not use an insecure port.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--insecure-port` argument is set to `0`.\"\n\n  tag fix: \"Edit the deployment specs and set --insecure-port=0.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['9.1', '6.1']\n  tag cis_rid: \"3.1.5\"\n  tag cis_level: 1\n  tag nist: ['CM-7 (1)', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--insecure-port=0/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 157
      },
      "id": "cis-kubernetes-benchmark-3.1.5"
    },
    {
      "title": "Ensure that the --secure-port argument is not set to 0 (Scored)",
      "desc": "Do not disable the secure port.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "The secure port is used to serve https with authentication and authorization. If you disable it, no https traffic is served and all traffic is served unencrypted.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--secure-port` argument is either not set or is set to an integer value between 1 and 65535.",
        "fix": "Edit the deployment specs and set the --secure-port argument to the desired port.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "3.1.6",
        "cis_level": 1,
        "nist": [
          "AC-4 (20)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.6' do\n  title 'Ensure that the --secure-port argument is not set to 0 (Scored)'\n  desc \"Do not disable the secure port.\"\n  impact 1.0\n\n  tag rationale: \"The secure port is used to serve https with authentication and authorization. If you disable it, no https traffic is served and all traffic is served unencrypted.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--secure-port` argument is either not set or is set to an integer value between 1 and 65535.\"\n\n  tag fix: \"Edit the deployment specs and set the --secure-port argument to the desired port.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"3.1.6\"\n  tag cis_level: 1\n  tag nist: ['AC-4 (20)', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe.one do\n    describe processes('federation-apiserver').commands.to_s do\n      it { should match(/--secure-port=([1-9][0-9]{0,3}|[1-5][0-9]{4}|6[0-4][0-9]{3}|65[0-4][0-9]{2}|655[0-2][0-9]|6553[0-5])/) }\n    end\n    describe processes('kube-apiserver').commands.to_s do\n      it { should_not match(/--secure-port/) }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 189
      },
      "id": "cis-kubernetes-benchmark-3.1.6"
    },
    {
      "title": "Ensure that the --profiling argument is set to false (Scored)",
      "desc": "Disable profiling, if not needed.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--profiling` argument is set to `false`.",
        "fix": "Edit the deployment specs and set `\"--profiling=false\"`:\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "3.1.7",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.7' do\n  title 'Ensure that the --profiling argument is set to false (Scored)'\n  desc \"Disable profiling, if not needed.\"\n  impact 1.0\n\n  tag rationale: \"Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--profiling` argument is set to `false`.\"\n\n  tag fix: \"Edit the deployment specs and set `\\\"--profiling=false\\\"`:\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"3.1.7\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--profiling=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 226
      },
      "id": "cis-kubernetes-benchmark-3.1.7"
    },
    {
      "title": "Ensure that the admission control policy is not set to AlwaysAdmit (Scored)",
      "desc": "Do not allow all requests.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Setting admission control policy to `AlwaysAdmit` allows all requests and do not filter any requests.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that does not include `AlwaysAdmit`.",
        "fix": "Edit the deployment specs and set --admission-control argument to a value that does not include AlwaysAdmit.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "3.1.8",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.8' do\n  title 'Ensure that the admission control policy is not set to AlwaysAdmit (Scored)'\n  desc \"Do not allow all requests.\"\n  impact 1.0\n\n  tag rationale: \"Setting admission control policy to `AlwaysAdmit` allows all requests and do not filter any requests.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that does not include `AlwaysAdmit`.\"\n\n  tag fix: \"Edit the deployment specs and set --admission-control argument to a value that does not include AlwaysAdmit.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"3.1.8\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should_not match(/--admission-control=(?:.)*AlwaysAdmit,*(?:.)*/) }\n    it { should match(/--admission-control=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 258
      },
      "id": "cis-kubernetes-benchmark-3.1.8"
    },
    {
      "title": "Ensure that the admission control policy is set to NamespaceLifecycle (Scored)",
      "desc": "Reject creating objects in a namespace that is undergoing termination.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Setting admission control policy to `NamespaceLifecycle` ensures that the namespaces undergoing termination are not used for creating the new objects. This is recommended to enforce the integrity of the namespace termination process and also for the availability of the newer objects.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `NamespaceLifecycle`.",
        "fix": "Edit the deployment specs and set `--admission-control` argument to a value that includes `NamespaceLifecycle`.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "3.1.9",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.9' do\n  title 'Ensure that the admission control policy is set to NamespaceLifecycle (Scored)'\n  desc \"Reject creating objects in a namespace that is undergoing termination.\"\n  impact 1.0\n\n  tag rationale: \"Setting admission control policy to `NamespaceLifecycle` ensures that the namespaces undergoing termination are not used for creating the new objects. This is recommended to enforce the integrity of the namespace termination process and also for the availability of the newer objects.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--admission-control` argument is set to a value that includes `NamespaceLifecycle`.\"\n\n  tag fix: \"Edit the deployment specs and set `--admission-control` argument to a value that includes `NamespaceLifecycle`.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"3.1.9\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--admission-control=(?:.)*NamespaceLifecycle,*(?:.)*/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 291
      },
      "id": "cis-kubernetes-benchmark-3.1.9"
    },
    {
      "title": "Ensure that the --audit-log-path argument is set as appropriate (Scored)",
      "desc": "Enable auditing on kubernetes federation apiserver and set the desired audit log path as appropriate.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Auditing Kubernetes federation apiserver provides a security-relevant chronological set of records documenting the sequence of activities that have affected system by individual users, administrators or other components of the system. Even though currently, Kubernetes provides only basic audit capabilities, it should be enabled. You can enable it by setting an appropriate audit log path.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--audit-log-path` argument is set as appropriate.",
        "fix": "Edit the deployment specs and set `--audit-log-path` argument as appropriate.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "6.2",
          "6.1"
        ],
        "cis_rid": "3.1.10",
        "cis_level": 1,
        "nist": [
          "AU-3",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.10' do\n  title 'Ensure that the --audit-log-path argument is set as appropriate (Scored)'\n  desc \"Enable auditing on kubernetes federation apiserver and set the desired audit log path as appropriate.\"\n  impact 1.0\n\n  tag rationale: \"Auditing Kubernetes federation apiserver provides a security-relevant chronological set of records documenting the sequence of activities that have affected system by individual users, administrators or other components of the system. Even though currently, Kubernetes provides only basic audit capabilities, it should be enabled. You can enable it by setting an appropriate audit log path.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--audit-log-path` argument is set as appropriate.\"\n\n  tag fix: \"Edit the deployment specs and set `--audit-log-path` argument as appropriate.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['6.2', '6.1']\n  tag cis_rid: \"3.1.10\"\n  tag cis_level: 1\n  tag nist: ['AU-3', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--audit-log-path=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 323
      },
      "id": "cis-kubernetes-benchmark-3.1.10"
    },
    {
      "title": "Ensure that the --audit-log-maxage argument is set to 30 or as appropriate (Scored)",
      "desc": "Retain the logs for at least 30 days or as appropriate.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Retaining logs for at least 30 days ensures that you can go back in time and investigate or correlate any events. Set your audit log retention period to 30 days or as per your business requirements.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--audit-log-maxage` argument is set to `30` or as appropriate.",
        "fix": "Edit the deployment specs and set --audit-log-maxage to 30 or as appropriate.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "6.3",
          "6.1"
        ],
        "cis_rid": "3.1.11",
        "cis_level": 1,
        "nist": [
          "AU-4",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.11' do\n  title 'Ensure that the --audit-log-maxage argument is set to 30 or as appropriate (Scored)'\n  desc \"Retain the logs for at least 30 days or as appropriate.\"\n  impact 1.0\n\n  tag rationale: \"Retaining logs for at least 30 days ensures that you can go back in time and investigate or correlate any events. Set your audit log retention period to 30 days or as per your business requirements.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--audit-log-maxage` argument is set to `30` or as appropriate.\"\n\n  tag fix: \"Edit the deployment specs and set --audit-log-maxage to 30 or as appropriate.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['6.3', '6.1']\n  tag cis_rid: \"3.1.11\"\n  tag cis_level: 1\n  tag nist: ['AU-4', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--audit-log-maxage=/) }\n  end\n\n  audit_log_maxage = processes('federation-apiserver').commands.to_s.scan(/--audit-log-maxage=(\\d+)/)\n\n  unless audit_log_maxage.empty?\n    describe audit_log_maxage.last.first.to_i do\n      it { should cmp >= 30 }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 355
      },
      "id": "cis-kubernetes-benchmark-3.1.11"
    },
    {
      "title": "Ensure that the --audit-log-maxbackup argument is set to 10 or as appropriate (Scored)",
      "desc": "Retain 10 or an appropriate number of old log files.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Kubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. For example, if you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--audit-log-maxbackup` argument is set to `10` or as appropriate.",
        "fix": "Edit the deployment specs and set `--audit-log-maxbackup` to `10` or as appropriate.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "6.3",
          "6.1"
        ],
        "cis_rid": "3.1.12",
        "cis_level": 1,
        "nist": [
          "AU-4",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.12' do\n  title 'Ensure that the --audit-log-maxbackup argument is set to 10 or as appropriate (Scored)'\n  desc \"Retain 10 or an appropriate number of old log files.\"\n  impact 1.0\n\n  tag rationale: \"Kubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. For example, if you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--audit-log-maxbackup` argument is set to `10` or as appropriate.\"\n\n  tag fix: \"Edit the deployment specs and set `--audit-log-maxbackup` to `10` or as appropriate.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['6.3', '6.1']\n  tag cis_rid: \"3.1.12\"\n  tag cis_level: 1\n  tag nist: ['AU-4', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--audit-log-maxbackup=/) }\n  end\n\n  audit_log_maxbackup = processes('federation-apiserver').commands.to_s.scan(/--audit-log-maxbackup=(\\d+)/)\n\n  unless audit_log_maxbackup.empty?\n    describe audit_log_maxbackup.last.first.to_i do\n      it { should cmp >= 10 }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 395
      },
      "id": "cis-kubernetes-benchmark-3.1.12"
    },
    {
      "title": "Ensure that the --audit-log-maxsize argument is set to 100 or as appropriate (Scored)",
      "desc": "Rotate log files on reaching 100 MB or as appropriate.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Kubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. If you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--audit-log-maxsize` argument is set to `100` or as appropriate.",
        "fix": "Edit the deployment specs and set `--audit-log-maxsize=100` to `100` or as appropriate.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "6.3",
          "6.1"
        ],
        "cis_rid": "3.1.13",
        "cis_level": 1,
        "nist": [
          "AU-4",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.13' do\n  title 'Ensure that the --audit-log-maxsize argument is set to 100 or as appropriate (Scored)'\n  desc \"Rotate log files on reaching 100 MB or as appropriate.\"\n  impact 1.0\n\n  tag rationale: \"Kubernetes automatically rotates the log files. Retaining old log files ensures that you would have sufficient log data available for carrying out any investigation or correlation. If you have set file size of 100 MB and the number of old log files to keep as 10, you would approximate have 1 GB of log data that you could potentially use for your analysis.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--audit-log-maxsize` argument is set to `100` or as appropriate.\"\n\n  tag fix: \"Edit the deployment specs and set `--audit-log-maxsize=100` to `100` or as appropriate.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['6.3', '6.1']\n  tag cis_rid: \"3.1.13\"\n  tag cis_level: 1\n  tag nist: ['AU-4', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--audit-log-maxsize=/) }\n  end\n\n  audit_log_maxsize = processes('federation-apiserver').commands.to_s.scan(/--audit-log-maxsize=(\\d+)/)\n\n  unless audit_log_maxsize.empty?\n    describe audit_log_maxsize.last.first.to_i do\n      it { should cmp >= 100 }\n    end\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 435
      },
      "id": "cis-kubernetes-benchmark-3.1.13"
    },
    {
      "title": "Ensure that the --authorization-mode argument is not set to AlwaysAllow (Scored)",
      "desc": "Do not always authorize all requests.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "The federation apiserver, by default, allows all requests. You should restrict this behavior to only allow the authorization modes that you explicitly use in your environment. For example, if you don't use REST APIs in your environment, it is a good security best practice to switch-off that capability.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--authorization-mode` argument exists and is not set to `AlwaysAllow`.",
        "fix": "Edit the deployment specs and set `--authorization-mode` argument to a value other than `AlwaysAllow`\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "9.1",
          "6.1"
        ],
        "cis_rid": "3.1.14",
        "cis_level": 1,
        "nist": [
          "CM-7 (1)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.14' do\n  title 'Ensure that the --authorization-mode argument is not set to AlwaysAllow (Scored)'\n  desc \"Do not always authorize all requests.\"\n  impact 1.0\n\n  tag rationale: \"The federation apiserver, by default, allows all requests. You should restrict this behavior to only allow the authorization modes that you explicitly use in your environment. For example, if you don't use REST APIs in your environment, it is a good security best practice to switch-off that capability.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--authorization-mode` argument exists and is not set to `AlwaysAllow`.\"\n\n  tag fix: \"Edit the deployment specs and set `--authorization-mode` argument to a value other than `AlwaysAllow`\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['9.1', '6.1']\n  tag cis_rid: \"3.1.14\"\n  tag cis_level: 1\n  tag nist: ['CM-7 (1)', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should_not match(/--authorization-mode=(?:.)*AlwaysAllow,*(?:.)*/) }\n    it { should match(/--authorization-mode=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 475
      },
      "id": "cis-kubernetes-benchmark-3.1.14"
    },
    {
      "title": "Ensure that the --token-auth-file parameter is not set (Scored)",
      "desc": "Do not use token based authentication.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/authentication/#static-token-file",
          "ref": "static-token-file"
        },
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "The token-based authentication utilizes static tokens to authenticate requests to the federation apiserver. The tokens are stored in clear-text in a file on the federation apiserver, and cannot be revoked or rotated without restarting the federation apiserver. Hence, do not use static token-based authentication.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--token-auth-file` argument does not exist.",
        "fix": "Follow the documentation and configure alternate mechanisms for authentication. Then, edit the deployment specs and remove the `--token-auth-file=<filename>` argument.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "16.14",
          "6.1"
        ],
        "cis_rid": "3.1.15",
        "cis_level": 1,
        "nist": [
          "SC-28",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.15' do\n  title 'Ensure that the --token-auth-file parameter is not set (Scored)'\n  desc \"Do not use token based authentication.\"\n  impact 1.0\n\n  tag rationale: \"The token-based authentication utilizes static tokens to authenticate requests to the federation apiserver. The tokens are stored in clear-text in a file on the federation apiserver, and cannot be revoked or rotated without restarting the federation apiserver. Hence, do not use static token-based authentication.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--token-auth-file` argument does not exist.\"\n\n  tag fix: \"Follow the documentation and configure alternate mechanisms for authentication. Then, edit the deployment specs and remove the `--token-auth-file=<filename>` argument.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['16.14', '6.1']\n  tag cis_rid: \"3.1.15\"\n  tag cis_level: 1\n  tag nist: ['SC-28', '4']\n  tag severity: \"medium\"\n\n  ref 'static-token-file', url: 'https://kubernetes.io/docs/admin/authentication/#static-token-file'\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should_not match(/--token-auth-file/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 508
      },
      "id": "cis-kubernetes-benchmark-3.1.15"
    },
    {
      "title": "Ensure that the --service-account-lookup argument is set to true (Scored)",
      "desc": "Validate service account before validating token.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/24167",
          "ref": "24167"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Time_of_check_to_time_of_use",
          "ref": "Time_of_check_to_time_of_use"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "By default, the apiserver only verifies that the authentication token is valid. However, it does not validate that the service account token mentioned in the request is actually present in etcd. This allows using a service account token even after the corresponding service account is deleted. This is an example of time of check to time of use security issue.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--service-account-lookup` argument exists and is set to `true`.",
        "fix": "Edit the deployment specs and set `\"--service-account-lookup=true\"`.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "16",
          "6.1"
        ],
        "cis_rid": "3.1.16",
        "cis_level": 1,
        "nist": [
          "AC-2",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.16' do\n  title 'Ensure that the --service-account-lookup argument is set to true (Scored)'\n  desc \"Validate service account before validating token.\"\n  impact 1.0\n\n  tag rationale: \"By default, the apiserver only verifies that the authentication token is valid. However, it does not validate that the service account token mentioned in the request is actually present in etcd. This allows using a service account token even after the corresponding service account is deleted. This is an example of time of check to time of use security issue.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--service-account-lookup` argument exists and is set to `true`.\"\n\n  tag fix: \"Edit the deployment specs and set `\\\"--service-account-lookup=true\\\"`.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['16', '6.1']\n  tag cis_rid: \"3.1.16\"\n  tag cis_level: 1\n  tag nist: ['AC-2', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref '24167', url: 'https://github.com/kubernetes/kubernetes/issues/24167'\n  ref 'Time_of_check_to_time_of_use', url: 'https://en.wikipedia.org/wiki/Time_of_check_to_time_of_use'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--service-account-lookup=true/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 541
      },
      "id": "cis-kubernetes-benchmark-3.1.16"
    },
    {
      "title": "Ensure that the --service-account-key-file argument is set as appropriate (Scored)",
      "desc": "Explicitly set a service account public key file for service accounts on the federation apiserver.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/issues/24167",
          "ref": "24167"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "By default, if no `--service-account-key-file` is specified to the federation apiserver, it uses the private key from the TLS serving certificate to verify the account tokens. To ensure that the keys for service account tokens could be rotated as needed, a separate public/private key pair should be used for signing service account tokens. Hence, the public key should be specified to the apiserver with `--service-account-key-file`.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--service-account-key-file` argument exists and is set as appropriate.",
        "fix": "Edit the deployment specs and set `--service-account-key-file` argument as appropriate.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "3",
          "6.1"
        ],
        "cis_rid": "3.1.17",
        "cis_level": 1,
        "nist": [
          "CM-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.17' do\n  title 'Ensure that the --service-account-key-file argument is set as appropriate (Scored)'\n  desc \"Explicitly set a service account public key file for service accounts on the federation apiserver.\"\n  impact 1.0\n\n  tag rationale: \"By default, if no `--service-account-key-file` is specified to the federation apiserver, it uses the private key from the TLS serving certificate to verify the account tokens. To ensure that the keys for service account tokens could be rotated as needed, a separate public/private key pair should be used for signing service account tokens. Hence, the public key should be specified to the apiserver with `--service-account-key-file`.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--service-account-key-file` argument exists and is set as appropriate.\"\n\n  tag fix: \"Edit the deployment specs and set `--service-account-key-file` argument as appropriate.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['3', '6.1']\n  tag cis_rid: \"3.1.17\"\n  tag cis_level: 1\n  tag nist: ['CM-6', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref '24167', url: 'https://github.com/kubernetes/kubernetes/issues/24167'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--service-account-key-file=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 575
      },
      "id": "cis-kubernetes-benchmark-3.1.17"
    },
    {
      "title": "Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate (Scored)",
      "desc": "etcd should be configured to make use of TLS encryption for client connections.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "https://coreos.com/etcd/docs/latest/op-guide/security.html",
          "ref": "security"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the federation API server to identify itself to the etcd server using a client certificate and key.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--etcd-certfile` and `--etcd-keyfile` arguments exist and they are set as appropriate.",
        "fix": "Follow the Kubernetes documentation and set up the TLS connection between the federation apiserver and etcd. Then, edit the deployment specs and set `\"--etcd- certfile=<path/to/client-certificate-file>\"` and `\"--etcd- keyfile=<path/to/client-key-file>\"` arguments.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "9",
          "6.1"
        ],
        "cis_rid": "3.1.18",
        "cis_level": 1,
        "nist": [
          "SC-7",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.18' do\n  title 'Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate (Scored)'\n  desc \"etcd should be configured to make use of TLS encryption for client connections.\"\n  impact 1.0\n\n  tag rationale: \"etcd is a highly-available key value store used by Kubernetes deployments for persistent storage of all of its REST API objects. These objects are sensitive in nature and should be protected by client authentication. This requires the federation API server to identify itself to the etcd server using a client certificate and key.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--etcd-certfile` and `--etcd-keyfile` arguments exist and they are set as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and set up the TLS connection between the federation apiserver and etcd. Then, edit the deployment specs and set `\\\"--etcd- certfile=<path/to/client-certificate-file>\\\"` and `\\\"--etcd- keyfile=<path/to/client-key-file>\\\"` arguments.\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['9', '6.1']\n  tag cis_rid: \"3.1.18\"\n  tag cis_level: 1\n  tag nist: ['SC-7', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'security', url: 'https://coreos.com/etcd/docs/latest/op-guide/security.html'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--etcd-certfile=/) }\n    it { should match(/--etcd-keyfile=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 608
      },
      "id": "cis-kubernetes-benchmark-3.1.18"
    },
    {
      "title": "Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Scored)",
      "desc": "Setup TLS connection on the federation API server.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-apiserver/",
          "ref": "federation-apiserver"
        },
        {
          "url": "http://rootsquash.com/2016/05/10/securing-the-kubernetes-api/",
          "ref": "securing-the-kubernetes-api"
        },
        {
          "url": "https://github.com/kelseyhightower/docker-kubernetes-tls-guide",
          "ref": "docker-kubernetes-tls-guide"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml",
          "ref": "federation-apiserver-deployment"
        },
        {
          "url": "https://kubernetes.io/docs/concepts/workloads/controllers/deployment/",
          "ref": "deployment"
        }
      ],
      "tags": {
        "rationale": "Federation API server communication contains sensitive parameters that should remain encrypted in transit. Configure the federation API server to serve only HTTPS traffic.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--tls-cert-file` and `--tls-private-key-file` arguments exist and they are set as appropriate.",
        "fix": "Follow the Kubernetes documentation and set up the TLS connection on the federation apiserver. Then, edit the deployment specs and set `\"--tls-cert-file=<path/to/tls- certificate-file>\"` and `\"--tls-private-key-file=<path/to/tls-key-file>\"`:\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`",
        "cis_family": [
          "14.2",
          "6.1"
        ],
        "cis_rid": "3.1.19",
        "cis_level": 1,
        "nist": [
          "AC-4 (20)",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.1.19' do\n  title 'Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Scored)'\n  desc \"Setup TLS connection on the federation API server.\"\n  impact 1.0\n\n  tag rationale: \"Federation API server communication contains sensitive parameters that should remain encrypted in transit. Configure the federation API server to serve only HTTPS traffic.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-apiserver`\n\n  Verify that the `--tls-cert-file` and `--tls-private-key-file` arguments exist and they are set as appropriate.\"\n\n  tag fix: \"Follow the Kubernetes documentation and set up the TLS connection on the federation apiserver. Then, edit the deployment specs and set `\\\"--tls-cert-file=<path/to/tls- certificate-file>\\\"` and `\\\"--tls-private-key-file=<path/to/tls-key-file>\\\"`:\n\n  `kubectl edit deployments federation-apiserver-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['14.2', '6.1']\n  tag cis_rid: \"3.1.19\"\n  tag cis_level: 1\n  tag nist: ['AC-4 (20)', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-apiserver', url: 'https://kubernetes.io/docs/admin/federation-apiserver/'\n  ref 'securing-the-kubernetes-api', url: 'http://rootsquash.com/2016/05/10/securing-the-kubernetes-api/'\n  ref 'docker-kubernetes-tls-guide', url: 'https://github.com/kelseyhightower/docker-kubernetes-tls-guide'\n  ref 'federation-apiserver-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-apiserver-deployment.yaml'\n  ref 'deployment', url: 'https://kubernetes.io/docs/concepts/workloads/controllers/deployment/'\n\n  describe processes('federation-apiserver').commands.to_s do\n    it { should match(/--tls-cert-file=/) }\n    it { should match(/--tls-private-key-file=/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_1_federation_api_server.rb",
        "line": 642
      },
      "id": "cis-kubernetes-benchmark-3.1.19"
    },
    {
      "title": "Ensure that the --profiling argument is set to false (Scored)",
      "desc": "Disable profiling, if not needed.",
      "impact": 1,
      "refs": [
        {
          "url": "https://kubernetes.io/docs/admin/federation-controller-manager/",
          "ref": "federation-controller-manager"
        },
        {
          "url": "https://github.com/kubernetes/community/blob/master/contributors/devel/profiling.md",
          "ref": "profiling"
        },
        {
          "url": "https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-controller-manager-deployment.yaml",
          "ref": "federation-controller-manager-deployment"
        }
      ],
      "tags": {
        "rationale": "Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.",
        "check": "Run the following command:\n\n  `ps -ef | grep federation-controller-manager`\n\n  Verify that the `--profiling` argument is set to `false`.",
        "fix": "Edit the deployment specs and set `\"--profiling=false\"`:\n\n  `kubectl edit deployments federation-controller-manager-deployment --namespace=federation-system`",
        "cis_family": [
          "14",
          "6.1"
        ],
        "cis_rid": "3.2.1",
        "cis_level": 1,
        "nist": [
          "AC-6",
          "Rev_4"
        ],
        "severity": "medium"
      },
      "code": "control 'cis-kubernetes-benchmark-3.2.1' do\n  title 'Ensure that the --profiling argument is set to false (Scored)'\n  desc \"Disable profiling, if not needed.\"\n  impact 1.0\n\n  tag rationale: \"Profiling allows for the identification of specific performance bottlenecks. It generates a significant amount of program data that could potentially be exploited to uncover system and program details. If you are not experiencing any bottlenecks and do not need the profiler for troubleshooting purposes, it is recommended to turn it off to reduce the potential attack surface.\"\n\n  tag check: \"Run the following command:\n\n  `ps -ef | grep federation-controller-manager`\n\n  Verify that the `--profiling` argument is set to `false`.\"\n\n  tag fix: \"Edit the deployment specs and set `\\\"--profiling=false\\\"`:\n\n  `kubectl edit deployments federation-controller-manager-deployment --namespace=federation-system`\"\n\n  tag cis_family: ['14', '6.1']\n  tag cis_rid: \"3.2.1\"\n  tag cis_level: 1\n  tag nist: ['AC-6', '4']\n  tag severity: \"medium\"\n\n  ref 'federation-controller-manager', url: 'https://kubernetes.io/docs/admin/federation-controller-manager/'\n  ref 'profiling', url: 'https://github.com/kubernetes/community/blob/master/contributors/devel/profiling.md'\n  ref 'federation-controller-manager-deployment', url: 'https://github.com/kubernetes/kubernetes/blob/master/federation/manifests/federation-controller-manager-deployment.yaml'\n\n  describe processes('federation-controller-manager').commands.to_s do\n    it { should match(/--profiling=false/) }\n  end\nend\n",
      "source_location": {
        "ref": "./controls/3_2_federation_controller_manager.rb",
        "line": 24
      },
      "id": "cis-kubernetes-benchmark-3.2.1"
    }
  ],
  "groups": [
    {
      "title": "1.1 Master Node: API Server",
      "controls": [
        "cis-kubernetes-benchmark-1.1.1",
        "cis-kubernetes-benchmark-1.1.2",
        "cis-kubernetes-benchmark-1.1.3",
        "cis-kubernetes-benchmark-1.1.4",
        "cis-kubernetes-benchmark-1.1.5",
        "cis-kubernetes-benchmark-1.1.6",
        "cis-kubernetes-benchmark-1.1.7",
        "cis-kubernetes-benchmark-1.1.8",
        "cis-kubernetes-benchmark-1.1.9",
        "cis-kubernetes-benchmark-1.1.10",
        "cis-kubernetes-benchmark-1.1.11",
        "cis-kubernetes-benchmark-1.1.12",
        "cis-kubernetes-benchmark-1.1.13",
        "cis-kubernetes-benchmark-1.1.14",
        "cis-kubernetes-benchmark-1.1.15",
        "cis-kubernetes-benchmark-1.1.16",
        "cis-kubernetes-benchmark-1.1.17",
        "cis-kubernetes-benchmark-1.1.18",
        "cis-kubernetes-benchmark-1.1.19",
        "cis-kubernetes-benchmark-1.1.20",
        "cis-kubernetes-benchmark-1.1.21",
        "cis-kubernetes-benchmark-1.1.22",
        "cis-kubernetes-benchmark-1.1.23",
        "cis-kubernetes-benchmark-1.1.24",
        "cis-kubernetes-benchmark-1.1.25",
        "cis-kubernetes-benchmark-1.1.26",
        "cis-kubernetes-benchmark-1.1.27",
        "cis-kubernetes-benchmark-1.1.28",
        "cis-kubernetes-benchmark-1.1.29",
        "cis-kubernetes-benchmark-1.1.30",
        "cis-kubernetes-benchmark-1.1.31",
        "cis-kubernetes-benchmark-1.1.32",
        "cis-kubernetes-benchmark-1.1.33",
        "cis-kubernetes-benchmark-1.1.34",
        "cis-kubernetes-benchmark-1.1.35"
      ],
      "id": "controls/1_1_master_node_api_server.rb"
    },
    {
      "title": "1.2 Master Node: Scheduler",
      "controls": [
        "cis-kubernetes-benchmark-1.2.1"
      ],
      "id": "controls/1_2_master_node_scheduler.rb"
    },
    {
      "title": "1.3 Master Node: Controller Manager",
      "controls": [
        "cis-kubernetes-benchmark-1.3.1",
        "cis-kubernetes-benchmark-1.3.2",
        "cis-kubernetes-benchmark-1.3.3",
        "cis-kubernetes-benchmark-1.3.4",
        "cis-kubernetes-benchmark-1.3.5",
        "cis-kubernetes-benchmark-1.3.6",
        "cis-kubernetes-benchmark-1.3.7"
      ],
      "id": "controls/1_3_master_node_controller_manager.rb"
    },
    {
      "title": "1.4 Master Node: Configuration Files",
      "controls": [
        "cis-kubernetes-benchmark-1.4.1",
        "cis-kubernetes-benchmark-1.4.2",
        "cis-kubernetes-benchmark-1.4.3",
        "cis-kubernetes-benchmark-1.4.4",
        "cis-kubernetes-benchmark-1.4.5",
        "cis-kubernetes-benchmark-1.4.6",
        "cis-kubernetes-benchmark-1.4.7",
        "cis-kubernetes-benchmark-1.4.8",
        "cis-kubernetes-benchmark-1.4.9",
        "cis-kubernetes-benchmark-1.4.10",
        "cis-kubernetes-benchmark-1.4.11",
        "cis-kubernetes-benchmark-1.4.12"
      ],
      "id": "controls/1_4_master_node_configuration_files.rb"
    },
    {
      "title": "1.5 Master Node: etcd",
      "controls": [
        "cis-kubernetes-benchmark-1.5.1",
        "cis-kubernetes-benchmark-1.5.2",
        "cis-kubernetes-benchmark-1.5.3",
        "cis-kubernetes-benchmark-1.5.4",
        "cis-kubernetes-benchmark-1.5.5",
        "cis-kubernetes-benchmark-1.5.6",
        "cis-kubernetes-benchmark-1.5.7",
        "cis-kubernetes-benchmark-1.5.8",
        "cis-kubernetes-benchmark-1.5.9"
      ],
      "id": "controls/1_5_master_node_etcd.rb"
    },
    {
      "title": "1.6 Master Node: General Security Primitives",
      "controls": [
        "cis-kubernetes-benchmark-1.6.1",
        "cis-kubernetes-benchmark-1.6.2",
        "cis-kubernetes-benchmark-1.6.3",
        "cis-kubernetes-benchmark-1.6.4",
        "cis-kubernetes-benchmark-1.6.5",
        "cis-kubernetes-benchmark-1.6.6",
        "cis-kubernetes-benchmark-1.6.7",
        "cis-kubernetes-benchmark-1.6.8"
      ],
      "id": "controls/1_6_master_node_general_security_primitives.rb"
    },
    {
      "title": "2.1 Worker Node: Kubelet",
      "controls": [
        "cis-kubernetes-benchmark-2.1.1",
        "cis-kubernetes-benchmark-2.1.2",
        "cis-kubernetes-benchmark-2.1.3",
        "cis-kubernetes-benchmark-2.1.4",
        "cis-kubernetes-benchmark-2.1.5",
        "cis-kubernetes-benchmark-2.1.6",
        "cis-kubernetes-benchmark-2.1.7",
        "cis-kubernetes-benchmark-2.1.8",
        "cis-kubernetes-benchmark-2.1.9",
        "cis-kubernetes-benchmark-2.1.10",
        "cis-kubernetes-benchmark-2.1.11",
        "cis-kubernetes-benchmark-2.1.12",
        "cis-kubernetes-benchmark-2.1.13",
        "cis-kubernetes-benchmark-2.1.14",
        "cis-kubernetes-benchmark-2.1.15"
      ],
      "id": "controls/2_1_worker_node_kubelet.rb"
    },
    {
      "title": "2.2 Worker Node: Configuration Files",
      "controls": [
        "cis-kubernetes-benchmark-2.2.1",
        "cis-kubernetes-benchmark-2.2.2",
        "cis-kubernetes-benchmark-2.2.3",
        "cis-kubernetes-benchmark-2.2.4",
        "cis-kubernetes-benchmark-2.2.5",
        "cis-kubernetes-benchmark-2.2.6",
        "cis-kubernetes-benchmark-2.2.7",
        "cis-kubernetes-benchmark-2.2.8"
      ],
      "id": "controls/2_2_worker_node_configuration_files.rb"
    },
    {
      "title": "3.1 Federation API Server",
      "controls": [
        "cis-kubernetes-benchmark-3.1.1",
        "cis-kubernetes-benchmark-3.1.2",
        "cis-kubernetes-benchmark-3.1.3",
        "cis-kubernetes-benchmark-3.1.4",
        "cis-kubernetes-benchmark-3.1.5",
        "cis-kubernetes-benchmark-3.1.6",
        "cis-kubernetes-benchmark-3.1.7",
        "cis-kubernetes-benchmark-3.1.8",
        "cis-kubernetes-benchmark-3.1.9",
        "cis-kubernetes-benchmark-3.1.10",
        "cis-kubernetes-benchmark-3.1.11",
        "cis-kubernetes-benchmark-3.1.12",
        "cis-kubernetes-benchmark-3.1.13",
        "cis-kubernetes-benchmark-3.1.14",
        "cis-kubernetes-benchmark-3.1.15",
        "cis-kubernetes-benchmark-3.1.16",
        "cis-kubernetes-benchmark-3.1.17",
        "cis-kubernetes-benchmark-3.1.18",
        "cis-kubernetes-benchmark-3.1.19"
      ],
      "id": "controls/3_1_federation_api_server.rb"
    },
    {
      "title": "3.2 Federation Controller Manager",
      "controls": [
        "cis-kubernetes-benchmark-3.2.1"
      ],
      "id": "controls/3_2_federation_controller_manager.rb"
    }
  ],
  "attributes": [
    {
      "name": "cis_level",
      "options": {
        "default": "2",
        "description": "CIS profile level to audit",
        "required": true
      }
    },
    {
      "name": "cis_level",
      "options": {
        "default": "2",
        "description": "CIS profile level to audit",
        "required": true
      }
    }
  ],
  "sha256": "84feb4c2bc15c050ec010cf4666e24fcd7c51f83c038e74273ffdf3fdb4933da"
}